---
title: "ä¸ªäººRAGé¡¹ç›®å¼€å‘è®°å½•"
date: 2025-11-07
lastmod: 2025-11-11
tags:
  - LLM
keywords:
  - LLM
  - RAG
description: "ä¸ªäººRAGé¡¹ç›®çš„å¼€å‘è®°å½•å’Œç¬”è®°"
---


## é¡¹ç›®ç¯å¢ƒæ­å»º

1. å¦‚ä½•å°†requirements.txtä¸­çš„ä¾èµ–è½¬ç§»åˆ° uvç¯å¢ƒä¸­
    1. `uv add -r requirements.txt`
        1. å¦‚æœå¤ªæ…¢åˆ™åŠ  url  `uv add -r requirements.txt --index-url https://pypi.tuna.tsinghua.edu.cn/simple`
2. ollamaæ­å»º
    1. æŠ¥é”™
        1. ollamaä¿®æ”¹æ¨¡å‹ä¸‹è½½ç›®å½•ä¹‹åæŠ¥é”™
        2. error: pull model manifest: 503: no healthy upstream
        3. é‡å¯æœåŠ¡å³å¯
            1. sudo systemctl stop ollama
            2. sudo systemctl start ollama
    2. ä¿®æ”¹æ¨¡å‹ç›®å½•
        1. sudo ln -s  /home/chester/ollama/models /usr/share/ollama/.ollama/
        2. sudo chown ollama /usr/share/ollama/.ollama/models
        3. sudo chgrp ollama /usr/share/ollama/.ollama/models
        4. åä¸¤æ¡æ˜¯ä¿è¯ç›®å½•çš„æƒé™é—®é¢˜ï¼Œä¸ç„¶ollmaè¿è¡Œä¼šæŠ¥é”™
        5. èµ„æ–™æ¥æº [Does anyone know how to change where your models are saved on linux? : r/ollama](https://www.reddit.com/r/ollama/comments/1c4zg15/does_anyone_know_how_to_change_where_your_models/)
    3. Ollama(model="qwen3:0.6b")
        1. è¿™æ®µä»£ç å‰ææ˜¯ ç³»ç»Ÿä¸­ åå°å¯åŠ¨äº†ollamaæœåŠ¡ï¼ˆlinuxå®‰è£…ä¹‹åä¼šè‡ªåŠ¨åŠ å…¥ç³»ç»ŸæœåŠ¡ï¼Œæ— éœ€æ‰‹åŠ¨å¯åŠ¨è¯¥æœåŠ¡ï¼‰ï¼Œä½†å¹¶ä¸éœ€è¦ å‘½ä»¤è¡Œæ‰§è¡Œ ollama run modelã€‚åº”è¯¥æ˜¯åå°ä¼šè‡ªåŠ¨åŠèµ·å¯¹åº”çš„æ¨¡å‹è¿›è¡Œè®¡ç®—å¹¶ä¼ å›pythonã€‚
    4. æœ¬åœ°è¿è¡ŒollamaçœŸçš„å¤ªæ…¢äº†ã€‚
3. embedding
    1. HuggingFaceBgeEmbeddings
        1. åœ¨pycharmä¸­è¿è¡Œçš„æ—¶å€™ï¼Œè¦ç»™jupyter server æ·»åŠ å‚æ•°ï¼Œé…ä¸Šhttp_proxyçš„ä»£ç†ã€‚åœ¨pycharmè½¯ä»¶å±‚é¢è®¾ç½®http_proxyæ˜¯æ²¡ç”¨çš„ã€‚
        2. huggingfaceä¼šä¸‹è½½æ¨¡å‹å»ºç«‹æœ¬åœ°æœåŠ¡è¿›è¡Œè®¡ç®—ã€‚
    2. HuggingFaceInferenceAPIEmbeddings
        1. æ˜¯é€šè¿‡apiè¿›è¡Œembeddingè®¡ç®—ï¼Œè€Œä¸æ˜¯æœ¬åœ°è¿›è¡Œè®¡ç®—ã€‚
4. httpcore ä¸€ç›´æŠ¥é”™æ²¡æœ‰å®‰è£…
    1. æœ€åå‘ç°æ˜¯httpcoreæ²¡æœ‰å®‰è£…å¥½ï¼Œå¯¹åº”çš„pythonåŒ…åªæœ‰å…ƒæ•°æ®æ²¡æœ‰çœŸå®ä»£ç ï¼Œå°†å¯¹åº”ç›®å½•åˆ é™¤åé‡åˆ·uvç¯å¢ƒå³å¯ã€‚

## P01-RAG-Projects
#### P01 chatbot

#### é—®é¢˜ï¼šload_dotenvçš„æœºåˆ¶

1. load_dotenv å®šä¹‰å¦‚ä¸‹
    1. é»˜è®¤åŠ è½½ .envæ–‡ä»¶ï¼Œå¦‚æœå½“å‰ç›®å½•ä¸å­˜åœ¨ï¼Œå°±ä¸æ–­æå‡ç›®å½•å±‚æ¬¡æ¥æŸ¥æ‰¾ã€‚
    2. interpolate ç”¨äºæ˜¯å¦è§£æå­—ç¬¦ä¸²ä¸­çš„å˜é‡ï¼Œæ¯”å¦‚ `PATH=${PATH}:/usr/share/bin` ï¼Œå°±ä¼šæŠŠPATHå˜é‡è¿›è¡Œè§£ææ›¿æ¢ã€‚
2. å…¶ä¸­ `dotenv.main.resolve_variables` å¯¹äºinterpolate åŠŸèƒ½çš„å®ç°å¾ˆæœ‰æ„æ€ï¼Œä½¿ç”¨äº†æ­£åˆ™æ–¹æ³•æ¥åŒ¹é…å¹¶åˆ†åˆ«è¿›è¡Œæ›¿æ¢ã€‚



```Python
def load_dotenv(
    dotenv_path: Optional[StrPath] = None,
    stream: Optional[IO[str]] = None,
    verbose: bool = False,
    override: bool = False,
    interpolate: bool = True,
    encoding: Optional[str] = "utf-8",
) -> bool:
    """Parse a .env file and then load all the variables found as environment variables.

    Parameters:
        dotenv_path: Absolute or relative path to .env file.
        stream: Text stream (such as `io.StringIO`) with .env content, used if
            `dotenv_path` is `None`.
        verbose: Whether to output a warning the .env file is missing.
        override: Whether to override the system environment variables with the variables
            from the `.env` file.
        encoding: Encoding to be used to read the file.
    Returns:
        Bool: True if at least one environment variable is set else False

    If both `dotenv_path` and `stream` are `None`, `find_dotenv()` is used to find the
    .env file with it's default parameters. If you need to change the default parameters
    of `find_dotenv()`, you can explicitly call `find_dotenv()` and pass the result
    to this function as `dotenv_path`.

    If the environment variable `PYTHON_DOTENV_DISABLED` is set to a truthy value,
    .env loading is disabled.
    """
```

#### P02 APIs

1. `ChatMessagePromptTemplate` å’Œ `ChatPromptTemplate` æ˜¯ä¸¤ä¸ªä¸åŒçš„ç±»ï¼Œä¸»è¦åŒºåˆ«å¦‚ä¸‹ï¼š
    1. **ChatMessagePromptTemplate**
        - ç”¨äºè¡¨ç¤ºå•ä¸ªèŠå¤©æ¶ˆæ¯çš„æ¨¡æ¿
        - å¯¹åº”å•æ¡æ¶ˆæ¯ï¼ŒåŒ…å«æ¶ˆæ¯çš„è§’è‰²ï¼ˆå¦‚ç³»ç»Ÿã€ç”¨æˆ·ã€åŠ©æ‰‹ï¼‰å’Œå†…å®¹æ¨¡æ¿
        - æ˜¯æ„æˆèŠå¤©æ¨¡æ¿çš„åŸºæœ¬å•å…ƒ
    2. **ChatPromptTemplate**
        - ç”¨äºè¡¨ç¤ºæ•´ä¸ªèŠå¤©å¯¹è¯çš„æ¨¡æ¿
        - å¯ä»¥åŒ…å«å¤šä¸ª `ChatMessagePromptTemplate` å®ä¾‹
        - ç”¨äºæ„å»ºå®Œæ•´çš„å¯¹è¯å†å²æ¨¡æ¿ï¼Œæ”¯æŒå¤šè½®å¯¹è¯åœºæ™¯
    - ç®€è€Œè¨€ä¹‹ï¼Œ`ChatMessagePromptTemplate` æ˜¯å•æ¡æ¶ˆæ¯æ¨¡æ¿ï¼Œè€Œ `ChatPromptTemplate` æ˜¯æ•´ä¸ªå¯¹è¯æ¨¡æ¿ï¼Œåè€…å¯ä»¥åŒ…å«å¤šä¸ªå‰è€…æ¥æ„å»ºå®Œæ•´çš„å¯¹è¯ä¸Šä¸‹æ–‡ã€‚
2. `ChatPromptTemplate`
    1. from_messages ä»è‹¥å¹²messageä¸­æ„é€ æ¨¡æ¿
    2. from_template ä»å•ä¸ª message çš„ template æ¥æ„é€  HumanMessageï¼Œå¹¶ç»„è£…ä¸ºä¸€ä¸ªChatã€‚
3. FewShotChatMessagePromptTemplate
4. langchain_core.promptsä¸­çš„å„ç§promptã€‚
5. ChatOpenAIçš„ä½¿ç”¨æ–¹æ³•
    1. [langchain\_openai.chat\_models.base.ChatOpenAI â€” ğŸ¦œğŸ”— LangChain 0.2.17](https://api.python.langchain.com/en/latest/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html#langchain_openai.chat_models.base.ChatOpenAI)
6. StrOutputParser å¦‚ä½•è§£æchainä¹‹å‰éƒ¨åˆ†çš„å†…å®¹
    1. langchain_core.outputs.chat_generation.ChatGeneration.set_text ä¸­æŒ‡æ˜äº†ä»messageä¸­çš„contentå±æ€§æ¥è·å–å†…å®¹ã€‚
#### P04 Retriever and Chain

1. create_stuff_documents_chain 
    1. RunnablePassthrough å³ identity functionï¼Œæ’ç­‰å‡½æ•°ï¼Œè¾“å…¥ä»€ä¹ˆå°±è¾“å‡ºä»€ä¹ˆã€‚
    2. RunnablePassthrough.assign  ï¼š Merge the Dict input with the output produced by the mapping argument.
2. **chainçš„è°ƒç”¨è¿‡ç¨‹**
    1. è¾“å…¥ï¼šè¾“å…¥æ•°æ®ä¸ºdictï¼Œæœ‰inputè¿™ä¸ªkeyã€‚
    2. `retrieval_docs` ï¼šå…ˆå¯¹ æ•°æ®è¿›è¡Œæ£€ç´¢ï¼Œå³ä»xä¸­è·å– inputè¿™ä¸€é¡¹ï¼Œç„¶åé€å…¥æ£€ç´¢å™¨ã€‚æ£€ç´¢å™¨æœ¬è´¨ä¸Šæ˜¯è°ƒç”¨äº† `__ror__`æ–¹æ³•ï¼Œè¿›ä¸€æ­¥è°ƒç”¨äº† `VectorStoreRetriever`çš„ `_get_relevant_documents` æ–¹æ³•ï¼Œè¿›ä¸€æ­¥è°ƒç”¨äº† `self.vectorstore.similarity_search`æ–¹æ³•ã€‚æ£€ç´¢å®Œä¹‹åï¼Œå°†ç›¸ä¼¼æ–‡æ¡£ç»„è£…ä¸ºä¸€ä¸ªitemæ”¾å…¥åˆ° contextè¿™ä¸ªkeyä¸‹ã€‚ æ•°æ®å˜ä¸º `{input:XXX, context:[docs]}`ã€‚
    3. `format_docs` ï¼šæ£€ç´¢å‡ºç›¸ä¼¼æ–‡æ¡£ä¹‹åï¼Œé€å…¥format_inputsè¿‡ç¨‹ï¼Œå³å°†æ•°æ®ä¸­çš„contexté¡¹æ ¼å¼ä¸ºå­—ç¬¦ä¸²ï¼Œå¹¶ç”¨ åŒæ¢è¡Œç¬¦è¿›è¡Œåˆ†éš”è¿æ¥ã€‚æ•°æ®å˜ä¸º `{input:XXX, context:doc_str}`
    4. `prompt`ï¼š é€å…¥promptï¼Œpromptçš„invokeæ–¹æ³•ä¸­æœ¬è´¨å°±æ˜¯å¯¹ templateå­—ç¬¦ä¸²å’Œ ä¸Šä¸€æ­¥è®¡ç®—å‡ºçš„æ•°æ®è¿›è¡Œæ ¼å¼åŒ–ã€‚
    5. `llm`ï¼šæ¨¡å‹ç»™å‡ºå“åº”
    6. `_output_parser` æœ¬è´¨å°±æ˜¯å¯¹ è¾“å‡ºçš„responseæ¶ˆæ¯è¿›è¡Œæ ¼å¼åŒ–ï¼Œæœ¬è´¨å°±æ˜¯æå–æ¶ˆæ¯ä¸­çš„keyä¸º"text"å¯¹åº”çš„å±æ€§ã€‚




```Python
response=retriever.invoke(input="""image processing with an introduction to techniques for image pattern classification""")

#langchain_classic/chains/retrieval.py:64
if not isinstance(retriever, BaseRetriever):  
    retrieval_docs: Runnable[dict, RetrieverOutput] = retriever  
else:  
    retrieval_docs = (lambda x: x["input"]) | retriever
    
return (  
    RunnablePassthrough.assign(  
        context=retrieval_docs.with_config(run_name="retrieve_documents"),  
    ).assign(answer=combine_docs_chain)  
).with_config(run_name="retrieval_chain")

def format_docs(inputs: dict) -> str:  
    return document_separator.join(  
        format_document(doc, _document_prompt)  
        for doc in inputs[document_variable_name]  
    )
    
return (  
    RunnablePassthrough.assign(**{document_variable_name: format_docs}).with_config(  
        run_name="format_inputs",  
    )  
    | prompt  
    | llm  
    | _output_parser  
).with_config(run_name="stuff_documents_chain")
```


#### P05 Advanced RAG Q&A Project

1. create_retriever_tool
    1. æœ¬è´¨å°±æ˜¯ å°†æ£€ç´¢ã€æ ¼å¼åŒ–ã€æ‹¼æ¥å·¥ä½œç»„è£…ä¸ºä¸€ä¸ªæ•´ä½“åŠŸèƒ½ç„¶åï¼Œå®ä¾‹åŒ–ä¸ºä¸€ä¸ªtoolã€‚
2. **Scratchpad å«ä¹‰**
    - ç›´è¯‘ä¸ºè‰ç¨¿çº¸
    - åœ¨ LangChain æˆ–ç±»ä¼¼æ¡†æ¶ä¸­ï¼Œ`scratchpad` é€šå¸¸æŒ‡ä»£ç†(Agent)çš„ä¸´æ—¶å·¥ä½œç©ºé—´ï¼Œç”¨äºï¼š
        - å­˜å‚¨ä¸­é—´æ€è€ƒè¿‡ç¨‹
        - è®°å½•å½“å‰ä»»åŠ¡çŠ¶æ€
        - ä¿å­˜ä¸´æ—¶è®¡ç®—ç»“æœ
        - è¿›è¡Œæ¨ç†å’Œå†³ç­–çš„ç¼“å†²åŒº
    - è¿™æ˜¯ä¸€ä¸ªé€šç”¨çš„è®¡ç®—æœºç§‘å­¦æ¦‚å¿µï¼Œè¡¨ç¤ºä»»ä½•ç”¨äºä¸´æ—¶å­˜å‚¨å’Œå¤„ç†çš„å†…å­˜åŒºåŸŸã€‚
3. æœ€ç»ˆtoolsæ˜¯åœ¨ `ollama._types.ChatRequest` è¿›è¡Œè§£æï¼Œå…·ä½“è§ä¸‹é¢ä»£ç ã€‚
4. è¿™é‡Œçš„llmèµ°çš„æ˜¯chatç±»å‹çš„llmï¼Œæ‰€ä»¥åº•å±‚æ˜¯èµ° `/api/chat` æ¥å£ï¼Œè¯¥æ¥å£çš„å‚æ•°åˆ—è¡¨ä¸­å«æœ‰toolsã€‚ç›¸å½“äºè¯¥æ¥å£å·²ç»æŠŠtoolsçš„æè¿°å¦‚ä½•æ ¼å¼åŒ–éƒ½å·²ç»åœ¨å†…éƒ¨è§£å†³æ‰ï¼Œä¸éœ€è¦è°ƒç”¨æ–¹å°†toolsçš„æè¿°æ ¼å¼åŒ–åˆ° prompté‡Œé¢ã€‚
5. AgentExecutoré‡Œæœ€é‡è§†ä¾èµ– `iter`æ–¹æ³•æ¥ä¸æ–­è¿­ä»£ï¼Œåº•å±‚æ˜¯ä¾èµ–`_iter_next_step`æ¥è¿›è¡Œ thoughtã€actionæ­¥éª¤çš„ã€‚
6. å³chat_modelçš„æ¥å£éƒ½æ˜¯æ”¯æŒåœ¨è¯·æ±‚ä¸­åŠ å…¥toolså‚æ•°çš„ã€‚


```Python
#Runnableçš„æ–¹æ³•
def bind(self, **kwargs: Any) -> Runnable[Input, Output]:  
    """Bind arguments to a `Runnable`, returning a new `Runnable`.  
  
    Useful when a `Runnable` in a chain requires an argument that is not    in the output of the previous `Runnable` or included in the user input.
"""
#langchain_ollama.chat_models.ChatOllama._create_chat_stream
# ollama/_client.py:351
# ollama._client.Client.chat
return self._request(  
  ChatResponse,  
  'POST',  
  '/api/chat',  
  json=ChatRequest(  
    model=model,  
    messages=list(_copy_messages(messages)),  
    tools=list(_copy_tools(tools)),  
    stream=stream,  
    think=think,  
    format=format,  
    options=options,  
    keep_alive=keep_alive,  
  ).model_dump(exclude_none=True),  
  stream=stream,  
)
```

```Python


#langchain_classic.agents.agent.AgentExecutor._iter_next_step
    def _iter_next_step(
        self,
        name_to_tool_map: dict[str, BaseTool],
        color_mapping: dict[str, str],
        inputs: dict[str, str],
        intermediate_steps: list[tuple[AgentAction, str]],
        run_manager: CallbackManagerForChainRun | None = None,
    ) -> Iterator[AgentFinish | AgentAction | AgentStep]:
        """Take a single step in the thought-action-observation loop.

        Override this to take control of how the agent makes and acts on choices.
        """
        try:
            intermediate_steps = self._prepare_intermediate_steps(intermediate_steps)

            # Call the LLM to see what to do.
            output = self._action_agent.plan(
                intermediate_steps,
                callbacks=run_manager.get_child() if run_manager else None,
                **inputs,
            )
        except OutputParserException as e:
            ......
            
        # If the tool chosen is the finishing tool, then we end and return.
        if isinstance(output, AgentFinish):
            yield output
            return

        actions: list[AgentAction]
        actions = [output] if isinstance(output, AgentAction) else output
        for agent_action in actions:
            yield agent_action
        for agent_action in actions:
            yield self._perform_agent_action(
                name_to_tool_map,
                color_mapping,
                agent_action,
                run_manager,
            )
        ...
```

#### P06 Advanced RAG Q&A Project

1. æœ¬åœ°æœåŠ¡å’Œè¿œç¨‹æœåŠ¡çš„ä»£ç†è®¾ç½®ï¼Œå¦‚ä¸‹é¢ä»£ç 
    1. HTTP_PROXY å’Œ HTTPS_PROXYç”¨äºè®¾ç½®é€šè¿‡httpæœåŠ¡çš„ä»£ç†
    2. NO_PROXY ç”¨äºæœ¬åœ°æœåŠ¡ç»•è¿‡ä¸Šé¢è®¾ç½®çš„ä»£ç†ï¼Œå¦‚æœ¬åœ°çš„OllamaæœåŠ¡ã€‚
2. `vectorstore.as_retriever` å¯ä»¥ç›´æ¥è½¬æ¢ä¸ºæ£€ç´¢å™¨
    1. æ–¹æ³•å‚æ•°`search_kwargs` ä¸­ä¹Ÿå¯ä»¥è®¾ç½®è¿”å›çš„æ–‡æ¡£æ•°ç›®kã€MMRå¤šæ ·æ€§ç®—æ³•ã€å…ƒæ•°æ®è¿‡æ»¤å™¨å‡½æ•°ç­‰ã€‚

```Python
import os  
# è®¾ç½®httpçš„ä»£ç†å’Œä¸ä»£ç†çš„åœ°å€  
os.environ['HTTP_PROXY'] = "http://127.0.0.1:7890"  
os.environ['HTTPS_PROXY'] = "http://127.0.0.1:7890"  
os.environ['NO_PROXY'] = "http://127.0.0.1:11434" #ollamaçš„æœ¬åœ°æœåŠ¡åœ°å€
```

#### P07

1. HuggingFaceEndpoint æ¥å£é—®é¢˜
    1. bug  https://github.com/langchain-ai/langchain/issues/31434#issuecomment-2936308959
    2. å› ä¸ºå®˜æ–¹æœåŠ¡ä¸å†æä¾› text-generationçš„æ¨¡å‹æœåŠ¡ã€‚
    3. å¯ä»¥ä½¿ç”¨ ChatHuggingFaceæ¥ç»•è¿‡è¿™ä¸ªé—®é¢˜ã€‚
#### P08

1. OllamaEmbeddings åœ¨æœ¬åœ°çš„ç¬”è®°æœ¬ä¸Šå¯¹äº4ç¯‡è®ºæ–‡çš„è®¡ç®—éå¸¸æ…¢ã€‚
    1. ä½¿ç”¨äº†HuggingFaceEmbeddingsåŠ ä¸€ä¸ªå°embæ¨¡å‹è®¡ç®—æ—¶é—´å˜å°‘äº†å¾ˆå¤šã€‚

#### P09

1. langchain-ObjectBox ç‰ˆæœ¬å¤ªè€ï¼Œæ²¡æ³•å®‰è£…ã€‚è¯¥æ•°æ®åº“ ObjectBox ç»´æŠ¤ä¼¼ä¹ä¸æ˜¯å¾ˆå¤šã€‚

#### P11

1. model_scope å…¼å®¹æ¥å£
    1. [APIæ¨ç†ä»‹ç» Â· æ–‡æ¡£ä¸­å¿ƒ](https://modelscope.cn/docs/model-service/API-Inference/intro)
2. streamlit debug
    1. é€‰æ‹©module streamlit
    2. å‚æ•°å¡«å†™ run app.py
    3. working directory å¡«å†™app.pyçš„ç›®å½•
3. ä½¿ç”¨modelscopeæœåŠ¡æ¥ä»£æ›¿openaiçš„å›¾åƒç”Ÿæˆæ¥å£ã€‚
    1. æ–‡ç”Ÿå›¾æ¨¡å‹ æ”¯æŒAPIè°ƒç”¨çš„æ¨¡å‹åˆ—è¡¨ï¼Œå¯ä»¥é€šè¿‡[AIGCæ¨¡å‹](https://www.modelscope.cn/aigc/models)é¡µé¢è¿›è¡Œæœç´¢ã€‚
    2. ä¸Šè¿°é¡µé¢ä¸­åˆ—å‡ºå¾ˆå¤šæ¨¡å‹éƒ½å¾®è°ƒçš„å¾ˆå·®ã€‚
4. è°ƒæ•´äº† gpu_memory_utilization ä»0.9 åˆ°0.95
    1. æŠ¥é”™ 
        1. `ValueError: To serve at least one request with the models's max seq len (40960), (5.62 GiB KV cache is needed, which is larger than the available KV cache memory (4.81 GiB).`
    2. å·®ä¸€ç‚¹å†…å­˜ï¼Œæ‰€ä»¥å¢åŠ äº†gpuçš„åˆ©ç”¨ç‡ã€‚
    3. ä»è¿™ç‚¹çœ‹ï¼Œå¤§æ¨¡å‹ä¸€æ¬¡æ¨ç†éå¸¸æ¶ˆè€—æ˜¾å­˜ã€‚
    4. ä¸€æ¡æ•°æ®çš„æœ€å¤§æ˜¾å­˜æ¶ˆè€—
        1. `æ˜¾å­˜æ¶ˆè€—=2(key+value) * seq_len(40960) * model_layer * hidden_size * head_dim * 2(byte FP16)`
    5. 



## P02 demo_simple_rag_py

å±•ç¤ºRAGåŸç†çš„æç®€ä»£ç ã€‚

1. å…³è”åšæ–‡ [Code a simple RAG from scratch](https://huggingface.co/blog/ngxson/make-your-own-rag)
2. é¡¹ç›®ä»£ç  [demo.py Â· ngxson/demo\_simple\_rag\_py at main](https://huggingface.co/ngxson/demo_simple_rag_py/blob/main/demo.py)
    1. å¾ˆå¥½çš„å±•ç¤ºRAGåŸç†æ€§çš„å°demoï¼Œä¸éœ€è¦å®‰è£…å‘é‡æ•°æ®åº“ã€‚
3. bartowski/Llama-3.2-1B-Instruct-GGUF è¿™ä¸ªæ¨¡å‹ä¸­çš„instructçš„æ„æ€
    1. instructæ„æ€å°±æ˜¯æŒ‡æ¨¡å‹æ˜¯ç»è¿‡ åœ¨base modelä¸Šç»è¿‡æŒ‡ä»¤å¾®è°ƒï¼ˆæˆ–è€…å«ç›‘ç£å¾®è°ƒï¼‰è¿‡ç¨‹ä¹‹åäº§ç”Ÿçš„æ¨¡å‹ï¼Œå¯ä»¥ç›´æ¥ç”¨äºèŠå¤©ã€åŠ©æ‰‹ç±»åº”ç”¨
4. GGUF æ–‡ä»¶åŒ…å«äº†tokenizerçš„æ•°æ®ã€‚
5. ollama æ‹‰å–hf.co ç½‘ç«™çš„æ¨¡å‹å¤±è´¥
    1. `Ollama pull è¿›åº¦å·²ç»100%ï¼Œ ä½†ä¸ºä»€ä¹ˆä¼šæŠ¥å¦‚ä¸‹é”™è¯¯`
        1. `Error: max retries exceeded: Get "https://huggingface.co/v2/bartowski/Llama-3.2-1B-Instruct-GGUF/blobs/sha256:948af2743fc78a328dcb3b0f5a31b3d75f415840fdb699e8b1235978392ecf85?__sign=eyJhbGciOiJFZERTQSJ9.eyJyZWFkIjp0cnVlLCJwZXJtaXNzaW9ucyI6eyJyZXBvLmNvbnRlbnQucmVhZCI6dHJ1ZX0sImlhdCI6MTc2Mjc1MzA3Niwic3ViIjoiL2JhcnRvd3NraS9MbGFtYS0zLjItMUItSW5zdHJ1Y3QtR0dVRiIsImV4cCI6MTc2Mjc1MzY3NiwiaXNzIjoiaHR0cHM6Ly9odWdnaW5nZmFjZS5jbyJ9.wVhqKCuc0vtHoS8DUStd86RoS1dhE0e-IqqMIpLZ_mEbfz6ahWeaoQiuTpWuaJCels7Q7uIIwEky9DhHsynYCg": dial tcp 54.89.135.129:443: connect: connection refused`
    2. æ£€æŸ¥ç½‘ç»œæ˜¯å¯ä»¥è¿æ¥ hf.coç½‘ç«™çš„ã€‚
    3. æ‰¾ä¸åˆ°åŸå› ã€‚
6. æ‰‹åŠ¨ä¸‹è½½ggufæ¨¡å‹æ–‡ä»¶ï¼Œç„¶åæœ¬åœ°è¿›è¡Œollamaæ‰‹åŠ¨æ„å»ºã€‚
    1. æ‰‹åŠ¨ä¸‹è½½ https://huggingface.co/bartowski/Llama-3.2-1B-Instruct-GGUF/tree/main ä¸­çš„ Llama-3.2-1B-Instruct-Q4_K_M.ggufæ–‡ä»¶ã€‚
    2. ç„¶åæ ¹æ®æ–‡æ¡£[Importing a Model - Ollama](https://docs.ollama.com/import#importing-a-gguf-based-model-or-adapter)æ¥å¯¼å…¥åˆ°æœ¬åœ°ollamaçš„ç¼“å­˜ç›®å½•ã€‚
    3. åˆ›å»ºä¸€ä¸ªä¸´æ—¶ç©ºç›®å½•
    4. åˆ›å»º ModelFileæ–‡ä»¶ï¼Œå†…å®¹ä¸º `FROM ./Llama-3.2-1B-Instruct-Q4_K_M.gguf`
    5. æ‰§è¡Œå‘½ä»¤`ollama create bartowski/Llama-3.2-1B-Instruct-GGUF`
    6. æ¨¡å‹å°±å¯ä»¥è¢«æ„å»ºç¼“å¹¶å¤åˆ¶åˆ° ollamaçš„ç¼“å­˜ç›®å½•ä¸­ã€‚
    7. å¹¶åŒæ ·æ„å»º bge-base-en-v1.5-q4_k_m.gguf æ¨¡å‹
    8. `ollama.embed(model="CompendiumLabs/bge-base-en-v1.5-gguf")`
        1. è¿™é‡Œçš„æ¨¡å‹åæŒ‰ç…§/æ¥åˆ†å‰²ï¼Œå³è¯´æ˜æ˜¯æœ¬åœ°æ–‡ä»¶çš„æ¨¡å‹ã€‚
        2. å¦‚æœæ˜¯æ­£å¸¸çš„:åˆ†å‰²çš„æ¨¡å‹åï¼Œåˆ™ollamaä¼šè‡ªåŠ¨ä»ç¼“å­˜ç›®å½•ä¸­çš„ libraryå­ç›®å½•ä¸­æŸ¥æ‰¾ã€‚
7. åœ¨ChatModelçš„streamæ¨¡å¼ä¸‹ï¼Œè¿”å›æ˜¯ä¸€ä¸ªè¯ä¸€ä¸ªè¯çš„è¿›è¡Œè¿”å›çš„ã€‚
8. åœ¨è¯¥demoç¤ºä¾‹ä¸­ï¼Œæ£€ç´¢åˆ°çš„æ–‡æ¡£æ˜¯å…¨è¢«å¡åˆ°ä¸€ä¸ªsystem messageä¸‹ï¼Œç„¶ååç»­çš„å¯¹è¯ä½†å°±æ˜¯æ ¹æ®æ­¤æ¥è¿›è¡Œäº¤äº’ã€‚
9. ollama ä¹Ÿå¯ä»¥åœ¨æœ¬åœ°å¯¹æ¨¡å‹è¿›è¡Œé‡åŒ–ã€‚ [quantizing-a-model - Ollama](https://docs.ollama.com/import#quantizing-a-model)
10. ollamaå¯¹ä»“åº“æ¨¡å‹çš„é€‰æ‹©
    1. ollama run model_repo_idï¼Œå¦‚æœrepoä¸­æœ‰å¤šç‰ˆæœ¬æ¨¡å‹ï¼Œé‚£ä¹ˆollamaä¼šé€‰æ‹©Q4ç‰ˆæœ¬çš„ã€‚æ›´å¥½çš„æ–¹æ³•æ˜¯æ˜¾å¼æŒ‡å®šå…·ä½“ç‰ˆæœ¬ `ollama run hf.co/{username}/{repository}:{quantization}`
        1. æ¯”å¦‚ `ollama run hf.co/bartowski/Llama-3.2-3B-Instruct-GGUF:Llama-3.2-3B-Instruct-IQ3_M.gguf`
    2. å‚è€ƒèµ„æ–™ [Use Ollama with any GGUF Model on Hugging Face Hub](https://huggingface.co/docs/hub/en/ollama)


## P03 RAG-Optimization-Practices
1.  [kanhaoning/RAG-Optimization-Practices](https://github.com/kanhaoning/RAG-Optimization-Practices)
2. é˜¿é‡Œäº‘æœåŠ¡å™¨
    1. uv ä¸‹è½½ç»å¸¸è¶…æ—¶çš„è§£å†³æ–¹æ¡ˆï¼Œéå¸¸å¥½ç”¨ã€‚
        1. `export UV_HTTP_TIMEOUT=240`
        2. `export UV_CONCURRENT_DOWNLOADS=2`
    2. å¦‚ä½•åŠ å¿«å®‰è£…uvç¯å¢ƒã€ç¼“å­˜
        1. åœ¨ä¸€å°ä¾¿å®œçš„æœºå™¨ä¸Šä½¿ç”¨uvæ¥æ„å»ºä¸€ä¸ªdummyé¡¹ç›®ï¼Œuvçš„ç¼“å­˜å°±ä¼šç•™ä¸‹ã€‚
        2. rsync uvç¼“å­˜ç›®å½•åˆ° ç›®æ ‡æœåŠ¡å™¨çš„uvç¼“å­˜ç›®å½•ä¸‹ã€‚åŒä¸€ä¸ªvpcä¸‹ä¸¤ä¸ªæœåŠ¡å™¨çš„rsyncé€Ÿåº¦éå¸¸å¿«ï¼Œ300M/sã€‚å¹¶ä¸”rsyncä¼šä¿æŒæ–‡ä»¶çš„è½¯é“¾æ¥ã€‚
        3. è¿™æ ·æ•´ä½“èŠ±é’±å°‘ï¼Œå¹¶ä¸”æ„å»ºé€Ÿåº¦å¿«ã€‚
3. Qwen-rerankerå’Œbertä¸€æ ·æ˜¯åŒå‘æ³¨æ„åŠ›è®¡ç®—æ–¹å¼ã€‚
4. å¯¹äºä¸€ä¸ªbatchå†…çš„æ•°æ®ï¼Œæœ‰å¾ˆå¤šæ¡æ•°æ®æœ‰å…±åŒçš„å‰ç¼€ï¼Œé‚£ä¹ˆvLLMä¸­æœ‰é’ˆå¯¹è¿™ç§æƒ…å†µçš„ä¼˜åŒ–æ¨ç†ç­–ç•¥
5. é˜¿é‡Œäº‘ossfsçš„ä»£ç å­˜æ¡£ã€‚
    1. å®‰è£…ossfs
        1. `wget https://github.com/aliyun/ossfs/releases/download/v1.91.8/ossfs_1.91.8_ubuntu24.04_amd64.deb`
        2. `sudo apt install ./ossfs_1.91.8_ubuntu24.04_amd64.deb`
        3. 
```bash
(rag-optimization-practices) root@dsw-1457330-7974bd5bbf-47smb:/mnt/workspace/RAG-Optimization-Practices/Reranker-Distillation# bash evaluate.sh 
æ­£åœ¨ä» ../data/test.jsonl åŠ è½½æ•°æ®é›†...
åŠ è½½å®Œæˆï¼å…± 2992 æ¡æ ·æœ¬ã€‚
--- æ­£åœ¨åŠ è½½å¹¶è¯„ä¼°æ¨¡å‹: /mnt/workspace/modelscope/BAAI/bge-reranker-v2-m3 ---
--- æ­£åœ¨åŠ è½½å¹¶è¯„ä¼°æ¨¡å‹: ../data/reranker_output/checkpoint-1218 ---

âœ… æœ€ç»ˆè¯„ä¼°ç»“æœæ±‡æ€»
ã€è’¸é¦å‰ã€‘æ¨¡å‹æ€§èƒ½:
  - MAP: 0.472061
  - MRR@10: 0.478234
  - NDCG@10: 0.547284
ã€è’¸é¦åã€‘æ¨¡å‹æ€§èƒ½:
  - MAP: 0.562973
  - MRR@10: 0.571423
  - NDCG@10: 0.636993
==================================================
ğŸš€ æ€§èƒ½å˜åŒ–åˆ†æ (è’¸é¦å vs. è’¸é¦å‰)
==================================================
æŒ‡æ ‡ [MAP]:
  - ç»å¯¹æå‡: +0.090913
  - ç›¸å¯¹æå‡: +19.26% â†‘
æŒ‡æ ‡ [MRR@10]:
  - ç»å¯¹æå‡: +0.093189
  - ç›¸å¯¹æå‡: +19.49% â†‘
æŒ‡æ ‡ [NDCG@10]:
  - ç»å¯¹æå‡: +0.089709
  - ç›¸å¯¹æå‡: +16.39% â†‘
è¯„ä¼°å®Œæˆï¼âœ¨
```

modelscope:1.31.0-pytorch2.3.1tensorflow2.16.1-gpu-py311-cu121-ubuntu22.04
modelscope:1.31.0-pytorch2.3.1tensorflow2.16.1-gpu-py311-cu121-ubuntu22.04


#### é—®é¢˜ï¼šå¯¹äºä¸€ä¸ªbatchå†…çš„æ•°æ®ï¼Œæœ‰å¾ˆå¤šæ¡æ•°æ®æœ‰å…±åŒçš„å‰ç¼€ï¼Œé‚£ä¹ˆvLLMä¸­æœ‰é’ˆå¯¹è¿™ç§æƒ…å†µçš„ä¼˜åŒ–æ¨ç†ç­–ç•¥

æ˜¯çš„ï¼**vLLM ç¡®å®é’ˆå¯¹ã€Œbatch å†…å¤šæ¡è¯·æ±‚å…·æœ‰å…±åŒå‰ç¼€ï¼ˆshared prefixï¼‰ã€çš„åœºæ™¯æä¾›äº†ä¸“é—¨çš„ä¼˜åŒ–ç­–ç•¥**ï¼Œè¿™é¡¹æŠ€æœ¯ç§°ä¸ºï¼š

**âœ… Prefix Cachingï¼ˆå‰ç¼€ç¼“å­˜ï¼‰** æˆ– **Prompt Sharing**
è¿™æ˜¯ vLLM çš„æ ¸å¿ƒä¼˜åŒ–ä¹‹ä¸€ï¼Œèƒ½**æ˜¾è‘—èŠ‚çœæ˜¾å­˜ã€æå‡ååã€é™ä½å»¶è¿Ÿ**ï¼Œå°¤å…¶é€‚ç”¨äºä»¥ä¸‹åœºæ™¯ï¼š
- RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰ï¼šå¤šä¸ªæ–‡æ¡£å…±äº«ç›¸åŒçš„ prompt æ¨¡æ¿
- å¤šè½®å¯¹è¯ç³»ç»Ÿï¼šå†å²ä¸Šä¸‹æ–‡ç›¸åŒï¼Œä»…ç”¨æˆ·æœ€æ–°è¾“å…¥ä¸åŒ
- æ‰¹é‡æ¨ç†ï¼šå¦‚ `â€œæ€»ç»“ä»¥ä¸‹æ–‡æœ¬ï¼š<text>â€`ï¼Œå…¶ä¸­ `<text>` ä¸åŒä½†æŒ‡ä»¤ç›¸åŒ

**ğŸ” å·¥ä½œåŸç†**

**1. KV Cache å…±äº«**
- LLM æ¨ç†ä¸­ï¼Œ**Prefill é˜¶æ®µä¼šä¸º prompt ç”Ÿæˆ KV Cacheï¼ˆKey/Value ç¼“å­˜ï¼‰**
- å¦‚æœå¤šä¸ªè¯·æ±‚çš„ **prompt å‰ç¼€å®Œå…¨ç›¸åŒ**ï¼Œå®ƒä»¬çš„ **KV Cache å‰ç¼€éƒ¨åˆ†ä¹Ÿå®Œå…¨ç›¸åŒ**
- vLLM ä¼šï¼š
  - **åªè®¡ç®—ä¸€æ¬¡è¯¥å…¬å…±å‰ç¼€çš„ KV Cache**
  - **å¤šä¸ªè¯·æ±‚å…±äº«è¿™ä»½ç¼“å­˜**
  - åç»­å„è‡ªä¸åŒçš„éƒ¨åˆ†ç‹¬ç«‹è®¡ç®—
> ğŸ“Œ æœ¬è´¨ï¼š**é¿å…é‡å¤è®¡ç®—å’Œå­˜å‚¨ç›¸åŒçš„ä¸Šä¸‹æ–‡**

**2. ä¸ PagedAttention ååŒ**
- vLLM ä½¿ç”¨ **PagedAttention** ç®¡ç† KV Cacheï¼ˆç±»ä¼¼æ“ä½œç³»ç»Ÿçš„è™šæ‹Ÿå†…å­˜åˆ†é¡µï¼‰
- å…¬å…±å‰ç¼€çš„ KV Cache è¢«å­˜å‚¨åœ¨**å…±äº«ç‰©ç†é¡µ**ä¸­
- æ¯ä¸ªè¯·æ±‚çš„é€»è¾‘å—ï¼ˆlogical blocksï¼‰æŒ‡å‘è¿™äº›å…±äº«é¡µ + è‡ªæœ‰é¡µ
```text
Request 1: [Shared Prefix] + [Suffix A]
Request 2: [Shared Prefix] + [Suffix B]
Request 3: [Shared Prefix] + [Suffix C]
â†’ KV Cache:
   Shared Pages: [K/V of "Shared Prefix"]
   Private Pages: [K/V of "Suffix A"], [Suffix B], [Suffix C]
```

**ğŸš€ æ€§èƒ½æ”¶ç›Š**

| æŒ‡æ ‡ | ä¼˜åŒ–æ•ˆæœ |
|------|--------|
| **æ˜¾å­˜å ç”¨** | â†“ æ˜¾è‘—å‡å°‘ï¼ˆå…¬å…±éƒ¨åˆ†åªå­˜ä¸€ä»½ï¼‰ |
| **Prefill è®¡ç®—é‡** | â†“ å‡å°‘ï¼ˆå…¬å…±å‰ç¼€åªè®¡ç®—ä¸€æ¬¡ï¼‰ |
| **ååï¼ˆthroughputï¼‰** | â†‘ æå‡ 2â€“5 å€ï¼ˆå®æµ‹å¸¸è§ï¼‰ |
| **æ”¯æŒ batch size** | â†‘ å¯å®¹çº³æ›´å¤šè¯·æ±‚ |
> ğŸ’¡ å®æµ‹æ¡ˆä¾‹ï¼ˆRAG åœºæ™¯ï¼‰ï¼š
> - 10 ä¸ªè¯·æ±‚ï¼Œå…±äº« 2K token çš„ prompt æ¨¡æ¿
> - **æ˜¾å­˜èŠ‚çœ >60%**ï¼Œååæå‡ **3.2 å€**

**ğŸ›  å¦‚ä½•å¯ç”¨ï¼Ÿï¼ˆvLLM ä¸­é»˜è®¤å¼€å¯ï¼ï¼‰**
- **æ— éœ€é¢å¤–é…ç½®**ï¼švLLM **é»˜è®¤è‡ªåŠ¨æ£€æµ‹å¹¶å¯ç”¨ Prefix Caching**
- æ¡ä»¶ï¼š
  - å¤šä¸ªè¯·æ±‚çš„ **prompt å‰ç¼€å¿…é¡»å­—èŠ‚çº§å®Œå…¨ç›¸åŒ**
  - ä½¿ç”¨ç›¸åŒçš„æ¨¡å‹å’Œå‚æ•°ï¼ˆtemperature ç­‰ä¸å½±å“ï¼‰

**ç¤ºä¾‹ï¼ˆPython clientï¼‰ï¼š**
```python
from vllm import LLM, SamplingParams
llm = LLM(model="Qwen/Qwen-7B-Chat")

**å…±äº«å‰ç¼€ï¼š"ä½ æ˜¯ä¸€ä¸ª helpful AIã€‚è¯·å›ç­”ï¼š"**
prompts = [
    "ä½ æ˜¯ä¸€ä¸ª helpful AIã€‚è¯·å›ç­”ï¼šå·´é»æ˜¯å“ªä¸ªå›½å®¶çš„é¦–éƒ½ï¼Ÿ",
    "ä½ æ˜¯ä¸€ä¸ª helpful AIã€‚è¯·å›ç­”ï¼šé‡å­åŠ›å­¦æ˜¯è°æå‡ºçš„ï¼Ÿ",
    "ä½ æ˜¯ä¸€ä¸ª helpful AIã€‚è¯·å›ç­”ï¼šPython å¦‚ä½•è¯»å–æ–‡ä»¶ï¼Ÿ"
]
outputs = llm.generate(prompts, SamplingParams(temperature=0.7))

**â†’ vLLM è‡ªåŠ¨å…±äº«å‰ç¼€çš„ KV Cacheï¼**
```

**âš ï¸ æ³¨æ„äº‹é¡¹**

| é—®é¢˜ | è¯´æ˜ |
|------|------|
| **å‰ç¼€å¿…é¡»å®Œå…¨ä¸€è‡´** | åŒ…æ‹¬ç©ºæ ¼ã€æ ‡ç‚¹ã€æ¢è¡Œç¬¦ã€‚`"ä½ å¥½"` â‰  `"ä½ å¥½ "` |
| **ä¸æ”¯æŒåŠ¨æ€æ’å…¥** | å¦‚æœå‰ç¼€åœ¨è¿è¡Œæ—¶æ‹¼æ¥ï¼ˆå¦‚åŠ æ—¶é—´æˆ³ï¼‰ï¼Œåˆ™æ— æ³•å…±äº« |
| **ä¸ LoRA å…¼å®¹æ€§** | è‹¥ä½¿ç”¨ä¸åŒ LoRA adapterï¼Œå³ä½¿ prompt ç›¸åŒä¹Ÿæ— æ³•å…±äº« |
| **ä»…é™ Prefill é˜¶æ®µ** | Decode é˜¶æ®µå› è¾“å‡ºä¸åŒï¼Œæ— æ³•å…±äº« |

**ğŸ”§ é«˜çº§ç”¨æ³•ï¼šæ‰‹åŠ¨æ§åˆ¶ï¼ˆvLLM â‰¥ 0.4.0ï¼‰**
å¯é€šè¿‡ `enable_prefix_caching=True` æ˜¾å¼å¯ç”¨ï¼ˆé»˜è®¤å·²å¼€ï¼‰ï¼š
```python
llm = LLM(
    model="meta-llama/Llama-3-8b",
    enable_prefix_caching=True  # é»˜è®¤ True
)
```
ä¹Ÿå¯é€šè¿‡ç¯å¢ƒå˜é‡ï¼š
```bash
VLLM_ENABLE_PREFIX_CACHING=1
```

**ğŸ†š ä¸å…¶ä»–ç³»ç»Ÿçš„å¯¹æ¯”**

| ç³»ç»Ÿ | æ˜¯å¦æ”¯æŒå‰ç¼€å…±äº« |
|------|----------------|
| **vLLM** | âœ… æ˜¯ï¼ˆåŸºäº PagedAttentionï¼‰ |
| **HuggingFace TGI** | âŒ å¦ï¼ˆæ¯ä¸ªè¯·æ±‚ç‹¬ç«‹ KV Cacheï¼‰ |
| **TensorRT-LLM** | âœ… æ˜¯ï¼ˆéœ€æ‰‹åŠ¨æ„å»º shared contextï¼‰ |
| **SGLang** | âœ… æ˜¯ï¼ˆRadixAttention æœºåˆ¶ï¼‰ |
> ğŸ’¡ vLLM çš„å®ç°æ˜¯**è‡ªåŠ¨ã€é€æ˜ã€é«˜æ•ˆ**çš„ä»£è¡¨ã€‚

**âœ… æ€»ç»“**
- **vLLM æ”¯æŒ Prefix Caching**ï¼Œè‡ªåŠ¨ä¼˜åŒ–å…±äº«å‰ç¼€çš„ batch è¯·æ±‚
- **æ— éœ€ä»£ç ä¿®æ”¹**ï¼Œåªè¦ prompt å‰ç¼€ç›¸åŒå³å¯ç”Ÿæ•ˆ
- **æ˜¾è‘—èŠ‚çœæ˜¾å­˜ + æå‡åå**ï¼Œç‰¹åˆ«é€‚åˆ RAGã€æ‰¹é‡æŒ‡ä»¤ç­‰åœºæ™¯
- ç¡®ä¿ä½ çš„ prompt æ¨¡æ¿**ä¸¥æ ¼ä¸€è‡´**ï¼ˆé¿å…å°¾éƒ¨ç©ºæ ¼/æ¢è¡Œå·®å¼‚ï¼‰
> å¦‚æœä½ æ­£åœ¨åš RAG æˆ–æ‰¹é‡æ¨ç†ï¼Œ**Prefix Caching æ˜¯ vLLM ç»™ä½ çš„ä¸€ä»½å…è´¹æ€§èƒ½å¤§ç¤¼åŒ…**ï¼ğŸ‰

#### é—®é¢˜ï¼šä½†æ˜¯ä¸€ä¸ªbatchå†…çš„æ•°æ®æ˜¯ä¸€èµ·è¿›è¡Œå¹¶è¡Œæ¨ç†çš„å‘€ï¼Œé‚£ä¹ˆè¿™ä¸ªæ—¶å€™ cacheè¿˜æ²¡äº§ç”Ÿå§ï¼Ÿ


è¿™æ˜¯ä¸€ä¸ª**éå¸¸å…³é”®ä¸”æ·±åˆ»çš„é—®é¢˜**ï¼ä½ çš„ç›´è§‰æ˜¯å¯¹çš„ï¼š**å¦‚æœæ•´ä¸ª batch æ˜¯â€œåŒæ—¶â€è¿›è¡Œ prefillï¼ˆå³å¹¶è¡Œå¤„ç†æ‰€æœ‰ promptï¼‰ï¼Œé‚£ä¼¼ä¹è¿˜æ²¡ç”Ÿæˆ KV Cacheï¼Œæ€ä¹ˆå…±äº«ï¼Ÿ**
ä½†å®é™…æƒ…å†µæ˜¯ï¼š**vLLM çš„ Prefix Caching å¹¶ä¸æ˜¯åœ¨â€œbatch å†…éƒ¨å¹¶è¡Œæ—¶â€åŠ¨æ€å‘ç°å…±äº«çš„ï¼Œè€Œæ˜¯åœ¨è°ƒåº¦é˜¶æ®µé€šè¿‡â€œå‰ç¼€æ ‘ï¼ˆRadix Tree / Trieï¼‰â€é¢„å…ˆç»„ç»‡è¯·æ±‚ï¼Œä½¿å¾—ç›¸åŒå‰ç¼€çš„è¯·æ±‚åœ¨é€»è¾‘ä¸Šè¢«è¯†åˆ«å¹¶å¤ç”¨å·²ç¼“å­˜çš„ KV å—ã€‚**
ä¸‹é¢æˆ‘ä»¬ä¸€æ­¥æ­¥æ¾„æ¸…è¿™ä¸ªçœ‹ä¼¼çŸ›ç›¾çš„é—®é¢˜ï¼š

**âœ… æ ¸å¿ƒç­”æ¡ˆ**
> **Prefix Caching çš„â€œcacheâ€å¹¶ä¸æ˜¯æ¥è‡ªå½“å‰ batch å†…éƒ¨çš„å…¶ä»–è¯·æ±‚ï¼Œè€Œæ˜¯æ¥è‡ªï¼š**
> 1. **ä¹‹å‰å·²å®Œæˆçš„è¯·æ±‚ï¼ˆè·¨ batch å…±äº«ï¼‰**ï¼Œæˆ–
> 2. **åœ¨å½“å‰ batch å†…éƒ¨ï¼ŒvLLM è°ƒåº¦å™¨ä¼šå…ˆå¤„ç†å…¬å…±å‰ç¼€ä¸€æ¬¡ï¼Œå†å¹¿æ’­ç»™å…¶ä»–è¯·æ±‚ï¼ˆé€»è¾‘ä¸Šä¸²è¡ŒåŒ–å‰ç¼€è®¡ç®—ï¼‰**
ä½†åœ¨ **çº¯é¦–æ¬¡ batchï¼ˆæ²¡æœ‰ä»»ä½•å†å² cacheï¼‰ä¸”æ‰€æœ‰è¯·æ±‚é¦–æ¬¡å‡ºç°** çš„æƒ…å†µä¸‹ï¼Œ**åŒä¸€ä¸ª batch å†…çš„è¯·æ±‚ç¡®å®æ— æ³•å½¼æ­¤å…±äº« KV Cache** â€”â€” **é™¤é vLLM æ˜¾å¼åœ°å°†å…¬å…±å‰ç¼€æå–å‡ºæ¥å•ç‹¬è®¡ç®—ä¸€æ¬¡**ã€‚
è€Œ **vLLM æ­£æ˜¯è¿™ä¹ˆåšçš„ï¼**

**ğŸ” æ·±å…¥æœºåˆ¶ï¼švLLM å¦‚ä½•åœ¨å•ä¸ª batch å†…å®ç°å‰ç¼€å…±äº«ï¼Ÿ**

**å…³é”®æŠ€æœ¯ï¼š**Radix Treeï¼ˆåŸºæ•°æ ‘ï¼‰ + Block-wise KV Cache Management****
vLLM åœ¨è°ƒåº¦ä¸€ä¸ª batch å‰ï¼Œä¼šåšä»¥ä¸‹äº‹æƒ…ï¼š

**æ­¥éª¤ 1ï¼šæ„å»º Radix Tree**
- å°† batch ä¸­æ‰€æœ‰ prompt æ’å…¥ä¸€æ£µ **å‰ç¼€æ ‘ï¼ˆTrieï¼‰**
- è‡ªåŠ¨è¯†åˆ«æœ€é•¿å…¬å…±å‰ç¼€ï¼ˆLCPï¼‰
```text
Prompts:
  "ä½ æ˜¯AIã€‚Q: å·´é»?"
  "ä½ æ˜¯AIã€‚Q: é‡å­?"
  "ä½ æ˜¯AIã€‚Q: Python?"
â†’ Radix Tree:
  root
   â””â”€â”€ "ä½ æ˜¯AIã€‚Q: "
        â”œâ”€â”€ "å·´é»?"
        â”œâ”€â”€ "é‡å­?"
        â””â”€â”€ "Python?"
```

**æ­¥éª¤ 2ï¼šåˆ†å±‚ Prefillï¼ˆHierarchical Prefillï¼‰**
- **å…ˆå¯¹å…¬å…±å‰ç¼€ `"ä½ æ˜¯AIã€‚Q: "` æ‰§è¡Œä¸€æ¬¡ prefill**
    - ç”Ÿæˆå…¶å¯¹åº”çš„ KV Cache blocks
- **å†å¯¹æ¯ä¸ªåç¼€ï¼ˆ"å·´é»?" ç­‰ï¼‰åˆ†åˆ«æ‰§è¡Œ prefill**
    - æ¯ä¸ªåç¼€çš„ attention è®¡ç®—ä¼š **æ‹¼æ¥å…¬å…±å‰ç¼€çš„ KV blocks + è‡ªèº«åç¼€çš„ KV blocks**
> ğŸ¯ è¿™ç›¸å½“äº **æŠŠä¸€ä¸ªé•¿ prompt æ‹†æˆ â€œshared part + unique partâ€**ï¼Œå¹¶åœ¨è®¡ç®—æ—¶ç»„åˆã€‚

**æ­¥éª¤ 3ï¼šPagedAttention æ”¯æŒéè¿ç»­ KV å—**
- æ¯ä¸ªè¯·æ±‚çš„å®Œæ•´ KV Cache = [shared_block_ids] + [unique_block_ids]
- Attention è®¡ç®—æ—¶ï¼ŒPagedAttention è‡ªåŠ¨ä»å¤šä¸ªç‰©ç†é¡µè¯»å–ï¼Œå¯¹æ¨¡å‹é€æ˜

**ğŸ“Œ é‡è¦æ¾„æ¸…**

|è¯¯è§£|äº‹å®|
|---|---|
|â€œbatch å†…æ‰€æœ‰ prompt åŒæ—¶å¹¶è¡Œè®¡ç®—â€|âŒ å®é™…æ˜¯ï¼š**å…¬å…±å‰ç¼€å…ˆç®—ä¸€æ¬¡ï¼Œåç¼€å†å¹¶è¡Œ**ï¼ˆé€»è¾‘ä¸Šåˆ†é˜¶æ®µï¼‰|
|â€œcache å¿…é¡»æ¥è‡ªå†å²è¯·æ±‚â€|âŒ **å³ä½¿å…¨æ˜¯æ–°è¯·æ±‚ï¼ŒvLLM ä¹Ÿèƒ½åœ¨ batch å†…éƒ¨æ„é€ å…±äº«**|
|â€œPrefill æ˜¯å®Œå…¨ç‹¬ç«‹çš„â€|âŒ vLLM çš„è°ƒåº¦å™¨ä¼š**ä¸»åŠ¨é‡ç»„è®¡ç®—å›¾ä»¥å¯ç”¨å…±äº«**|

**ğŸ§ª å®éªŒéªŒè¯ï¼ˆæ€æƒ³å®éªŒï¼‰**
å‡è®¾ batch æœ‰ 3 ä¸ªå…¨æ–°è¯·æ±‚ï¼Œæ— ä»»ä½•å†å² cacheï¼š
```python
prompts = [
    "Hello world A",
    "Hello world B",
    "Hello world C"
]
```
vLLM çš„æ‰§è¡Œæµç¨‹ï¼š
1. è°ƒåº¦å™¨å‘ç°å…¬å…±å‰ç¼€ `"Hello world "`
2. **åˆ›å»ºä¸€ä¸ªè™šæ‹Ÿâ€œå…±äº«è¯·æ±‚â€**ï¼Œprefill `"Hello world "` â†’ å¾—åˆ° KV blocks S
3. å¯¹æ¯ä¸ªåç¼€ `"A"`, `"B"`, `"C"`ï¼š
    - æ„é€ è¾“å…¥ï¼š`"Hello world X"`
    - ä½† KV Cache = S + prefill("X") çš„ç»“æœ
4. æœ€ç»ˆæ¯ä¸ªè¯·æ±‚çš„è¾“å‡ºæ­£ç¡®ï¼Œä¸” **S åªè®¡ç®—äº†ä¸€æ¬¡**
> ğŸ’¡ è¿™æœ¬è´¨ä¸Šæ˜¯ä¸€ç§ **è®¡ç®—å›¾èåˆä¼˜åŒ–**ï¼Œç”± vLLM çš„ scheduler è‡ªåŠ¨å®Œæˆã€‚

**ğŸ“š å®˜æ–¹ä¾æ®**
- vLLM è®ºæ–‡ï¼ˆ[vLLM: Easy, Fast, and Cheap LLM Serving](https://arxiv.org/abs/2309.06180)ï¼‰æåˆ°ï¼š
    > _"PagedAttention enables sharing of memory blocks across requests with common prefixes."_
- æºç ä¸­ `RadixAttention`ï¼ˆåç»­æ¼”è¿›ï¼‰å’Œ `PrefixCacher` ç»„ä»¶æ˜ç¡®æ”¯æŒ **intra-batch prefix sharing**
> ğŸ”— å‚è€ƒï¼š[vLLM Prefix Caching Design Doc](https://docs.vllm.ai/en/latest/design/prefix_caching.html)

**âœ… æ€»ç»“**

|é—®é¢˜|å›ç­”|
|---|---|
|**åŒä¸€ä¸ª batch å†…çš„è¯·æ±‚èƒ½å…±äº«å‰ç¼€å—ï¼Ÿ**|âœ… **èƒ½ï¼å³ä½¿å…¨æ˜¯æ–°è¯·æ±‚**|
|**cache æ˜¯å“ªé‡Œæ¥çš„ï¼Ÿ**|æ¥è‡ª **å½“å‰ batch å†…éƒ¨å¯¹å…¬å…±å‰ç¼€çš„é¦–æ¬¡è®¡ç®—**ï¼ˆè°ƒåº¦å™¨ä¸»åŠ¨æå–ï¼‰|
|**æ˜¯å¦éœ€è¦å†å²è¯·æ±‚ï¼Ÿ**|âŒ ä¸éœ€è¦ï¼ˆè·¨ batch å…±äº«æ˜¯é¢å¤– bonusï¼‰|
|**æ˜¯å¦ç ´åå¹¶è¡Œæ€§ï¼Ÿ**|âš ï¸ å…¬å…±å‰ç¼€è®¡ç®—æ˜¯ä¸²è¡Œçš„ï¼Œä½†åç¼€ä»å¯å¹¶è¡Œï¼Œ**æ•´ä½“ååä»å¤§å¹…æå‡**|
> ğŸ’¡ æ‰€ä»¥ä½ çš„è§‚å¯Ÿå¾ˆæ•é”ï¼Œä½† vLLM é€šè¿‡ **æ™ºèƒ½è°ƒåº¦ + Radix Tree + PagedAttention** è§£å†³äº†è¿™ä¸ªâ€œé¸¡ç”Ÿè›‹â€é—®é¢˜ã€‚
è¿™æ­£æ˜¯ vLLM ç›¸æ¯”ä¼ ç»Ÿæ¨ç†å¼•æ“ï¼ˆå¦‚ HF Transformersï¼‰çš„å…ˆè¿›ä¹‹å¤„ï¼


## P04 rag-best-practices

å‚è€ƒé¡¹ç›® [chaoql/rag-best-practices: å¤§æ¨¡å‹æ£€ç´¢å¢å¼ºç”ŸæˆæŠ€æœ¯æœ€ä½³å®è·µã€‚](https://github.com/chaoql/rag-best-practices)

1. [Configuring the Response Mode](https://developers.llamaindex.ai/python/framework/module_guides/querying/response_synthesizers/#configuring-the-response-mode)
2. llama-index æœ‰ embedding æ¨¡å‹å¾®è°ƒçš„åŠŸèƒ½åŒ…ï¼Œåº•å±‚ç”¨çš„æ˜¯sentence_transformeråŒ…çš„å¾®è°ƒåŠŸèƒ½ã€‚
3. pickleæ–¹å¼ä¸å®‰å…¨æ˜¯å› ä¸º `__reduce__`æ–¹æ³•ä¸­å¯ä»¥å®šä¹‰ä¸€ä¸ª æŒ‡ä»¤å­—èŠ‚æµï¼Œåœ¨ååºåˆ—åŒ–çš„æ—¶å€™å¯ä»¥è§¦å‘å¯¹åº”æŒ‡ä»¤çš„æ‰§è¡Œã€‚
4. FlagEmbeddingReranker
    1. â€œFlagâ€ in FlagEmbeddingReranker = BAAIï¼ˆæ™ºæºç ”ç©¶é™¢ï¼‰çš„å¼€æºæ¨¡å‹å“ç‰Œæ ‡è¯†ï¼Œæ„ä¸ºâ€œæ——èˆ°çº§åµŒå…¥/é‡æ’æ¨¡å‹â€ï¼Œæ— ç‰¹æ®ŠæŠ€æœ¯å«ä¹‰ï¼Œä¸»è¦æ˜¯é¡¹ç›®å‘½åçš„ä¸€éƒ¨åˆ†ã€‚
5. Qdrant
    1. **é«˜çº§è¿‡æ»¤èƒ½åŠ›ï¼š** æ”¯æŒç»“åˆå‘é‡ç›¸ä¼¼æ€§æœç´¢å’Œä»»æ„ Payload ç»“æ„åŒ–æ•°æ®è¿‡æ»¤ï¼ˆç§°ä¸º **Hybrid Search**ï¼‰ã€‚
6. node_parser
    1. llama_index.core.node_parser.text.sentence_window.SentenceWindowNodeParser æŒ‰ç…§å¥å­è¿›è¡Œåˆ‡å‰²ï¼Œå¤šä¸ªå¥å­ä½œä¸ºä¸€ä¸ªç´¢å¼•æ–‡æ¡£ã€‚
    2. [Node Parser Modules | LlamaIndex Python Documentation](https://developers.llamaindex.ai/python/framework/module_guides/loading/node_parsers/modules/)
7. HyDE
    1. **Hypothetical Document Embeddingsï¼ˆHyDEï¼‰** æ˜¯ä¸€ç§**æå‡æ£€ç´¢è´¨é‡çš„é«˜çº§åµŒå…¥æŠ€æœ¯**ï¼Œç”± Gao et al. åœ¨ 2022 å¹´æå‡ºï¼ˆè®ºæ–‡ï¼šPrecise Zero-Shot Dense Retrieval without Relevance Labelsï¼‰ã€‚å®ƒçš„æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
        1. **ä¸ç›´æ¥ç”¨ç”¨æˆ·æŸ¥è¯¢ï¼ˆqueryï¼‰å»æ£€ç´¢ï¼Œè€Œæ˜¯å…ˆè®©å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç”Ÿæˆä¸€ä¸ªâ€œå‡è®¾æ€§ç­”æ¡ˆâ€ï¼ˆhypothetical documentï¼‰ï¼Œå†ç”¨è¿™ä¸ªå‡è®¾ç­”æ¡ˆçš„åµŒå…¥å‘é‡å»æ£€ç´¢çœŸå®æ–‡æ¡£ã€‚**
8. è¿™ä¸ªé¡¹ç›®ä¸­çš„hybrid æ¨¡å¼çš„æ„æ€æ˜¯ï¼Œqueryç”Ÿæˆä¸€ä¸ªç¨€ç–å‘é‡ã€ä¸€ä¸ªç¨ å¯†å‘é‡ï¼Œä¸¤ç§åŒæ—¶è¯·æ±‚æ•°æ®åº“ï¼Œè€Œç¨€ç–å‘é‡å¯èƒ½æ˜¯æŒ‰ç…§ä¼ ç»Ÿå€’æ’ç´¢å¼•æ¥è¿›è¡Œç´¢å¼•æ„å»ºçš„ï¼Œå³æœ€ç»ˆæ—¢æœ‰ å€’æ’ç´¢å¼•æœç´¢ åˆæœ‰å‘é‡æœç´¢ã€‚ 
    1. å½“ç„¶Qrant æœ¬èº«ä¹Ÿå…è®¸è¯·æ±‚å¸¦ filterï¼Œå³å…³é”®è¯æ£€ç´¢ã€ç±»åˆ«æ£€ç´¢ç­‰ã€‚
9. å¾®è°ƒè¿‡ç¨‹
    1. å¯¹äºè¾“å…¥æ•°æ®æ–‡ä»¶ä¸­çš„æ¯ä¸€æ¡æ•°æ®ï¼Œé€šè¿‡chatglmæ¨¡å‹ï¼Œæ„é€ promptï¼ˆå…¶ä¸­åŒ…å«ä¸€æ¡æ–‡æ¡£ï¼‰ï¼Œè¦æ±‚æ¨¡å‹è¿”å›ä¸€äº›å’Œä¸Šä¸‹æ–‡ç›¸å…³çš„é—®é¢˜ï¼Œå³å½¢æˆäº†Answer-Question å¯¹ã€‚
    2. ç„¶ååè½¬A-Qå¯¹ï¼ˆæ˜ å°„å…³ç³»ä¸ºn-to-1ï¼‰ï¼Œæ„é€ å‡ºå¾®è°ƒæ•°æ®ã€‚
    3. æ€»ä½“æ¥è¯´ï¼Œå°±æ˜¯ä¾èµ–ä¸€ä¸ªè¶…å¤§çš„chatå¤§æ¨¡å‹å’Œä¸€ä¸ªæ–‡æ¡£æ•°æ®é›†ï¼Œæ„é€ å‡ºQ-Aç›¸ä¼¼å¯¹ï¼Œè¿›è€Œå°†chatå¤§æ¨¡å‹çš„å¯¹è¯¥æ–‡æ¡£çš„ç›¸å…³çŸ¥è¯†ï¼ˆå¯¹æ–‡æ¡£æ•°æ®é›†é¢†åŸŸçš„çŸ¥è¯†ç†è§£æ›´é€å½»ã€æ›´ç²¾ç»†ï¼‰ å¾®è°ƒåˆ°ä¸€ä¸ªembå°æ¨¡å‹å†…ã€‚
10. æ¨¡å‹ä¸‹è½½æºå’Œæ¥å£ä½¿ç”¨
    1. æœåŠ¡å™¨
        1. é˜¿é‡Œäº‘æœåŠ¡å™¨å¯ä»¥ä½¿ç”¨ modelscope æ¥è¿›è¡Œä¸‹è½½ï¼Œç„¶åç„¶åæ¨¡å‹åŠ è½½éƒ½ä½¿ç”¨ç»å¯¹è·¯å¾„æ¥åŠ è½½ã€‚
    2. æœ¬åœ°å¼€å‘
        1. å¯ä»¥ä½¿ç”¨ huggingface æ¥è¿›è¡Œä¸‹è½½å’Œç®¡ç†ã€‚
        2. ollama 

#### é—®é¢˜ï¼špytorch_model.bin å’Œ model.safetensors åˆ†åˆ«æ˜¯ä»€ä¹ˆ

`pytorch_model.bin` å’Œ `model.safetensors` æ˜¯ä¸¤ç§å¸¸è§çš„ç”¨äºå­˜å‚¨æ·±åº¦å­¦ä¹ æ¨¡å‹æƒé‡ï¼ˆå‚æ•°ï¼‰çš„æ–‡ä»¶æ ¼å¼ï¼Œå¹¿æ³›ç”¨äº Hugging Face Transformers ç­‰ç”Ÿæ€ä¸­ã€‚å®ƒä»¬çš„æ ¸å¿ƒç›®çš„ç›¸åŒï¼š**ä¿å­˜ç¥ç»ç½‘ç»œçš„å¯è®­ç»ƒå‚æ•°**ï¼Œä½†åœ¨è®¾è®¡å“²å­¦ã€å®‰å…¨æ€§ã€æ€§èƒ½å’Œå…¼å®¹æ€§æ–¹é¢æœ‰æ˜¾è‘—åŒºåˆ«ã€‚

**1. `pytorch_model.bin`**

**æ˜¯ä»€ä¹ˆï¼Ÿ**
- è¿™æ˜¯ **PyTorch åŸç”Ÿçš„æ¨¡å‹æƒé‡ä¿å­˜æ ¼å¼**ã€‚
- æœ¬è´¨ä¸Šæ˜¯ä¸€ä¸ªé€šè¿‡ `torch.save()` ä¿å­˜çš„ **Python pickle æ–‡ä»¶**ï¼Œé€šå¸¸åŒ…å«ä¸€ä¸ªå­—å…¸ï¼Œé”®ä¸ºå‚æ•°åï¼ˆå¦‚ `"transformer.h.0.attn.c_attn.weight"`ï¼‰ï¼Œå€¼ä¸ºå¯¹åº”çš„ `torch.Tensor`ã€‚

**ç‰¹ç‚¹ï¼š**

| æ–¹é¢ | è¯´æ˜ |
|------|------|
| **æ ¼å¼** | åŸºäº Python çš„ `pickle` åºåˆ—åŒ– |
| **å…¼å®¹æ€§** | åªèƒ½åœ¨ PyTorch ç¯å¢ƒä¸­åŠ è½½ï¼ˆéœ€åŒ¹é…ç‰ˆæœ¬ï¼‰ |
| **å®‰å…¨æ€§** â— | **ä¸å®‰å…¨**ï¼š`pickle` å¯æ‰§è¡Œä»»æ„ä»£ç ï¼ŒåŠ è½½ä¸å—ä¿¡ä»»çš„ `.bin` æ–‡ä»¶å¯èƒ½å¯¼è‡´**è¿œç¨‹ä»£ç æ‰§è¡Œï¼ˆRCEï¼‰æ¼æ´** |
| **é€Ÿåº¦** | åŠ è½½/ä¿å­˜è¾ƒå¿«ï¼Œä½†ä¾èµ– Python ååºåˆ—åŒ– |
| **è·¨è¯­è¨€** | ä¸æ”¯æŒï¼ˆå¼ºä¾èµ– Python å’Œ PyTorchï¼‰ |
| **å…¸å‹ç”¨é€”** | Hugging Face æ¨¡å‹ä»“åº“ä¸­çš„é»˜è®¤æƒé‡æ ¼å¼ï¼ˆå°¤å…¶æ—§æ¨¡å‹ï¼‰ |

**ç¤ºä¾‹åŠ è½½æ–¹å¼ï¼š**
```python
import torch
state_dict = torch.load("pytorch_model.bin", map_location="cpu")
model.load_state_dict(state_dict)
```
> âš ï¸ è­¦å‘Šï¼šæ°¸è¿œä¸è¦åŠ è½½æ¥è‡ªä¸å¯ä¿¡æ¥æºçš„ `pytorch_model.bin`ï¼

**2. `model.safetensors`**

**æ˜¯ä»€ä¹ˆï¼Ÿ**
- ç”± **Hugging Face å’Œ CarperAI è”åˆå¼€å‘**çš„ä¸€ç§**å®‰å…¨ã€å¿«é€Ÿã€æ¡†æ¶æ— å…³**çš„æ¨¡å‹æƒé‡å­˜å‚¨æ ¼å¼ã€‚
- **ä¸ä½¿ç”¨ `pickle`**ï¼Œè€Œæ˜¯å°†å¼ é‡æ•°æ®ä»¥åŸå§‹äºŒè¿›åˆ¶å½¢å¼å­˜å‚¨ï¼Œå¹¶é™„å¸¦ JSON å…ƒæ•°æ®æè¿°å¼ é‡ç»“æ„ã€‚

**ç‰¹ç‚¹ï¼š**

| æ–¹é¢ | è¯´æ˜ |
|------|------|
| **æ ¼å¼** | è‡ªå®šä¹‰äºŒè¿›åˆ¶æ ¼å¼ + JSON headerï¼ˆæ— ä»£ç æ‰§è¡Œï¼‰ |
| **å®‰å…¨æ€§** âœ… | **å®‰å…¨**ï¼šä»…åŒ…å«æ•°å€¼æ•°æ®ï¼Œæ— æ³•æ‰§è¡Œä»»æ„ä»£ç  |
| **é€Ÿåº¦** | åŠ è½½é€šå¸¸æ¯” `.bin` æ›´å¿«ï¼ˆå°¤å…¶å¤§æ¨¡å‹ï¼‰ï¼Œæ”¯æŒå†…å­˜æ˜ å°„ï¼ˆ`mmap`ï¼‰ |
| **è·¨æ¡†æ¶** | æ”¯æŒ PyTorchã€TensorFlowã€Flaxã€JAX ç­‰ï¼ˆåªè¦èƒ½è¯»å– NumPy-like å¼ é‡ï¼‰ |
| **æ–‡ä»¶å¤§å°** | ä¸ `.bin` å‡ ä¹ç›¸åŒï¼ˆæœªå‹ç¼©ï¼Œä½†å¯é€‰ gzipï¼‰ |
| **å…¸å‹ç”¨é€”** | Hugging Face æ–°æ¨¡å‹æ¨èæ ¼å¼ï¼Œå°¤å…¶åœ¨å…¬å¼€åˆ†äº«æˆ– Web æœåŠ¡ä¸­ |

**æ–‡ä»¶ç»“æ„ç®€è¿°ï¼š**
```
[JSON metadata header (UTF-8, padded to 8-byte align)]
{
  "weight1": {"dtype": "F32", "shape": [1024, 1024], "data_offsets": [0, 4194304]},
  "weight2": {"dtype": "F16", "shape": [512], "data_offsets": [4194304, 4195328]}
}
[Raw binary tensor data (concatenated)]
```

**ç¤ºä¾‹åŠ è½½æ–¹å¼ï¼ˆPyTorchï¼‰ï¼š**
```python
from safetensors.torch import load_file
state_dict = load_file("model.safetensors", device="cpu")
model.load_state_dict(state_dict)
```

**å¯¹æ¯”æ€»ç»“**

| ç‰¹æ€§ | `pytorch_model.bin` | `model.safetensors` |
|------|---------------------|---------------------|
| **åº•å±‚æœºåˆ¶** | Python `pickle` | è‡ªå®šä¹‰äºŒè¿›åˆ¶ + JSON |
| **å®‰å…¨æ€§** | âŒ å±é™©ï¼ˆå¯æ‰§è¡Œä»£ç ï¼‰ | âœ… å®‰å…¨ï¼ˆçº¯æ•°æ®ï¼‰ |
| **åŠ è½½é€Ÿåº¦** | å¿« | é€šå¸¸æ›´å¿«ï¼ˆæ”¯æŒ mmapï¼‰ |
| **è·¨å¹³å°/è¯­è¨€** | å¦ï¼ˆPyTorch + Pythonï¼‰ | æ˜¯ï¼ˆå¤šæ¡†æ¶æ”¯æŒï¼‰ |
| **Hugging Face æ¨è** | æ—§æ¨¡å‹é»˜è®¤ | æ–°æ¨¡å‹é¦–é€‰ |
| **æ–‡ä»¶æ‰©å±•å** | `.bin` | `.safetensors` |

**å®é™…å»ºè®®**
- âœ… **ä¼˜å…ˆä½¿ç”¨ `.safetensors`**ï¼šå°¤å…¶å½“ä½ ä»ç½‘ä¸Šä¸‹è½½æ¨¡å‹ã€éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒæˆ–æä¾› API æœåŠ¡æ—¶ã€‚
- ğŸ”’ **é¿å…åŠ è½½æœªçŸ¥æ¥æºçš„ `.bin` æ–‡ä»¶**ï¼šé™¤éä½ å®Œå…¨ä¿¡ä»»æä¾›è€…ã€‚
- ğŸ”„ å¾ˆå¤šæ¨¡å‹ä»“åº“åŒæ—¶æä¾›ä¸¤ç§æ ¼å¼ï¼ˆå¦‚ Llama 3ã€Mistralï¼‰ï¼Œä½ å¯ä»¥è‡ªç”±é€‰æ‹©ã€‚
- ğŸ› ï¸ å¯ç”¨å·¥å…·è½¬æ¢ï¼š
  ```bash
  # ä½¿ç”¨ Hugging Face transformers è‡ªåŠ¨è½¬æ¢
  from transformers import AutoModel
  model = AutoModel.from_pretrained("your-model", use_safetensors=True)  # è‡ªåŠ¨ä¼˜å…ˆåŠ è½½ .safetensors
  ```
å¦‚æœä½ æ­£åœ¨å¼€å‘ä¸€ä¸ªéœ€è¦åŠ è½½å¤–éƒ¨æ¨¡å‹çš„åº”ç”¨ï¼ˆå¦‚ Web UIã€æ¨ç†æœåŠ¡ï¼‰ï¼Œ**å¼ºçƒˆå»ºè®®åªæ”¯æŒ `.safetensors` æ ¼å¼**ä»¥è§„é¿å®‰å…¨é£é™©ã€‚


#### é—®é¢˜ï¼šSparse text embeddings å’Œ dense text embeddings çš„åŒºåˆ«

**Sparse text embeddings** å’Œ **dense text embeddings** æ˜¯ä¸¤ç§ä¸åŒçš„æ–‡æœ¬è¡¨ç¤ºæ–¹æ³•ï¼Œå®ƒä»¬åœ¨ç»“æ„ã€ç”Ÿæˆæ–¹å¼ã€åº”ç”¨åœºæ™¯å’Œæ€§èƒ½ç‰¹ç‚¹ä¸Šæœ‰æ˜¾è‘—åŒºåˆ«ã€‚ä»¥ä¸‹æ˜¯è¯¦ç»†å¯¹æ¯”ï¼š

**ä¸€ã€æ ¸å¿ƒå®šä¹‰**

|ç±»å‹|å®šä¹‰|
|---|---|
|**Dense Embeddingsï¼ˆç¨ å¯†åµŒå…¥ï¼‰**|å°†æ–‡æœ¬æ˜ å°„ä¸ºä¸€ä¸ª**ä½ç»´ï¼ˆé€šå¸¸å‡ ç™¾åˆ°å‡ åƒç»´ï¼‰ã€è¿ç»­ã€ç¨ å¯†**çš„å®æ•°å‘é‡ï¼Œå‡ ä¹æ‰€æœ‰ç»´åº¦éƒ½æœ‰éé›¶å€¼ã€‚|
|**Sparse Embeddingsï¼ˆç¨€ç–åµŒå…¥ï¼‰**|å°†æ–‡æœ¬è¡¨ç¤ºä¸ºä¸€ä¸ª**é«˜ç»´ï¼ˆå¯èƒ½æ•°ä¸‡åˆ°ç™¾ä¸‡ç»´ï¼‰ã€ç¦»æ•£ã€ç¨€ç–**çš„å‘é‡ï¼Œç»å¤§å¤šæ•°ç»´åº¦ä¸º 0ï¼Œåªæœ‰å°‘æ•°ç»´åº¦æœ‰éé›¶å€¼ï¼ˆé€šå¸¸æ˜¯æ­£æƒé‡ï¼‰ã€‚|

**äºŒã€å…¸å‹ä»£è¡¨**

|ç±»å‹|æ¨¡å‹/æ–¹æ³•ç¤ºä¾‹|
|---|---|
|**Dense**|- BERT, RoBERTa  <br>- Sentence-BERT (SBERT)  <br>- BGE (BAAI General Embedding)  <br>- OpenAI Embeddings  <br>- Cohere Embeddings|
|**Sparse**|- BM25ï¼ˆä¼ ç»Ÿï¼Œéå­¦ä¹ å‹ï¼‰  <br>- SPLADE  <br>- uniCOIL  <br>- DeepImpact  <br>- ColBERTï¼ˆéƒ¨åˆ†ç¨€ç–ï¼Œå¸¦åæœŸäº¤äº’ï¼‰|
> ğŸ’¡ æ³¨æ„ï¼šBM25 è™½ç„¶å¸¸è¢«å½’ä¸ºâ€œç¨€ç–æ£€ç´¢â€ï¼Œä½†å®ƒä¸æ˜¯â€œembedding æ¨¡å‹â€ï¼ˆæ— ç¥ç»ç½‘ç»œï¼‰ï¼Œè€Œ SPLADE ç­‰æ˜¯**åŸºäºæ·±åº¦å­¦ä¹ çš„ç¨€ç– embedding æ¨¡å‹**ã€‚

**ä¸‰ã€ç»“æ„å¯¹æ¯”ï¼ˆä¸¾ä¾‹ï¼‰**
å‡è®¾è¯æ±‡è¡¨å¤§å°ä¸º 30,000ï¼š
- **Sparse embedding**ï¼ˆå¦‚ SPLADEï¼‰ï¼š
    ```python
    [0, 0, 0, ..., 2.1, 0, 0, ..., 0.8, ..., 0]  # é•¿åº¦=30,000ï¼Œä»…å‡ åä¸ªéé›¶å€¼
    ```
    â†’ æ¯ä¸ªéé›¶ä½ç½®å¯¹åº”ä¸€ä¸ªè¯ï¼ˆå¦‚ "apple" åœ¨ç´¢å¼• 12345ï¼‰ï¼Œå€¼è¡¨ç¤ºé‡è¦æ€§ã€‚
- **Dense embedding**ï¼ˆå¦‚ BGEï¼‰ï¼š
    ```python
    [0.23, -0.41, 0.88, ..., 0.05]  # é•¿åº¦=1024ï¼Œå‡ ä¹æ¯ä¸ªå€¼éƒ½éé›¶
    ```
    â†’ å‘é‡ç»´åº¦ä¸è¯æ±‡è¡¨æ— å…³ï¼Œè¯­ä¹‰ä¿¡æ¯åˆ†å¸ƒåœ¨æ•´ä¸ªå‘é‡ä¸­ã€‚

**å››ã€å…³é”®åŒºåˆ«æ€»ç»“**

|ç»´åº¦|Sparse Embeddings|Dense Embeddings|
|---|---|---|
|**ç»´åº¦**|é«˜ç»´ï¼ˆâ‰ˆè¯æ±‡è¡¨å¤§å°ï¼Œå¦‚ 30kâ€“1Mï¼‰|ä½ç»´ï¼ˆé€šå¸¸ 384â€“4096ï¼‰|
|**éé›¶å…ƒç´ **|æå°‘ï¼ˆ< 100 ä¸ªï¼‰|å‡ ä¹å…¨éƒ¨éé›¶|
|**å¯è§£é‡Šæ€§**|âœ… é«˜ï¼ˆæ¯ä¸ªéé›¶ç»´å¯¹åº”ä¸€ä¸ªè¯ï¼‰|âŒ ä½ï¼ˆè¯­ä¹‰åˆ†å¸ƒåœ¨éšç©ºé—´ï¼‰|
|**å­˜å‚¨æ•ˆç‡**|âœ… é«˜ï¼ˆå¯ç”¨å€’æ’ç´¢å¼•å‹ç¼©å­˜å‚¨ï¼‰|âš ï¸ ä¸­ç­‰ï¼ˆéœ€å­˜å‚¨å®Œæ•´æµ®ç‚¹æ•°ç»„ï¼‰|
|**æ£€ç´¢æ–¹å¼**|å€’æ’ç´¢å¼•ï¼ˆInverted Indexï¼‰ + TF-IDF/BM25 é£æ ¼æ‰“åˆ†|å‘é‡ç›¸ä¼¼åº¦ï¼ˆå¦‚ä½™å¼¦ã€å†…ç§¯ï¼‰+ ANNï¼ˆå¦‚ FAISS, HNSWï¼‰|
|**è®­ç»ƒç›®æ ‡**|ä¼˜åŒ–è¯çº§é‡è¦æ€§ï¼ˆå¦‚é€šè¿‡ KL æ•£åº¦å¯¹é½ BM25ï¼‰|ä¼˜åŒ–å¥å­/æ®µè½çº§è¯­ä¹‰ç›¸ä¼¼åº¦ï¼ˆå¦‚å¯¹æ¯”å­¦ä¹ ï¼‰|
|**å¤šè¯­è¨€æ”¯æŒ**|ä¾èµ–è¯æ±‡è¡¨ï¼Œè·¨è¯­è¨€è¾ƒéš¾|æ›´å®¹æ˜“é€šè¿‡å…±äº«è¯­ä¹‰ç©ºé—´å®ç°|
|**ç¡¬ä»¶åŠ é€Ÿ**|CPU å‹å¥½ï¼Œé€‚åˆå¤§è§„æ¨¡æ–‡æ¡£åº“|GPU/ANN åŠ é€Ÿæ•ˆæœæ›´å¥½|

**äº”ã€åº”ç”¨åœºæ™¯**

**âœ… Sparse æ›´é€‚åˆï¼š**
- **å¤§è§„æ¨¡æ–‡æ¡£æ£€ç´¢**ï¼ˆå¦‚æœç´¢å¼•æ“ï¼‰ï¼š==åˆ©ç”¨æˆç†Ÿçš„å€’æ’ç´¢å¼•æŠ€æœ¯==ï¼Œé«˜æ•ˆè¿‡æ»¤æµ·é‡æ–‡æ¡£ã€‚
- **å…³é”®è¯æ•æ„Ÿä»»åŠ¡**ï¼šéœ€è¦ç²¾ç¡®åŒ¹é…æœ¯è¯­ï¼ˆå¦‚æ³•å¾‹ã€åŒ»ç–—æ£€ç´¢ï¼‰ã€‚
- **èµ„æºå—é™ç¯å¢ƒ**ï¼šæ— éœ€ GPUï¼Œçº¯ CPU å³å¯é«˜æ•ˆè¿è¡Œã€‚

**âœ… Dense æ›´é€‚åˆï¼š**
- **è¯­ä¹‰ç›¸ä¼¼åº¦ä»»åŠ¡**ï¼šç†è§£åŒä¹‰ã€ paraphraseã€ä¸Šä¸‹æ–‡å«ä¹‰ï¼ˆå¦‚ â€œcarâ€ â‰ˆ â€œautomobileâ€ï¼‰ã€‚
- **å°æ ·æœ¬æˆ– zero-shot åœºæ™¯**ï¼šæ³›åŒ–èƒ½åŠ›å¼ºã€‚
- **RAG ç³»ç»Ÿä¸­çš„ç²¾æ’**ï¼šä¸ LLM ç»“åˆæ•ˆæœå¥½ã€‚

**å…­ã€æ··åˆæ–¹æ³•ï¼ˆHybrid Retrievalï¼‰**
ç°ä»£ç³»ç»Ÿå¸¸**ç»“åˆä¸¤è€…ä¼˜åŠ¿**ï¼š
```text
Query â†’ [Sparse Retriever (BM25/SPLADE)] â†’ Top K candidates
       + [Dense Retriever (BGE)]          â†’ Top K candidates
       â†’ åˆå¹¶å»é‡ â†’ Reranker (e.g., BGE-reranker)
```
- **ColBERT**ï¼šè™½è¾“å‡ºç¨ å¯† token å‘é‡ï¼Œä½†é€šè¿‡ MaxSim å®ç°ç±»ä¼¼ç¨€ç–çš„ç»†ç²’åº¦åŒ¹é…ã€‚
- **BGE-M3**ï¼ˆBAAI æœ€æ–°æ¨¡å‹ï¼‰ï¼šåŒæ—¶è¾“å‡º denseã€sparse å’Œ multi-vector è¡¨ç¤ºï¼Œæ”¯æŒç»Ÿä¸€æ£€ç´¢ã€‚

**ä¸ƒã€å¯è§†åŒ–æ¯”å–»**
- **Sparse**ï¼šåƒä¸€æœ¬**ç´¢å¼•ç›®å½•**â€”â€”åªåˆ—å‡ºå…³é”®è¯åŠå…¶é¡µç ï¼ˆä½ç½®+æƒé‡ï¼‰ã€‚
- **Dense**ï¼šåƒä¸€å¹…**æŠ½è±¡ç”»**â€”â€”æ•´ä½“è¡¨è¾¾è¯­ä¹‰ï¼Œæ— æ³•æ‹†è§£å•ä¸ªå…ƒç´ å«ä¹‰ã€‚

**æ€»ç»“ä¸€å¥è¯ï¼š**
> **Sparse embeddings = å…³é”®è¯åŠ æƒï¼ˆå¯è§£é‡Šã€é«˜æ•ˆï¼‰ï¼›Dense embeddings = è¯­ä¹‰å‹ç¼©ï¼ˆæ³›åŒ–å¼ºã€éœ€å‘é‡æ£€ç´¢ï¼‰**ã€‚
æ ¹æ®ä½ çš„ä»»åŠ¡éœ€æ±‚ï¼ˆç²¾åº¦ vs æ•ˆç‡ã€å…³é”®è¯åŒ¹é… vs è¯­ä¹‰ç†è§£ï¼‰ï¼Œå¯ä»¥é€‰æ‹©åˆé€‚ç±»å‹ï¼Œæˆ–ç›´æ¥ä½¿ç”¨ **hybrid æ–¹æ¡ˆ**è·å¾—æœ€ä½³æ•ˆæœã€‚

#### é—®é¢˜ï¼šSparse Embeddingsçš„æ¨¡å‹å¦‚ä½•åšåˆ° è¾“å‡ºç¨€ç–å‘é‡çš„
è¿™æ˜¯ä¸€ä¸ªéå¸¸å¥½çš„é—®é¢˜ï¼**Sparse Embeddings æ¨¡å‹ï¼ˆå¦‚ SPLADEã€uniCOILã€DeepImpact ç­‰ï¼‰ä¹‹æ‰€ä»¥èƒ½è¾“å‡ºâ€œç¨€ç–ä½†æœ‰ä¿¡æ¯é‡â€çš„å‘é‡ï¼Œå…³é”®åœ¨äºå®ƒä»¬é€šè¿‡ç¥ç»ç½‘ç»œå­¦ä¹ æ¯ä¸ªè¯é¡¹ï¼ˆtermï¼‰çš„é‡è¦æ€§æƒé‡ï¼Œå¹¶å¼ºåˆ¶ç»å¤§å¤šæ•°æƒé‡ä¸ºé›¶æˆ–æ¥è¿‘é›¶**ã€‚ä¸‹é¢ä»åŸç†ã€æŠ€æœ¯æ‰‹æ®µå’Œè®­ç»ƒç›®æ ‡ä¸‰ä¸ªæ–¹é¢è¯¦ç»†è§£é‡Šï¼š

**ä¸€ã€æ ¸å¿ƒæ€æƒ³ï¼šå°†æ–‡æœ¬æ˜ å°„åˆ°â€œè¯æ±‡è¡¨ç»´åº¦â€çš„ç¨€ç–å‘é‡**
ä¸ dense embedding è¾“å‡ºä¸€ä¸ªå›ºå®šä½ç»´å‘é‡ä¸åŒï¼Œ**sparse embedding æ¨¡å‹çš„è¾“å‡ºç»´åº¦ = è¯æ±‡è¡¨å¤§å°ï¼ˆVï¼‰**ï¼ˆä¾‹å¦‚ V = 30,000ï¼‰ã€‚  
å¯¹äºè¾“å…¥æ–‡æœ¬ï¼Œæ¨¡å‹ä¼šä¸ºè¯æ±‡è¡¨ä¸­çš„æ¯ä¸ªè¯ $w_i$ é¢„æµ‹ä¸€ä¸ª **éè´Ÿé‡è¦æ€§åˆ†æ•° $s_i \geq 0$**ï¼Œæœ€ç»ˆè¾“å‡ºå‘é‡ä¸ºï¼š
$$ \mathbf{e} = [s_1, s_2, ..., s_V] $$
å…¶ä¸­ **ç»å¤§å¤šæ•° $s_i = 0$**ï¼Œåªæœ‰å°‘æ•°å…³é”®è¯çš„ $s_i > 0$ï¼Œå½¢æˆç¨€ç–è¡¨ç¤ºã€‚
> âœ… è¿™ä¸ªå‘é‡å¯ä»¥ç›´æ¥ç”¨äº **å€’æ’ç´¢å¼•ï¼ˆInverted Indexï¼‰æ£€ç´¢**ï¼Œå°±åƒ BM25 ä¸€æ ·é«˜æ•ˆã€‚

**äºŒã€å¦‚ä½•å®ç°â€œç¨€ç–æ€§â€ï¼Ÿå…³é”®æŠ€æœ¯æ‰‹æ®µ**

**1. **ä½¿ç”¨å¸¦ç¨€ç–è¯±å¯¼çš„æ¿€æ´»å‡½æ•°****
æœ€å¸¸ç”¨çš„æ˜¯ **ReLU + å¯¹æ•°å˜æ¢ + FLOPS æ­£åˆ™åŒ–**ï¼ˆä»¥ SPLADE ä¸ºä»£è¡¨ï¼‰ï¼š

**ï¼ˆ1ï¼‰åŸºäº BERT çš„ token-level logits**
- è¾“å…¥æ–‡æœ¬ â†’ BERT ç¼–ç å™¨ â†’ å¾—åˆ°æ¯ä¸ª token çš„ä¸Šä¸‹æ–‡è¡¨ç¤ºã€‚
- é€šè¿‡ä¸€ä¸ªçº¿æ€§å±‚ï¼ˆæˆ– MLM headï¼‰é¢„æµ‹ **æ•´ä¸ªè¯æ±‡è¡¨ä¸Šæ¯ä¸ªè¯çš„ logits**ï¼ˆç±»ä¼¼æ©ç è¯­è¨€å»ºæ¨¡ï¼‰ã€‚

**ï¼ˆ2ï¼‰åº”ç”¨ **$\text{ReLU}(\log(1 + \exp(x)))$** æˆ–ç›´æ¥ **$\text{F}(x) = \max(0, x)$****
- å°† logits ç»è¿‡ **éè´Ÿæ¿€æ´»**ï¼Œç¡®ä¿è¾“å‡º â‰¥ 0ã€‚
- å®é™…ä¸­å¸¸ç”¨ï¼š  
    $$s_i = \text{ReLU}\left( \text{MLM logits}_i \right)$$ æˆ–æ›´å¹³æ»‘çš„ï¼š $$ s_i = \log\left(1 + \exp(\text{MLM logits}_i)\right) \quad \text{(softplus)} $$
> ğŸ“Œ æ³¨æ„ï¼šå³ä½¿ logits æ˜¯ç¨ å¯†çš„ï¼Œåç»­ä¼šé€šè¿‡æ­£åˆ™åŒ–è®©å¤§å¤šæ•° $s_i \to 0$ã€‚

**2. **å¼•å…¥ç¨€ç–æ€§æ­£åˆ™åŒ–ï¼ˆSparsity Regularizationï¼‰****
è¿™æ˜¯å®ç°â€œçœŸæ­£ç¨€ç–â€çš„å…³é”®ï¼æ¨¡å‹åœ¨è®­ç»ƒæ—¶ä¼š**æƒ©ç½šéé›¶å…ƒç´ çš„æ•°é‡æˆ–å¤§å°**ã€‚

**å¸¸è§æ­£åˆ™é¡¹ï¼ˆåŠ åœ¨ loss ä¸­ï¼‰ï¼š**
- **L1 æ­£åˆ™åŒ–**ï¼š$\lambda \sum_i |s_i|$  
    â†’ é¼“åŠ±æƒé‡è¶‹è¿‘äº 0ã€‚
- **FLOPS æ­£åˆ™åŒ–ï¼ˆSPLADE æå‡ºï¼‰**ï¼š  
    $$ \mathcal{L}_{\text{flops}} = \left( \frac{1}{V} \sum_i \mathbb{E}[s_i] \right)^2 $$ â†’ æƒ©ç½š**å¹³å‡æ¿€æ´»å¼ºåº¦**ï¼Œä¿ƒä½¿æ¨¡å‹åªæ¿€æ´»æå°‘æ•°è¯ã€‚
- **Group Lasso / Top-k çº¦æŸ**ï¼šå¼ºåˆ¶åªä¿ç•™ top-k ä¸ªæœ€å¤§æƒé‡ã€‚
> ğŸ’¡ è®­ç»ƒå®Œæˆåï¼Œæ¨ç†æ—¶å¯è®¾ç½®é˜ˆå€¼ï¼ˆå¦‚ $s_i < 1e-4$ åˆ™ç½® 0ï¼‰ï¼Œè¿›ä¸€æ­¥æå‡ç¨€ç–åº¦ã€‚

**3. **åˆ©ç”¨é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹çš„ MLM Head****
- SPLADE ç­‰æ¨¡å‹ç›´æ¥å¤ç”¨ **BERT çš„ Masked Language Model (MLM) å¤´**ã€‚
- MLM å¤´æœ¬æ¥å°±èƒ½é¢„æµ‹â€œå“ªäº›è¯å¯èƒ½å‡ºç°åœ¨ä¸Šä¸‹æ–‡ä¸­â€ï¼Œå¤©ç„¶å…·æœ‰**è¯çº§è¯­ä¹‰æ„ŸçŸ¥èƒ½åŠ›**ã€‚
- é€šè¿‡å¾®è°ƒ MLM å¤´ï¼Œä½¿å…¶è¾“å‡ºçš„ logits ä¸å†ç”¨äºé¢„æµ‹è¢«é®ç›–è¯ï¼Œè€Œæ˜¯ä½œä¸º**å…¨æ–‡çš„è¯é‡è¦æ€§åˆ†å¸ƒ**ã€‚
> âœ… è¿™æ ·æ—¢åˆ©ç”¨äº†é¢„è®­ç»ƒçŸ¥è¯†ï¼Œåˆå®ç°äº†ç«¯åˆ°ç«¯çš„ç¨€ç–è¡¨ç¤ºå­¦ä¹ ã€‚

**ä¸‰ã€è®­ç»ƒç›®æ ‡ï¼šå¯¹é½ç›¸å…³æ€§ä¿¡å·**
ä¸ºäº†è®©ç¨€ç–å‘é‡â€œæœ‰ä¿¡æ¯é‡â€ï¼ˆå³èƒ½æœ‰æ•ˆæ’åºç›¸å…³æ–‡æ¡£ï¼‰ï¼Œæ¨¡å‹é€šå¸¸é‡‡ç”¨ä»¥ä¸‹ç›‘ç£ä¿¡å·ï¼š

|æ–¹æ³•|è®­ç»ƒç›®æ ‡|
|---|---|
|**SPLADE**|æœ€å¤§åŒ–æŸ¥è¯¢-æ­£æ ·æœ¬æ–‡æ¡£çš„ç›¸ä¼¼åº¦ï¼ˆå†…ç§¯ï¼‰ï¼Œæœ€å°åŒ–æŸ¥è¯¢-è´Ÿæ ·æœ¬çš„ç›¸ä¼¼åº¦ + ç¨€ç–æ­£åˆ™|
|**DeepImpact / uniCOIL**|å›å½’åˆ°ä¼ªæ ‡ç­¾ï¼ˆå¦‚ BM25 åˆ†æ•°ã€æ•™å¸ˆæ¨¡å‹æ‰“åˆ†ï¼‰|
|**æ— ç›‘ç£ SPLADE**|ä½¿ç”¨å¯¹æ¯”å­¦ä¹ æˆ–è‡ªç›‘ç£ï¼ˆå¦‚æ–‡æ¡£-æ ‡é¢˜å¯¹ï¼‰|
ç›¸ä¼¼åº¦è®¡ç®—æ–¹å¼ï¼š $$ \text{score}(q, d) = \sum_{i=1}^V \text{ReLU}(q_i) \cdot \text{ReLU}(d_i) $$ â†’ æœ¬è´¨æ˜¯ **åŠ æƒè¯é‡å ï¼ˆWeighted Term Matchingï¼‰**ï¼Œä½†æƒé‡ç”±ç¥ç»ç½‘ç»œå­¦ä¹ å¾—åˆ°ï¼Œæ¯” TF-IDF/BM25 æ›´æ™ºèƒ½ã€‚

**å››ã€ä¸¾ä¸ªå…·ä½“ä¾‹å­ï¼šSPLADE å¦‚ä½•å·¥ä½œï¼Ÿ**
1. è¾“å…¥æŸ¥è¯¢ `"How to bake a cake?"`
2. ç»è¿‡ BERT + MLM head â†’ è¾“å‡º 30,000 ç»´ logits
3. åº”ç”¨ $\text{ReLU}(\cdot)$ â†’ å¾—åˆ°éè´Ÿåˆ†æ•°
4. åŠ å…¥ FLOPS æ­£åˆ™ â†’ æ¨¡å‹å­¦ä¼šåªç»™ `"bake"`, `"cake"`, `"recipe"` ç­‰è¯é«˜åˆ†ï¼Œå…¶ä½™ä¸º 0
5. æœ€ç»ˆè¾“å‡ºç¨€ç–å‘é‡ï¼šä»…å‡ åä¸ªéé›¶å€¼ï¼Œæ¯ä¸ªå¯¹åº”ä¸€ä¸ªå…³é”®è¯åŠå…¶è¯­ä¹‰é‡è¦æ€§
ğŸ” æ£€ç´¢æ—¶ï¼š
- æ–‡æ¡£ä¹Ÿç”¨åŒæ ·æ–¹å¼ç¼–ç æˆç¨€ç–å‘é‡
- é€šè¿‡å€’æ’ç´¢å¼•å¿«é€Ÿè®¡ç®—å†…ç§¯å¾—åˆ†ï¼ˆåªè®¡ç®—éé›¶ç»´åº¦äº¤é›†ï¼‰

**äº”ã€ä¸ºä»€ä¹ˆå«â€œå“äº®â€ï¼ˆinformativeï¼‰ï¼Ÿ**
- è™½ç„¶ç¨€ç–ï¼Œä½†**éé›¶ç»´åº¦æ˜¯æ¨¡å‹ç²¾å¿ƒæŒ‘é€‰çš„å…³é”®è¯**ï¼Œä¸”æƒé‡åæ˜ å…¶åœ¨å½“å‰ä¸Šä¸‹æ–‡ä¸­çš„**è¯­ä¹‰é‡è¦æ€§**ã€‚
- ç›¸æ¯” BM25 çš„é™æ€ TF-IDFï¼Œsparse embedding èƒ½ï¼š
    - ç†è§£åŒä¹‰è¯ï¼ˆ"car" â†’ æ¿€æ´» "automobile"ï¼‰
    - æŠ‘åˆ¶åœç”¨è¯ï¼ˆ"the", "how" æƒé‡â‰ˆ0ï¼‰
    - æ ¹æ®ä¸Šä¸‹æ–‡åŠ¨æ€è°ƒæ•´ï¼ˆ"apple" åœ¨ç§‘æŠ€ vs æ°´æœè¯­å¢ƒä¸‹æ¿€æ´»ä¸åŒè¯ï¼‰

**æ€»ç»“**

|å…³é”®ç‚¹|è¯´æ˜|
|---|---|
|**è¾“å‡ºç»´åº¦**|= è¯æ±‡è¡¨å¤§å°ï¼ˆé«˜ç»´ï¼‰|
|**ç¨€ç–æ€§æ¥æº**|ReLU/Softplus æ¿€æ´» + L1/FLOPS æ­£åˆ™åŒ–|
|**ä¿¡æ¯é‡æ¥æº**|åŸºäºé¢„è®­ç»ƒ MLM å¤´ + ç›¸å…³æ€§ç›‘ç£å­¦ä¹ |
|**æ£€ç´¢å…¼å®¹æ€§**|å®Œå…¨å…¼å®¹ä¼ ç»Ÿå€’æ’ç´¢å¼•ç³»ç»Ÿï¼ˆå¦‚ Lucene, Elasticsearchï¼‰|
|**ä»£è¡¨æ¨¡å‹**|SPLADEï¼ˆæœ€ç»å…¸ï¼‰ã€uniCOILã€DeepImpactã€BGE-M3ï¼ˆæ”¯æŒ sparse è¾“å‡ºï¼‰|
> âœ… æ‰€ä»¥ï¼Œ**â€œç¨€ç–ä½†å“äº®â€ = åªä¿ç•™æœ€å…³é”®çš„å‡ ä¸ªè¯ï¼Œä½†æ¯ä¸ªè¯çš„æƒé‡éƒ½ç»è¿‡æ·±åº¦è¯­ä¹‰ç†è§£ä¼˜åŒ–**ã€‚
å¦‚æœä½ æ­£åœ¨æ„å»ºæ£€ç´¢ç³»ç»Ÿï¼Œsparse embeddings èƒ½è®©ä½ åœ¨ä¸ç‰ºç‰²å¤ªå¤šè¯­ä¹‰èƒ½åŠ›çš„å‰æä¸‹ï¼Œäº«å—ä¼ ç»Ÿæœç´¢å¼•æ“çš„é«˜æ•ˆä¸å¯æ‰©å±•æ€§ã€‚
## é—®é¢˜
####  é—®é¢˜ï¼šlangchainä¸­çš„ç«–çº¿è¿ç®—ç¬¦æ˜¯ç”±å“ªäº›æ–¹æ³•æ¥å®ç°çš„
åœ¨ `langchain` ä¸­ï¼Œç«–çº¿è¿ç®—ç¬¦ï¼ˆ`|`ï¼‰çš„å®ç°ä¸»è¦ä¾èµ–äºä»¥ä¸‹æ–¹æ³•ï¼š

**æ ¸å¿ƒå®ç°æ–¹æ³•**
1. **`__or__` æ–¹æ³•**
   - è¿™æ˜¯ Python ä¸­å®ç°ç«–çº¿è¿ç®—ç¬¦çš„æ ¸å¿ƒé­”æœ¯æ–¹æ³•
   - å½“ä½¿ç”¨ `a | b` è¯­æ³•æ—¶ï¼ŒPython ä¼šè°ƒç”¨ `a.__or__(b)`
2. **`__ror__` æ–¹æ³•**
   - å³ä¾§å¯¹è±¡çš„åå‘æˆ–è¿ç®—æ–¹æ³•
   - å½“å·¦ä¾§å¯¹è±¡æ²¡æœ‰å®ç° `__or__` æ—¶è°ƒç”¨

**åœ¨ Langchain ä¸­çš„åº”ç”¨**
åœ¨ä½ çš„ä»£ç ä¸­ `prompt|llm|output_parser` è¿™ä¸ªé“¾æ¡ä¸­ï¼š
- promptï¼ˆ`ChatPromptTemplate` å¯¹è±¡ï¼‰å®ç°äº† `__or__` æ–¹æ³•
- llmï¼ˆ`ChatOpenAI` å¯¹è±¡ï¼‰ä¹Ÿå®ç°äº† `__or__` æ–¹æ³•  
- output_parserï¼ˆ`StrOutputParser` å¯¹è±¡ï¼‰åŒæ ·æ”¯æŒé“¾å¼æ“ä½œ

**å®ç°æœºåˆ¶**
```python

**ä¼ªä»£ç ç¤ºä¾‹**
class BaseComponent:
    def __or__(self, other):
        return Chain(self, other)
```
è¿™ç§è®¾è®¡æ¨¡å¼å…è®¸ä¸åŒçš„ `langchain` ç»„ä»¶ï¼ˆå¦‚ promptã€llmã€output_parserï¼‰é€šè¿‡ç«–çº¿è¿ç®—ç¬¦ç»„åˆæˆä¸€ä¸ªå®Œæ•´çš„å¤„ç†é“¾ chainã€‚

#### é—®é¢˜ï¼šlangchainä¸­çš„StrOutputParser æ˜¯å¦‚ä½•è‡ªåŠ¨å¯¹ chatbotçš„ç»“æœè¿›è¡Œæ¸²æŸ“çš„

ä½œä¸ºä¸€åèµ„æ·±æŠ€æœ¯å¯¼å¸ˆï¼Œæˆ‘æ¥è¯¦ç»†è§£é‡Š LangChain ä¸­çš„ `StrOutputParser` **ä¸æ˜¯**å¦‚ä½•â€œè‡ªåŠ¨æ¸²æŸ“â€ç»“æœçš„ï¼Œè€Œæ˜¯å®ƒåœ¨ LangChain è¡¨è¾¾å¼è¯­è¨€ (LCEL) ç®¡é“ä¸­æ‰®æ¼”çš„**å…³é”®è§’è‰²**ã€‚

**æ ¸å¿ƒè§‚ç‚¹ï¼š`StrOutputParser` å¹¶éæ¸²æŸ“å™¨ï¼Œè€Œæ˜¯è½¬æ¢å™¨**
`StrOutputParser` çš„ä½œç”¨**ä¸æ˜¯**å¯¹ç»“æœè¿›è¡Œå¤æ‚çš„â€œæ¸²æŸ“â€ï¼ˆå¦‚æ ¼å¼åŒ–ä¸º Markdown æˆ– HTMLï¼‰ï¼Œè€Œæ˜¯æ‰§è¡Œä¸€ä¸ªéå¸¸ç®€å•ä½†è‡³å…³é‡è¦çš„**ç±»å‹è½¬æ¢**ï¼š
**å®ƒç¡®ä¿ç®¡é“ï¼ˆChainï¼‰çš„æœ€ç»ˆè¾“å‡ºæ˜¯æ ‡å‡†çš„ Python å­—ç¬¦ä¸²ï¼ˆ`str`ï¼‰ç±»å‹ã€‚**
åœ¨ LangChain ç®¡é“ä¸­ï¼Œâ€œæ¸²æŸ“â€è¿™ä¸ªè¯é€šå¸¸æ„å‘³ç€å°†è¾“å‡ºä»ä¸€ä¸ªå¤æ‚å¯¹è±¡è½¬æ¢ä¸ºç”¨æˆ·æˆ–ä¸‹ä¸€ä¸ªç»„ä»¶å¯ä»¥ä½¿ç”¨çš„æ ¼å¼ã€‚

**1. ä¸ºä»€ä¹ˆéœ€è¦ `StrOutputParser`ï¼Ÿ**
LLM æ¨¡å‹çš„åŸå§‹è¾“å‡ºé€šå¸¸æ˜¯ä¸€ä¸ªå¤æ‚çš„å¯¹è±¡ï¼Œè€Œä¸æ˜¯ä¸€ä¸ªç®€å•çš„å­—ç¬¦ä¸²ï¼š

| **åŸå§‹è¾“å‡ºç±»å‹**        | **è§£é‡Š**                                                                                                                                   |
| ----------------- | ---------------------------------------------------------------------------------------------------------------------------------------- |
| **`BaseMessage`** | å¯¹äº **Chat æ¨¡å‹** (`ChatOpenAI`, `ChatGroq` ç­‰)ï¼Œå®ƒä»¬çš„ `invoke()` æˆ– `stream()` æ–¹æ³•è¿”å›çš„æ˜¯ä¸€ä¸ª `BaseMessage` å¯¹è±¡ï¼ˆé€šå¸¸æ˜¯ `AIMessage` æˆ– `HumanMessage` çš„å­ç±»ï¼‰ã€‚ |
| **`Generation`**  | å¯¹äº **Completion æ¨¡å‹** (`OpenAI` ç­‰)ï¼Œå®ƒä»¬çš„ `invoke()` è¿”å›çš„æ˜¯ä¸€ä¸ª `Generation` å¯¹è±¡çš„åˆ—è¡¨ï¼ˆåŒ…è£…åœ¨ `LLMResult` ä¸­ï¼‰ã€‚                                           |
**`StrOutputParser` çš„å·¥ä½œå°±æ˜¯ä»è¿™äº›å¤æ‚çš„å¯¹è±¡ä¸­ï¼Œå®‰å…¨åœ°æå–å‡ºäººç±»å¯è¯»çš„å­—ç¬¦ä¸²å†…å®¹ã€‚**

**2. `StrOutputParser` çš„å·¥ä½œæœºåˆ¶**
`StrOutputParser` åœ¨ LCEL ç®¡é“ä¸­å®ç°äº† `BaseOutputParser` æ¥å£ï¼Œå®ƒçš„æ ¸å¿ƒé€»è¾‘éå¸¸ç®€å•ï¼š

**A. å¤„ç† Chat æ¨¡å‹è¾“å‡º (`BaseMessage` å¯¹è±¡)**
å½“å®ƒæ¥æ”¶åˆ° `AIMessage` æˆ–å…¶ä»– `BaseMessage` å¯¹è±¡æ—¶ï¼Œå®ƒä¼šè°ƒç”¨è¯¥å¯¹è±¡çš„ `.content` å±æ€§ã€‚
- **è¾“å…¥ç¤ºä¾‹ï¼š** `<AIMessage content='ä½ å¥½ï¼æˆ‘æ˜¯ä¸€ä¸ªAIã€‚'>`
- **è¾“å‡ºç»“æœï¼š** `'ä½ å¥½ï¼æˆ‘æ˜¯ä¸€ä¸ªAIã€‚'`

**B. å¤„ç† Completion æ¨¡å‹è¾“å‡º (`LLMResult` / `Generation` å¯¹è±¡)**
å¦‚æœå®ƒæ¥æ”¶åˆ°çš„æ˜¯ Completion æ¨¡å‹è¿”å›çš„ç»“æ„ï¼Œå®ƒä¼šæå–ç¬¬ä¸€ä¸ª `Generation` å¯¹è±¡çš„æ–‡æœ¬å†…å®¹ã€‚

**C. å¤„ç†æµå¼è¾“å‡º (Streaming)**
åœ¨æµå¼ä¼ è¾“ä¸­ï¼Œ`StrOutputParser` ä¼šæŒç»­æ¥æ”¶åˆ°ç‰‡æ®µï¼ˆChunksï¼‰çš„ `BaseMessage` å¯¹è±¡æˆ–å­—ç¬¦ä¸²ã€‚å®ƒçš„ä½œç”¨æ˜¯ï¼š
- **æå–å†…å®¹ï¼š** ä»æ¯ä¸ªä¼ å…¥çš„ Chunk ä¸­æå– `.content` å±æ€§ã€‚
- **æ‹¼æ¥å†…å®¹ï¼š** å°†è¿™äº›å†…å®¹ç‰‡æ®µ**å®‰å…¨åœ°æ‹¼æ¥**èµ·æ¥ï¼Œå½¢æˆæœ€ç»ˆçš„å®Œæ•´å­—ç¬¦ä¸²ã€‚è¿™ç¡®ä¿äº†å‰ç«¯æˆ–ç”¨æˆ·æ¥æ”¶åˆ°çš„æµæ˜¯è¿ç»­ä¸”æ­£ç¡®çš„æ–‡æœ¬ã€‚

**3. å¦‚ä½•â€œè‡ªåŠ¨æ¸²æŸ“â€çš„è¯¯è§£**
ç”¨æˆ·ä¹‹æ‰€ä»¥è§‰å¾—å®ƒæ˜¯â€œè‡ªåŠ¨æ¸²æŸ“â€çš„ï¼Œæ˜¯å› ä¸ºå®ƒå°†ä¸€ä¸ªä¸é€æ˜çš„ LangChain å†…éƒ¨å¯¹è±¡ï¼ˆå¦‚ `AIMessage`ï¼‰è½¬æ¢æˆäº†åº”ç”¨ç¨‹åºå‰ç«¯å¯ä»¥ç›´æ¥æ˜¾ç¤ºçš„ **Python `str` ç±»å‹**ã€‚
åœ¨ LCEL ç®¡é“ä¸­ï¼Œ`StrOutputParser` é€šå¸¸ä½äºç®¡é“çš„**æœ«ç«¯**ï¼Œå› ä¸ºå®ƒç¡®ä¿äº†ç®¡é“çš„è¾“å‡ºèƒ½å¤Ÿè¢«åç»­çš„ç³»ç»Ÿï¼ˆå¦‚ Flask API å“åº”ã€Streamlit ç•Œé¢æˆ–ç®€å•çš„ `print()` è¯­å¥ï¼‰è½»æ¾æ¶ˆè´¹ã€‚

**æ€»ç»“**
`StrOutputParser` æ˜¯ LangChain ç®¡é“ä¸­ä¸€ä¸ª**ç±»å‹è½¬æ¢**ç»„ä»¶ï¼Œå®ƒçš„ä½œç”¨æ˜¯ï¼š
1. ä» LLM è¿”å›çš„å¤æ‚å¯¹è±¡ï¼ˆå¦‚ `AIMessage`ï¼‰ä¸­**æå–**çº¯æ–‡æœ¬å†…å®¹ã€‚
2. ç¡®ä¿ Chain çš„è¾“å‡ºç±»å‹å§‹ç»ˆæ˜¯æ ‡å‡†çš„ **`str`**ï¼Œä»¥ä¾¿äºåç»­å¤„ç†å’Œå±•ç¤ºã€‚
3. åœ¨æµå¼ä¼ è¾“ä¸­ï¼Œè´Ÿè´£å°†æ¥æ”¶åˆ°çš„å†…å®¹**ç‰‡æ®µå®‰å…¨æ‹¼æ¥**ã€‚


#### é—®é¢˜ï¼šé‚£ä¹ˆstreamlitçš„writeæ–¹æ³•æ˜¯å¦‚ä½•å°†markdownæ ¼å¼æ–‡æœ¬è‡ªåŠ¨æ¸²æŸ“ä¸ºæœ‰æ ¼å¼çš„htmlçš„

ä»£ç  streamlit.elements.write.WriteMixin.write ä¸­æœ‰è®²è§£è¿™éƒ¨åˆ†å†…å®¹ã€‚

è¿™æ˜¯ä¸€ä¸ªéå¸¸å¥½çš„é—®é¢˜ï¼Œå®ƒè§¦åŠäº† Streamlit çš„æ ¸å¿ƒæœºåˆ¶å’Œå‰ç«¯äº¤äº’åŸç†ã€‚
`streamlit.write()` æ–¹æ³•è‡ªèº«ä¸ä¼šæ‰§è¡Œ Markdown æ¸²æŸ“ï¼Œå®ƒæ˜¯ä¸€ä¸ªâ€œä¸‡èƒ½â€å‘½ä»¤ï¼Œä¼šæ ¹æ®ä¼ å…¥çš„æ•°æ®ç±»å‹è¿›è¡Œ**åˆ†æ´¾ï¼ˆDispatchï¼‰**ã€‚å½“å®ƒæ¥æ”¶åˆ°**å­—ç¬¦ä¸²**æ—¶ï¼Œå®ƒä¼šå°†æ¸²æŸ“å·¥ä½œå§”æ‰˜ç»™ä¸“é—¨çš„å‡½æ•°ã€‚
ä¸‹é¢æ˜¯ `st.write()` å¦‚ä½•å°† Markdown æ–‡æœ¬è‡ªåŠ¨è½¬æ¢ä¸º HTML æ ¼å¼åŒ–æ˜¾ç¤ºçš„è¯¦ç»†è¿‡ç¨‹ã€‚

**1. `st.write()` çš„åˆ†æ´¾æœºåˆ¶ (The Swiss Army Knife)**
`st.write()` è¢«ç§°ä¸º Streamlit çš„â€œç‘å£«å†›åˆ€â€ï¼Œå®ƒä¼šæ£€æŸ¥ä¼ å…¥çš„å‚æ•°ç±»å‹ï¼š

| **ä¼ å…¥å‚æ•°ç±»å‹**            | **st.write() å®é™…è°ƒç”¨**  |
| --------------------- | -------------------- |
| **`str` (å­—ç¬¦ä¸²)**       | å§”æ‰˜ç»™ `st.markdown()`  |
| `pd.DataFrame`        | å§”æ‰˜ç»™ `st.dataframe()` |
| `dict` æˆ– `list`       | å§”æ‰˜ç»™ `st.json()`      |
| `Altair/Plotly Chart` | å§”æ‰˜ç»™ç›¸åº”çš„å›¾è¡¨å‡½æ•°           |
| `Exception`           | å§”æ‰˜ç»™ `st.exception()` |
å› æ­¤ï¼Œå½“ä½ ä¼ å…¥ä¸€ä¸ªåŒ…å« Markdown æ ¼å¼çš„å­—ç¬¦ä¸²æ—¶ï¼Œå®é™…æ‰§è¡Œæ¸²æŸ“çš„æ˜¯ **`st.markdown()`** å‡½æ•°ã€‚

**2. `st.markdown()` çš„æ ¸å¿ƒæ¸²æŸ“è¿‡ç¨‹**
`st.markdown()` æ˜¯ä¸“é—¨è´Ÿè´£å°† Markdown æ–‡æœ¬è½¬æ¢ä¸º HTML çš„å‡½æ•°ã€‚è¿™ä¸ªè½¬æ¢è¿‡ç¨‹åœ¨ Streamlit å†…éƒ¨æ˜¯è¿™æ ·è¿ä½œçš„ï¼š

**A. åç«¯ï¼ˆPythonï¼‰å¤„ç†ï¼šä½¿ç”¨ Markdown è§£æåº“**
1. **è§£æå™¨ä½¿ç”¨ï¼š** Streamlit çš„ Python åç«¯ä¸ä¼šè‡ªå·±ç¼–å†™ Markdown è½¬æ¢é€»è¾‘ã€‚å®ƒä¼šä¾èµ–ä¸€ä¸ªæˆ–å¤šä¸ªæˆç†Ÿçš„ã€é«˜æ€§èƒ½çš„ **Python Markdown è§£æåº“**ï¼ˆä¾‹å¦‚ï¼Œæ—©æœŸç‰ˆæœ¬å¯èƒ½ä¾èµ– `markdown-it-py` æˆ–ç±»ä¼¼çš„åº“ï¼‰ã€‚
2. **ç”Ÿæˆ HTML/æŠ½è±¡ç»“æ„ï¼š** å½“ä½ è°ƒç”¨ `st.markdown(body)` æ—¶ï¼Œ`body` å­—ç¬¦ä¸²ä¼šè¢«è¿™ä¸ªå†…éƒ¨çš„ Markdown è§£æå™¨å¤„ç†ï¼Œå¹¶è½¬æ¢æˆå¯¹åº”çš„ **HTML ç»“æ„**ï¼ˆæˆ–ä¸€ä¸ªåŒ…å«æ¸²æŸ“æŒ‡ä»¤çš„ä¸­é—´æ•°æ®ç»“æ„ï¼‰ã€‚
    - ä¾‹å¦‚ï¼Œ`**bold**` è¢«è½¬æ¢ä¸º `<strong>bold</strong>`ã€‚
3. **åºåˆ—åŒ–ä¸ä¼ è¾“ï¼š** Streamlit å°†è¿™ä¸ª HTML ç»“æ„æˆ–æ¸²æŸ“æŒ‡ä»¤**åºåˆ—åŒ–**ï¼ˆé€šå¸¸ä¸º JSON æ ¼å¼ï¼‰ã€‚
4. **WebSocket ä¼ è¾“ï¼š** åºåˆ—åŒ–åçš„æ•°æ®é€šè¿‡ **WebSocket** è¿æ¥ï¼Œä» Python åç«¯å‘é€åˆ° Streamlit çš„å‰ç«¯ï¼ˆæµè§ˆå™¨ï¼‰ã€‚

**B. å‰ç«¯ï¼ˆæµè§ˆå™¨ï¼‰æ¸²æŸ“ï¼šReact + CSS**
1. **å‰ç«¯æ¥æ”¶ï¼š** Streamlit çš„å‰ç«¯ï¼ˆä½¿ç”¨ **React** æ¡†æ¶æ„å»ºï¼‰æ¥æ”¶åˆ°é€šè¿‡ WebSocket å‘é€è¿‡æ¥çš„æŒ‡ä»¤/æ•°æ®ã€‚
2. **DOM æ“ä½œï¼š** React ç»„ä»¶æ ¹æ®æ”¶åˆ°çš„ HTML ç»“æ„æˆ–æŒ‡ä»¤ï¼Œå°†å…¶å®‰å…¨åœ°æ’å…¥åˆ° Web é¡µé¢çš„ **DOM (Document Object Model)** ä¸­ã€‚
3. **æµè§ˆå™¨æ¸²æŸ“ï¼š** æµè§ˆå™¨è¯†åˆ«è¿™äº› HTML æ ‡ç­¾ï¼ˆå¦‚ `<h1>`, `<p>`, `<strong>`ï¼‰å¹¶åº”ç”¨é»˜è®¤æˆ– Streamlit è‡ªå®šä¹‰çš„ CSS æ ·å¼ã€‚
    - **æ ·å¼åº”ç”¨ï¼š** Streamlit å…·æœ‰å†…ç½®çš„æ ·å¼è¡¨ï¼Œç¡®ä¿æ‰€æœ‰çš„ Markdown å…ƒç´ ï¼ˆæ ‡é¢˜ã€åˆ—è¡¨ã€ä»£ç å—ç­‰ï¼‰éƒ½éµå¾ªåº”ç”¨çš„ä¸»é¢˜å’Œå¤–è§‚ï¼Œçœ‹èµ·æ¥ç¾è§‚ä¸”ä¸€è‡´ã€‚

**3. ä¸ºä»€ä¹ˆæ˜¯è‡ªåŠ¨çš„ï¼Ÿ**
å¯¹äºå¼€å‘è€…æ¥è¯´ï¼Œæ•´ä¸ªè¿‡ç¨‹æ˜¯è‡ªåŠ¨ä¸”æ— æ„Ÿçš„ï¼Œå› ä¸ºï¼š
1. **å°è£…ï¼š** `st.write()` å’Œ `st.markdown()` å°è£…äº†ä» Markdown å­—ç¬¦ä¸²åˆ° HTML æ¸²æŸ“çš„æ‰€æœ‰æ­¥éª¤ã€‚
2. **å®æ—¶åŒæ­¥ï¼š** Streamlit çš„æ¶æ„æœ¬èº«å°±æ˜¯ä¸ºäº†åœ¨ Python åç«¯ä»£ç ä¸æµè§ˆå™¨å‰ç«¯ä¹‹é—´æä¾›**å®æ—¶åŒæ­¥**ã€‚å½“ä½ è°ƒç”¨ä¸€ä¸ª Streamlit å‘½ä»¤æ—¶ï¼ŒPython æ¡†æ¶ä¼šç«‹å³å¤„ç†æ•°æ®å¹¶å‘Šè¯‰å‰ç«¯å¦‚ä½•æ›´æ–°ã€‚



#### é—®é¢˜ï¼šPydantic ä¸­ `BaseModel` çš„æ ¸å¿ƒä½œç”¨ï¼šæ•°æ®æ¨¡å‹å’Œæ•°æ®æ ¡éªŒ
åœ¨ Python çš„ `pydantic` åº“ä¸­ï¼Œ`BaseModel` æ˜¯**æ„å»ºæ•°æ®æ¨¡å‹**çš„åŸºçŸ³ã€‚å®ƒçš„ä¸»è¦ä½œç”¨æ˜¯**å®šä¹‰æ•°æ®çš„ç»“æ„ã€ç±»å‹ï¼Œå¹¶è‡ªåŠ¨è¿›è¡ŒéªŒè¯**ã€‚
ç®€å•æ¥è¯´ï¼Œ`BaseModel` å°†æ¾æ•£çš„ Python å­—å…¸æ•°æ®æå‡ä¸ºå…·æœ‰**æ˜ç¡®ç»“æ„ã€ç±»å‹å’Œå†…ç½®éªŒè¯**çš„å¼ºå¤§æ•°æ®å¯¹è±¡ã€‚

**ğŸš€ `BaseModel` çš„ä¸»è¦åŠŸèƒ½**

**1. å®šä¹‰æ¸…æ™°çš„æ•°æ®ç»“æ„ (Schema Definition)**
`BaseModel` å…è®¸ä½ ä½¿ç”¨æ ‡å‡†çš„ Python ç±»å‹æ³¨è§£æ¥å®šä¹‰ä½ çš„æ•°æ®å¯¹è±¡åº”è¯¥é•¿ä»€ä¹ˆæ ·ï¼ŒåŒ…æ‹¬å“ªäº›å­—æ®µã€æ¯ä¸ªå­—æ®µçš„ç±»å‹ã€‚
- **ç¤ºä¾‹:**
    Python
    ```
    from pydantic import BaseModel
    from datetime import datetime
    class User(BaseModel):
        id: int
        name: str = "John Doe"  # å¸¦æœ‰é»˜è®¤å€¼
        signup_ts: datetime | None = None # è”åˆç±»å‹
        is_active: bool
    ```
    è¿™ä¸ªç±»æ¸…æ¥šåœ°å®šä¹‰äº†ä¸€ä¸ªç”¨æˆ·å¯¹è±¡å¿…é¡»åŒ…å« `id`ï¼ˆæ•´æ•°ï¼‰ã€`name`ï¼ˆå­—ç¬¦ä¸²ï¼‰ã€`signup_ts`ï¼ˆæ—¥æœŸæ—¶é—´æˆ– Noneï¼‰å’Œ `is_active`ï¼ˆå¸ƒå°”å€¼ï¼‰ã€‚

**2. è‡ªåŠ¨æ•°æ®æ ¡éªŒ (Data Validation)**
è¿™æ˜¯ `BaseModel` **æœ€æ ¸å¿ƒ**çš„åŠŸèƒ½ã€‚å½“ä½ å°è¯•åˆ›å»ºä¸€ä¸ª `BaseModel` å®ä¾‹æ—¶ï¼ŒPydantic ä¼šè‡ªåŠ¨æ£€æŸ¥ä¼ å…¥çš„æ•°æ®æ˜¯å¦ç¬¦åˆä½ å®šä¹‰çš„ç±»å‹å’Œç»“æ„ã€‚
- **å¦‚æœæ•°æ®ç±»å‹æ­£ç¡®ï¼š** å®ƒä¼šå°†è¾“å…¥æ•°æ®ï¼ˆæ¯”å¦‚ JSON å­—ç¬¦ä¸²ã€å­—å…¸ï¼‰**è½¬æ¢**ä¸ºæ­£ç¡®çš„ Python ç±»å‹ï¼ˆä¾‹å¦‚å°† JSON å­—ç¬¦ä¸² "1" è½¬æ¢ä¸ºæ•´æ•° 1ï¼‰ã€‚
- **å¦‚æœæ•°æ®æ ¡éªŒå¤±è´¥ï¼š** å®ƒä¼šæŠ›å‡ºä¸€ä¸ªæ¸…æ™°çš„ `ValidationError`ï¼Œå‘Šè¯‰ä½ å“ªä¸ªå­—æ®µå‡ºäº†é—®é¢˜ï¼Œä»¥åŠä¸ºä»€ä¹ˆã€‚è¿™æå¤§åœ°å‡å°‘äº†è¿è¡Œæ—¶é”™è¯¯å’Œè°ƒè¯•æ—¶é—´ã€‚

**3. è‡ªåŠ¨æ•°æ®è½¬æ¢ (Data Coercion)**
`BaseModel` ä¸ä»…è¿›è¡Œæ ¡éªŒï¼Œè¿˜å°è¯•è¿›è¡Œåˆç†çš„ç±»å‹è½¬æ¢ï¼š
- **å­—ç¬¦ä¸²åˆ°æ•°å­—ï¼š** å­—ç¬¦ä¸² `"123"` ä¼šè¢«è‡ªåŠ¨è½¬æ¢ä¸ºæ•´æ•° `123`ã€‚
- **å­—ç¬¦ä¸²åˆ°æ—¥æœŸ/æ—¶é—´ï¼š** éµå¾ª ISO æ ¼å¼çš„æ—¥æœŸå­—ç¬¦ä¸²ä¼šè¢«è‡ªåŠ¨è½¬æ¢ä¸º `datetime` å¯¹è±¡ã€‚

**4. å¼ºå¤§çš„åºåˆ—åŒ–å’Œååºåˆ—åŒ–**
`BaseModel` å®ä¾‹å†…ç½®äº†å°†æ•°æ®å¯¹è±¡è½¬æ¢ä¸ºå…¶ä»–æ ¼å¼çš„æ–¹æ³•ï¼š
- **åºåˆ—åŒ– (Serialization):**
    - `user_instance.model_dump()`: å°†æ¨¡å‹å®ä¾‹è½¬æ¢ä¸ºæ ‡å‡†çš„ Python **å­—å…¸ (dict)**ã€‚
    - `user_instance.model_dump_json()`: å°†æ¨¡å‹å®ä¾‹è½¬æ¢ä¸º **JSON å­—ç¬¦ä¸²**ï¼Œæ–¹ä¾¿ç½‘ç»œä¼ è¾“ã€‚
- **ååºåˆ—åŒ– (Deserialization):**
    - `User(**data_dict)`: ä»å­—å…¸åˆ›å»ºæ¨¡å‹å®ä¾‹ã€‚
    - `User.model_validate(data_dict)`: ä»å­—å…¸æˆ– JSON æ•°æ®ä¸­éªŒè¯å¹¶åˆ›å»ºæ¨¡å‹å®ä¾‹ã€‚

**5. ä¸ FastAPI ç­‰æ¡†æ¶é›†æˆ**
åœ¨ FastAPI ä¸­ï¼Œ`BaseModel` æ˜¯å®šä¹‰**è¯·æ±‚ä½“ (Request Body)** å’Œ **å“åº”ä½“ (Response Body)** çš„æ ‡å‡†æ–¹å¼ã€‚
- å½“ç”¨ä½œè¯·æ±‚ä½“æ—¶ï¼ŒFastAPI è‡ªåŠ¨ä½¿ç”¨ `BaseModel` æ¥æ ¡éªŒå®¢æˆ·ç«¯å‘é€çš„ JSON æ•°æ®ã€‚
- å½“ç”¨ä½œå“åº”ä½“æ—¶ï¼ŒFastAPI è‡ªåŠ¨ä½¿ç”¨ `BaseModel` æ¥åºåˆ—åŒ–ä½ çš„ Python å¯¹è±¡ä¸º JSON å“åº”ã€‚
**æ€»ç»“:**
`BaseModel` çš„ä½œç”¨å°±æ˜¯å°† Python åº”ç”¨ç¨‹åºä¸­çš„æ•°æ®å¤„ç†ä»**æ¾æ•£ã€æ˜“é”™çš„å­—å…¸æ“ä½œ**ï¼Œå‡çº§ä¸º**ç»“æ„åŒ–ã€ç±»å‹å®‰å…¨ä¸”è‡ªå¸¦éªŒè¯çš„å¼ºå¤§å¯¹è±¡æ¨¡å‹**ã€‚



#### é—®é¢˜ï¼šllama2å¹¶éæ˜¯ä¸“å±çš„embeddingæ¨¡å‹ï¼Œä¹Ÿå¯ä»¥ç”¨OllamaEmbeddingsæ¥åŠ è½½ä¹ˆï¼Ÿ


è¿™æ˜¯ä¸€ä¸ªéå¸¸ä¸“ä¸šå’Œå…³é”®çš„é—®é¢˜ï¼Œå®ƒæ¶‰åŠåˆ°å¤§æ¨¡å‹çš„**å¤šåŠŸèƒ½æ€§**å’Œ **Ollama å¹³å°çš„çµæ´»æ€§**ã€‚
**ç­”æ¡ˆæ˜¯ï¼šæ˜¯çš„ï¼Œæ‚¨å¯ä»¥å°† Llama 2 (æˆ– Llama 3 ç­‰èŠå¤©/ç”Ÿæˆæ¨¡å‹) ç”¨ä½œ `OllamaEmbeddings` çš„æ¨¡å‹ï¼Œä½†å®ƒå¹¶éæœ€ä½³å®è·µã€‚**
ä»¥ä¸‹æ˜¯è¯¦ç»†çš„è§£é‡Šå’Œå»ºè®®ï¼š

**1. ä¸ºä»€ä¹ˆ Llama 2 å¯ä»¥ç”¨äºåµŒå…¥ï¼Ÿï¼ˆæŠ€æœ¯å¯è¡Œæ€§ï¼‰**
Ollama å¹³å°æä¾›äº†ä¸€ä¸ªé€šç”¨çš„ **`/api/embeddings`** REST API ç«¯ç‚¹ã€‚
å½“æ‚¨åœ¨ `OllamaEmbeddings` ä¸­æŒ‡å®šä¸€ä¸ª**éä¸“ç”¨**çš„èŠå¤©æ¨¡å‹ï¼ˆå¦‚ `llama2`ï¼‰æ—¶ï¼ŒOllama å®ˆæŠ¤è¿›ç¨‹ä¼šæ‰§è¡Œä»¥ä¸‹æ“ä½œï¼š
- **æå–éšè—çŠ¶æ€ (Hidden State):** Ollama ä¼šè¿è¡Œ Llama 2 æ¨¡å‹ï¼Œä½†ä¸æ‰§è¡Œæœ€ç»ˆçš„**è¯­è¨€æ¨¡å‹å¤´ï¼ˆLM Headï¼‰**å±‚ï¼ˆè¯¥å±‚è´Ÿè´£é¢„æµ‹ä¸‹ä¸€ä¸ªè¯å…ƒï¼‰ã€‚
- **æ± åŒ– (Pooling):** å®ƒä¼šä»æ¨¡å‹çš„å€’æ•°ç¬¬äºŒå±‚ï¼ˆæˆ–æ ¹æ®é…ç½®çš„ç‰¹å®šå±‚ï¼‰æå–**è¯å…ƒéšè—çŠ¶æ€ï¼ˆToken Hidden Statesï¼‰**ã€‚ç„¶åï¼Œå®ƒé€šå¸¸ä¼šåº”ç”¨ä¸€ä¸ª**æ± åŒ–ç­–ç•¥**ï¼ˆå¦‚å¹³å‡æ± åŒ–ï¼‰å°†è¿™äº›è¯å…ƒå‘é‡èšåˆä¸ºä¸€ä¸ªå•ä¸€çš„å¥å­å‘é‡ï¼Œä½œä¸ºæœ€ç»ˆçš„åµŒå…¥ï¼ˆEmbeddingï¼‰ã€‚
**LangChain çš„ `OllamaEmbeddings` é€šè¿‡è°ƒç”¨è¿™ä¸ªé€šç”¨çš„ Ollama APIï¼Œå®ç°äº†å¯¹ Llama 2 çš„åµŒå…¥åŠŸèƒ½è°ƒç”¨ã€‚**

**2. ä¸ºä»€ä¹ˆ Llama 2 ä¸æ¨èç”¨äºåµŒå…¥ï¼Ÿï¼ˆæ•ˆæœè€ƒé‡ï¼‰**
å°½ç®¡æŠ€æœ¯ä¸Šå¯è¡Œï¼Œä½† Llama 2 æˆ–å…¶ä»–èŠå¤©æ¨¡å‹ï¼ˆå¦‚ Mistralï¼‰åœ¨æ²¡æœ‰ç»è¿‡ç‰¹å®šå¾®è°ƒçš„æƒ…å†µä¸‹ï¼Œä½œä¸ºåµŒå…¥æ¨¡å‹çš„æ•ˆæœé€šå¸¸è¿œä¸å¦‚ä¸“ç”¨åµŒå…¥æ¨¡å‹ã€‚

|**åµŒå…¥æ¨¡å‹ç±»å‹**|**Llama 2 (ç”Ÿæˆæ¨¡å‹)**|**ä¸“ç”¨åµŒå…¥æ¨¡å‹ (å¦‚ Nomic Embed, mxbai-embed-large)**|
|---|---|---|
|**è®­ç»ƒç›®æ ‡**|**ç”Ÿæˆæ–‡æœ¬**ï¼ˆé¢„æµ‹ä¸‹ä¸€ä¸ªè¯å…ƒï¼‰ã€‚|**è¯­ä¹‰ç›¸ä¼¼æ€§**ï¼ˆè®­ç»ƒç›®æ ‡æ˜¯è®©è¯­ä¹‰ç›¸è¿‘çš„å¥å­åœ¨å‘é‡ç©ºé—´ä¸­è·ç¦»æ›´è¿‘ï¼‰ã€‚|
|**æ•ˆæœ/ç²¾åº¦**|**è¾ƒå·®ã€‚** å‘é‡ç©ºé—´æ²¡æœ‰é’ˆå¯¹ç›¸ä¼¼æ€§æœç´¢è¿›è¡Œä¼˜åŒ–ï¼Œæ£€ç´¢ç²¾åº¦ä½ã€‚|**ä¼˜ç§€ã€‚** åœ¨ MTEB ç­‰åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼ŒRAG æ•ˆæœå¥½ã€‚|
|**èµ„æºæ¶ˆè€—**|**é«˜ã€‚** Llama 2 å°ºå¯¸è¾ƒå¤§ï¼ˆå¦‚ 7Bï¼‰ï¼Œæ¨ç†æ…¢ï¼Œå†…å­˜å ç”¨é«˜ã€‚|**ä½ã€‚** ä¸“ç”¨æ¨¡å‹é€šå¸¸æ›´å°ï¼ˆå¦‚ 300Mï¼‰ï¼Œé€Ÿåº¦å¿«ï¼Œèµ„æºæ¶ˆè€—ä½ã€‚|
**ç®€è€Œè¨€ä¹‹ï¼š** Llama 2 ç”Ÿæˆçš„å‘é‡å¯èƒ½æ— æ³•å‡†ç¡®æ•æ‰ä¸åŒå¥å­ä¹‹é—´çš„**è¯­ä¹‰ç›¸ä¼¼æ€§**ï¼Œè¿™ä¼šä¸¥é‡æŸå®³æ‚¨çš„ RAG æ£€ç´¢è´¨é‡ã€‚

**3. æ¶æ„å¸ˆå»ºè®®**
ä½œä¸ºä¸€åèµ„æ·±æ¶æ„å¸ˆï¼Œæˆ‘çš„å»ºè®®æ˜¯ï¼š
1. **å¯¹äº RAG æˆ–è¯­ä¹‰æœç´¢ï¼š** **å§‹ç»ˆä¼˜å…ˆä½¿ç”¨ä¸“ç”¨çš„åµŒå…¥æ¨¡å‹ã€‚** æ‚¨å·²ç»çœ‹åˆ°äº†ï¼ŒOllama æ”¯æŒè®¸å¤šé«˜æ€§èƒ½ã€å°å·§ä¸”ä¸“é—¨ä¸ºåµŒå…¥ä»»åŠ¡ä¼˜åŒ–çš„æ¨¡å‹ï¼ˆå¦‚ `mxbai-embed-large` æˆ– `embeddinggemma`ï¼‰ã€‚è¿™èƒ½æä¾›æ›´å¥½çš„ç²¾åº¦å’Œæ›´å¿«çš„é€Ÿåº¦ã€‚
2. **å®éªŒå’Œè‡ªå®šä¹‰ï¼š** å¦‚æœæ‚¨åªæ˜¯è¿›è¡Œ**å®éªŒ**ï¼Œæˆ–è€…æ‚¨çš„ Llama 2 æ˜¯ç»è¿‡ä¸“é—¨çš„ **å¯¹æ¯”å­¦ä¹ ï¼ˆContrastive Learningï¼‰å¾®è°ƒ**ç‰ˆæœ¬ï¼ˆä¾‹å¦‚ï¼Œ`AnglE-LLaMA` ç­‰ï¼‰ï¼Œé‚£ä¹ˆä½¿ç”¨ Llama 2 æ˜¯æœ‰æ„ä¹‰çš„ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä½ éœ€è¦ç¡®ä¿ä½ çš„ Llama 2 æ¨¡å‹æ–‡ä»¶åœ¨ Ollama ä¸­å·²ç»åŒ…å«äº†å¿…è¦çš„åµŒå…¥é…ç½®ã€‚
**ç»“è®ºï¼šä½¿ç”¨ `OllamaEmbeddings(model="llama2")` æ˜¯å¯è¡Œçš„ï¼Œä½†ä¸ºäº†æ‚¨çš„åº”ç”¨æ€§èƒ½å’Œå‡†ç¡®æ€§ï¼Œè¯·ä½¿ç”¨ä¸€ä¸ªä¸“ç”¨çš„ Ollama åµŒå…¥æ¨¡å‹ã€‚**


