[{"content":"ä¸ªäººé¡¹ç›®æ–‡æ¡£\nRAGç±»é¡¹ç›® é¡¹ç›®1 è‹¥å¹²RAGå°é¡¹ç›® é¡¹ç›®2 RAGåŸç†æ€§é¡¹ç›® é¡¹ç›®3 Rerankerå’ŒEmbedding æ¨¡å‹è’¸é¦ é¡¹ç›®4 embeddingé¡¹ç›®å¾®è°ƒ+æ··åˆæ£€ç´¢ é¡¹ç›®5 function callingå¾®è°ƒï¼š åŸºäºgemma3æ¨¡å‹çš„function-callingå¾®è°ƒ Agentç±»é¡¹ç›® é¡¹ç›®6 æ™ºèƒ½å®¢æœç³»ç»Ÿ ","permalink":"https://chesterwang.github.io/chester-blog/posts/2025-11-13-%E4%B8%AA%E4%BA%BA%E5%BC%80%E5%8F%91%E9%A1%B9%E7%9B%AE%E5%B1%95%E7%A4%BA/","summary":"ä¸ªäººé¡¹ç›®æ–‡æ¡£ RAGç±»é¡¹ç›® é¡¹ç›®1 è‹¥å¹²RAGå°é¡¹ç›® é¡¹ç›®2 RAGåŸç†æ€§é¡¹ç›® é¡¹ç›®3 Rerankerå’ŒEmbedding æ¨¡å‹è’¸é¦ é¡¹ç›®4 embeddingé¡¹ç›®å¾®è°ƒ+æ··åˆæ£€ç´¢ é¡¹ç›®5 function callingå¾®è°ƒï¼š åŸºäºgemma3æ¨¡å‹çš„function-callingå¾®è°ƒ Agentç±»é¡¹ç›® é¡¹ç›®6 æ™ºèƒ½å®¢æœç³»ç»Ÿ","title":"ã€ç½®é¡¶ã€‘ä¸ªäººå¼€å‘é¡¹ç›®å±•ç¤º"},{"content":"Agenté¡¹ç›®æ­å»º æ™ºèƒ½å®¢æœé¡¹ç›® ç¬”è®°\n","permalink":"https://chesterwang.github.io/chester-blog/posts/2025-11-17-agent%E9%A1%B9%E7%9B%AE%E5%BC%80%E5%8F%91%E8%AE%B0%E5%BD%95/","summary":"Agenté¡¹ç›®æ­å»º æ™ºèƒ½å®¢æœé¡¹ç›® ç¬”è®°","title":"Agenté¡¹ç›®å¼€å‘è®°å½•"},{"content":"Function-Calling å¾®è°ƒ 2025-11-14-Huggingface-Agents-Course ä¸­çš„Function-Calling å¾®è°ƒ è®­ç»ƒç¬”è®°\nåŸå§‹ ipynbæ–‡ä»¶ bonus-unit1.ipynb - Colab\næ¨¡å‹ä¸‹è½½ é•œåƒç«™ hf-mirros.com ä¸‹è½½é€Ÿåº¦æ›´å¿«ã€‚å‘½ä»¤å¦‚ä¸‹ HF_ENDPOINT=https://hf-mirror.com huggingface-cli download google/gemma-2-2b-it å…³äºæ•°æ®é›†è‹¥å¹²é—®é¢˜ è¿™é‡Œçš„åŸå§‹æ•°æ®é›† åªæœ‰ä¸€ä¸ªsplitï¼Œå°±æ˜¯trainã€‚ å³ç±»å‹æ˜¯ DatasetDictï¼Œåªæœ‰ä¸€ä¸ªkey=\u0026ldquo;train\u0026rdquo;ã€‚ æ•°æ®ä¸‹è½½ æ•°æ®å·²ç»å­˜åœ¨æœ¬åœ°ç¼“å­˜ï¼Œæ‰€ä»¥å°±ç®—æ˜¯æ‰§è¡Œæ˜¯æŠ›å‡ºç½‘ç»œé”™è¯¯ï¼Œä¹Ÿä¸ä¼šå½±å“åŠ è½½æ•°æ®é›†ã€‚ ä½†ä¼šéå¸¸è€—æ—¶ï¼Œéœ€è¦å¾ˆå¤šçš„ç½‘ç»œå°è¯•ã€‚ ä¹Ÿå¯ä»¥é€šè¿‡è®¾ç½®ç¯å¢ƒå˜é‡ HF_DATASETS_OFFLINE=1 æ¥é¿å…ç½‘ç»œè¯·æ±‚ã€‚ datasetDict.map æ˜¯ä½œç”¨äº valueçš„datasetç±»å‹çš„ã€‚ NousResearch/hermes-function-calling-v1 æ˜¯æŒ‡åŸå§‹æ•°æ®ï¼Œä¸åŒ…å«thinkè¿‡ç¨‹ã€‚æœ¬é¡¹ç›®ä¸­åŠ è½½çš„æ•°æ®æ˜¯åŸºäºè¯¥æ•°æ®é›†åˆ›å»ºçš„æ–°æ•°æ®é›†ï¼Œæ˜¯åŠ å…¥äº†deepseekçš„æ€è€ƒè¿‡ç¨‹çš„ã€‚ ä»åŠ è½½çš„æ•°æ®ä¸­ï¼Œå¯ä»¥çœ‹å‡ºè¯´å¥ä¸­æœ‰çš„æ—¶å€™å¼€å¯äº†æ€è€ƒï¼Œæœ‰çš„æ—¶å€™æ²¡æœ‰å¼€å¯æ€è€ƒï¼Œè¯´æ˜ä¸åŒä»»åŠ¡æœ‰ä¸åŒçš„éš¾åº¦ï¼Œè¿™ç§æ•°æ®ç‰¹æ€§ä½¿å¾—æ¨¡å‹ä¹Ÿå¯ä»¥å­¦ä¹ åˆ°è¿™ç§èƒ½åŠ›ã€‚ è®­ç»ƒ gemma2æ¨¡å‹åœ¨T4GPUä¸­æ— æ³•è®­ç»ƒï¼Œæ‰€ä»¥ä½¿ç”¨äº† gemma3-1b-it æ¨¡å‹ï¼Œä½¿å¾—å¯ä»¥åœ¨T4 GPUä¸­è¿è¡Œã€‚å¹¶ä¸”ä¸¤è€…çš„ special_tokenå°½é‡å…¼å®¹ã€‚ é‚£ä¹ˆä¸å…¼å®¹ä¼šæ€æ ·ï¼Ÿ æ¯”å¦‚ä½¿ç”¨ llamaç±»å‹çš„chatè®­ç»ƒæ•°æ®æ¥å¾®è°ƒgemmaæ¨¡å‹ï¼Œæ˜¯å¦ä¼šå‡ºé—®é¢˜ï¼Ÿ è­¦å‘Šä¿¡æ¯ï¼šThe tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 1}. å…¶å®æ˜¯è¯´ åŸå§‹çš„æ¨¡å‹åŸå§‹çš„tokenizerä¸­çš„special_tokenå’Œ SFTTrainerä¸­å¯¹äºè®­ç»ƒæ•°æ®å¤„ç†ä½¿ç”¨çš„ tokenizer æ˜¯ä¸åŒçš„ã€‚ æ¨¡å‹ model = AutoModelForCausalLM.from_pretrained(model_name, attn_implementation='eager', device_map=\u0026quot;auto\u0026quot;) ä¸­ä½¿ç”¨çš„æ˜¯åŸå§‹æ¨¡å‹æ–‡ä»¶ä¸­å®šä¹‰çš„tokenizerã€‚ SFTTrainer ä¸­åŠ å…¥äº† \u0026lt;tools\u0026gt; \u0026lt;think\u0026gt; \u0026lt;tool_call\u0026gt; \u0026lt;tool_response\u0026gt; ä½†æˆ‘åœ¨æ¨¡å‹åŸå§‹çš„tokenizerä¸­æ‰¾ä¸åˆ° start_of_turn end_of_turnä¸¤ä¸ªç‰¹æ®Šçš„tokenã€‚ è®­ç»ƒæ•°æ®çš„æ¶ˆæ¯æ ¼å¼éå¸¸ç›¸ä¼¼ï¼Œä½†ä½¿ç”¨è¯¥æ¨¡æ¿è€ƒè™‘äº†å¯¹è®­ç»ƒæ•°æ®ä¸­ï¼Œå»é™¤äº†ä¸åˆç†çš„æ¶ˆæ¯ã€‚å…·ä½“å¦‚ä¸‹ æ–°çš„æ¶ˆæ¯æ ¼å¼\n{{ bos_token }}{% if messages[0][\u0026#39;role\u0026#39;] == \u0026#39;system\u0026#39; %}{{ raise_exception(\u0026#39;System role not supported\u0026#39;) }}{% endif %}{% for message in messages %}{% if (message[\u0026#39;role\u0026#39;] == \u0026#39;user\u0026#39;) != (loop.index0 % 2 == 0) %}{{ raise_exception(\u0026#39;Conversation roles must alternate user/assistant/user/assistant/...\u0026#39;) }}{% endif %}{% if (message[\u0026#39;role\u0026#39;] == \u0026#39;assistant\u0026#39;) %}{% set role = \u0026#39;model\u0026#39; %}{% else %}{% set role = message[\u0026#39;role\u0026#39;] %}{% endif %}{{ \u0026#39;\u0026lt;start_of_turn\u0026gt;\u0026#39; + role + \u0026#39; \u0026#39; + message[\u0026#39;content\u0026#39;] | trim + \u0026#39;\u0026lt;end_of_turn\u0026gt; \u0026#39; }}{% endfor %}{% if add_generation_prompt %}{{\u0026#39;\u0026lt;start_of_turn\u0026gt;model \u0026#39;}}{% endif %} æ¨¡å‹åŸæœ‰çš„æ¶ˆæ¯æ ¼å¼(gemma2)ã€‚Gemma3çš„æ¶ˆæ¯æ¨¡å‹æ›´å¤æ‚ï¼Œä¸è¿‡åŸºæœ¬ç»“æ„ç›¸åŒã€‚\n{{ bos_token }}{% if messages[0][\u0026#39;role\u0026#39;] == \u0026#39;system\u0026#39; %}{{ raise_exception(\u0026#39;System role not supported\u0026#39;) }}{% endif %}{% for message in messages %}{{ \u0026#39;\u0026lt;start_of_turn\u0026gt;\u0026#39; + message[\u0026#39;role\u0026#39;] + \u0026#39;\\n\u0026#39; + message[\u0026#39;content\u0026#39;] | trim + \u0026#39;\u0026lt;end_of_turn\u0026gt;\u0026lt;eos\u0026gt;\\n\u0026#39; }}{% endfor %}{% if add_generation_prompt %}{{\u0026#39;\u0026lt;start_of_turn\u0026gt;model\\n\u0026#39;}}{% endif %} è®­ç»ƒæ•°æ®ç»“æ„è¯´æ˜\nå…³é”®æ˜¯å…¶ä¸­çš„toolså’Œtool_call éƒ¨åˆ†ã€‚\næ•°æ®æ¥æº https://huggingface.co/datasets/Jofthomas/hermes-function-calling-thinking-V1\n[ { \u0026#34;content\u0026#34;: \u0026#34;You are a function calling AI model. You are provided with function signatures within \u0026lt;tools\u0026gt;\u0026lt;/tools\u0026gt; XML tags.You may call one or more functions to assist with the user query. Don\u0026#39;t make assumptions about what values to plug into functions.Here are the available tools: \u0026lt;tools\u0026gt; [ { \u0026#39;type\u0026#39;: \u0026#39;function\u0026#39;, \u0026#39;function\u0026#39;: { \u0026#39;name\u0026#39;: \u0026#39;get_stock_price\u0026#39;, \u0026#39;description\u0026#39;: \u0026#39;Get the current stock price of a company\u0026#39;, \u0026#39;parameters\u0026#39;: { \u0026#39;type\u0026#39;: \u0026#39;object\u0026#39;, \u0026#39;properties\u0026#39;: { \u0026#39;company\u0026#39;: { \u0026#39;type\u0026#39;: \u0026#39;string\u0026#39;, \u0026#39;description\u0026#39;: \u0026#39;The name of the company\u0026#39; } }, \u0026#39;required\u0026#39;: [\u0026#39;company\u0026#39;] } } }, { \u0026#39;type\u0026#39;: \u0026#39;function\u0026#39;, \u0026#39;function\u0026#39;: { \u0026#39;name\u0026#39;: \u0026#39;get_movie_details\u0026#39;, \u0026#39;description\u0026#39;: \u0026#39;Get details about a movie\u0026#39;, \u0026#39;parameters\u0026#39;: { \u0026#39;type\u0026#39;: \u0026#39;object\u0026#39;, \u0026#39;properties\u0026#39;: { \u0026#39;title\u0026#39;: { \u0026#39;type\u0026#39;: \u0026#39;string\u0026#39;, \u0026#39;description\u0026#39;: \u0026#39;The title of the movie\u0026#39; } }, \u0026#39;required\u0026#39;: [\u0026#39;title\u0026#39;] } } } ] \u0026lt;/tools\u0026gt; Use the following pydantic model json schema for each tool call you will make: {\u0026#39;title\u0026#39;: \u0026#39;FunctionCall\u0026#39;, \u0026#39;type\u0026#39;: \u0026#39;object\u0026#39;, \u0026#39;properties\u0026#39;: { \u0026#39;arguments\u0026#39;: {\u0026#39;title\u0026#39;: \u0026#39;Arguments\u0026#39;, \u0026#39;type\u0026#39;: \u0026#39;object\u0026#39;}, \u0026#39;name\u0026#39;: {\u0026#39;title\u0026#39;: \u0026#39;Name\u0026#39;, \u0026#39;type\u0026#39;: \u0026#39;string\u0026#39;} }, \u0026#39;required\u0026#39;: [\u0026#39;arguments\u0026#39;, \u0026#39;name\u0026#39;] } For each function call return a json object with function name and arguments within \u0026lt;tool_call\u0026gt;\u0026lt;/tool_call\u0026gt; XML tags as follows:\\n\u0026lt;tool_call\u0026gt;\\n{tool_call}\\n\u0026lt;/tool_call\u0026gt;\u0026#34;, \u0026#34;role\u0026#34;: \u0026#34;system\u0026#34; }, { \u0026#34;content\u0026#34;: \u0026#34;Hi, can you tell me the current stock price of Apple?\u0026#34;, \u0026#34;role\u0026#34;: \u0026#34;human\u0026#34; }, { \u0026#34;content\u0026#34;: \u0026#34;\u0026lt;think\u0026gt;Alright, the user asked for the current stock price of Apple. Looking at the tools available, there\u0026#39;s a function called get_stock_price which exactly fits this request. I\u0026#39;ll need to call this function with the parameter company set to \u0026#39;Apple\u0026#39; to retrieve the information the user is asking for. This seems like the most straightforward and appropriate action to take.\\n\u0026lt;/think\u0026gt; \u0026lt;tool_call\u0026gt;\\n{\u0026#39;name\u0026#39;: \u0026#39;get_stock_price\u0026#39;, \u0026#39;arguments\u0026#39;: {\u0026#39;company\u0026#39;: \u0026#39;Apple\u0026#39;}}\\n\u0026lt;/tool_call\u0026gt;\u0026#34;, \u0026#34;role\u0026#34;: \u0026#34;model\u0026#34; }, { \u0026#34;content\u0026#34;: \u0026#34;\u0026lt;tool_response\u0026gt;\\n{\u0026#39;stock_price\u0026#39;: \u0026#39;$150.75\u0026#39;}\\n\u0026lt;/tool_response\u0026gt;\u0026#34;, \u0026#34;role\u0026#34;: \u0026#34;tool\u0026#34; }, { \u0026#34;content\u0026#34;: \u0026#34;The current stock price of Apple is $150.75.\u0026#34;, \u0026#34;role\u0026#34;: \u0026#34;model\u0026#34; }, { \u0026#34;content\u0026#34;: \u0026#34;That\u0026#39;s great. Can you also tell me the stock price for Microsoft?\u0026#34;, \u0026#34;role\u0026#34;: \u0026#34;human\u0026#34; }, { \u0026#34;content\u0026#34;: \u0026#34;\u0026lt;think\u0026gt;Alright, let me try to figure out how to handle this user\u0026#39;s request. The user first asked about Apple\u0026#39;s stock price, and I responded by calling the get_stock_price function with \u0026#39;Apple\u0026#39; as the argument. The tool provided the price, and I passed that information back to the user.\\n\\nNow, the user is asking for the stock price of Microsoft. I need to determine the appropriate action here. Looking at the tools available, there\u0026#39;s still the get_stock_price function, which is designed to fetch current stock prices. Since the user is requesting another company\u0026#39;s stock price, it makes sense to use the same function again but with the company name changed to Microsoft. \\n\\nI shouldn\u0026#39;t assume any other tools are needed because the available functions are specifically tailored for stock prices and movie details. In this case, the relevant function is get_stock_price. I should ensure that the function is called with the correct parameter, \u0026#39;Microsoft\u0026#39; in this case, to retrieve the accurate information the user is seeking. This approach is efficient and aligns directly with the user\u0026#39;s request without making unnecessary assumptions or using unrelated tools.\\n\u0026lt;/think\u0026gt; \u0026lt;tool_call\u0026gt;\\n{\u0026#39;name\u0026#39;: \u0026#39;get_stock_price\u0026#39;, \u0026#39;arguments\u0026#39;: {\u0026#39;company\u0026#39;: \u0026#39;Microsoft\u0026#39;}}\\n\u0026lt;/tool_call\u0026gt;\u0026#34;, \u0026#34;role\u0026#34;: \u0026#34;model\u0026#34; }, { \u0026#34;content\u0026#34;: \u0026#34;\u0026lt;tool_response\u0026gt;\\n{\u0026#39;stock_price\u0026#39;: \u0026#39;$210.22\u0026#39;}\\n\u0026lt;/tool_response\u0026gt;\u0026#34;, \u0026#34;role\u0026#34;: \u0026#34;tool\u0026#34; }, { \u0026#34;content\u0026#34;: \u0026#34;The current stock price of Microsoft is $210.22.\u0026#34;, \u0026#34;role\u0026#34;: \u0026#34;model\u0026#34; }, { \u0026#34;content\u0026#34;: \u0026#34;Thank you for the information.\u0026#34;, \u0026#34;role\u0026#34;: \u0026#34;human\u0026#34; }, { \u0026#34;content\u0026#34;: \u0026#34;You\u0026#39;re welcome! If you have any other questions, feel free to ask.\u0026#34;, \u0026#34;role\u0026#34;: \u0026#34;model\u0026#34; } ] ","permalink":"https://chesterwang.github.io/chester-blog/posts/2025-11-14-llm%E8%AE%AD%E7%BB%83%E5%BE%AE%E8%B0%83%E5%BC%80%E5%8F%91%E8%AE%B0%E5%BD%95/","summary":"Function-Calling å¾®è°ƒ 2025-11-14-Huggingface-Agents-Course ä¸­çš„Function-Calling å¾®è°ƒ è®­ç»ƒç¬”è®° åŸå§‹ ipynbæ–‡ä»¶ bonus-unit1.ipynb - Colab æ¨¡å‹ä¸‹è½½ é•œåƒç«™ hf-mirros.com ä¸‹è½½é€Ÿåº¦æ›´å¿«ã€‚å‘½ä»¤å¦‚ä¸‹ HF_ENDPOINT=https://hf-mirror.com huggingface-cli download google/gemma-2-2b-it å…³äºæ•°æ®é›†è‹¥å¹²é—®é¢˜ è¿™é‡Œçš„åŸå§‹æ•°æ®é›† åªæœ‰ä¸€ä¸ªsplitï¼Œå°±æ˜¯trainã€‚ å³ç±»å‹æ˜¯ DatasetDictï¼Œåªæœ‰ä¸€ä¸ªkey=\u0026ldquo;train\u0026rdquo","title":"LLMè®­ç»ƒå¾®è°ƒå¼€å‘è®°å½•"},{"content":"é¡¹ç›®ç¯å¢ƒæ­å»º å¦‚ä½•å°†requirements.txtä¸­çš„ä¾èµ–è½¬ç§»åˆ° uvç¯å¢ƒä¸­ uv add -r requirements.txt å¦‚æœå¤ªæ…¢åˆ™åŠ  url uv add -r requirements.txt --index-url https://pypi.tuna.tsinghua.edu.cn/simple ollamaæ­å»º æŠ¥é”™ ollamaä¿®æ”¹æ¨¡å‹ä¸‹è½½ç›®å½•ä¹‹åæŠ¥é”™ error: pull model manifest: 503: no healthy upstream é‡å¯æœåŠ¡å³å¯ sudo systemctl stop ollama sudo systemctl start ollama ä¿®æ”¹æ¨¡å‹ç›®å½• sudo ln -s /home/chester/ollama/models /usr/share/ollama/.ollama/ sudo chown ollama /usr/share/ollama/.ollama/models sudo chgrp ollama /usr/share/ollama/.ollama/models åä¸¤æ¡æ˜¯ä¿è¯ç›®å½•çš„æƒé™é—®é¢˜ï¼Œä¸ç„¶ollmaè¿è¡Œä¼šæŠ¥é”™ èµ„æ–™æ¥æº Does anyone know how to change where your models are saved on linux? : r/ollama Ollama(model=\u0026ldquo;qwen3:0.6b\u0026rdquo;) è¿™æ®µä»£ç å‰ææ˜¯ ç³»ç»Ÿä¸­ åå°å¯åŠ¨äº†ollamaæœåŠ¡ï¼ˆlinuxå®‰è£…ä¹‹åä¼šè‡ªåŠ¨åŠ å…¥ç³»ç»ŸæœåŠ¡ï¼Œæ— éœ€æ‰‹åŠ¨å¯åŠ¨è¯¥æœåŠ¡ï¼‰ï¼Œä½†å¹¶ä¸éœ€è¦ å‘½ä»¤è¡Œæ‰§è¡Œ ollama run modelã€‚åº”è¯¥æ˜¯åå°ä¼šè‡ªåŠ¨åŠèµ·å¯¹åº”çš„æ¨¡å‹è¿›è¡Œè®¡ç®—å¹¶ä¼ å›pythonã€‚ æœ¬åœ°è¿è¡ŒollamaçœŸçš„å¤ªæ…¢äº†ã€‚ embeddingæ¨ç†æœåŠ¡æ–¹æ³• HuggingFaceBgeEmbeddings åœ¨pycharmä¸­è¿è¡Œçš„æ—¶å€™ï¼Œè¦ç»™jupyter server æ·»åŠ å‚æ•°ï¼Œé…ä¸Šhttp_proxyçš„ä»£ç†ã€‚åœ¨pycharmè½¯ä»¶å±‚é¢è®¾ç½®http_proxyæ˜¯æ²¡ç”¨çš„ã€‚ huggingfaceä¼šä¸‹è½½æ¨¡å‹å»ºç«‹æœ¬åœ°æœåŠ¡è¿›è¡Œè®¡ç®—ã€‚ HuggingFaceInferenceAPIEmbeddings æ˜¯é€šè¿‡apiè¿›è¡Œembeddingè®¡ç®—ï¼Œè€Œä¸æ˜¯æœ¬åœ°è¿›è¡Œè®¡ç®—ã€‚ é—®é¢˜ï¼šhttpcore ä¸€ç›´æŠ¥é”™æ²¡æœ‰å®‰è£… æœ€åå‘ç°æ˜¯httpcoreæ²¡æœ‰å®‰è£…å¥½ï¼Œå¯¹åº”çš„pythonåŒ…åªæœ‰å…ƒæ•°æ®æ²¡æœ‰çœŸå®ä»£ç ï¼Œå°†å¯¹åº”ç›®å½•åˆ é™¤åé‡åˆ·uvç¯å¢ƒå³å¯ã€‚ P01 RAG-Projects ä»¥ä¸‹ä¸ºå°çš„RAGå­é¡¹ç›®\nProject 01 chatbot é—®é¢˜ï¼šload_dotenvçš„æœºåˆ¶\nload_dotenv å®šä¹‰å¦‚ä¸‹ é»˜è®¤åŠ è½½ .envæ–‡ä»¶ï¼Œå¦‚æœå½“å‰ç›®å½•ä¸å­˜åœ¨ï¼Œå°±ä¸æ–­æå‡ç›®å½•å±‚æ¬¡æ¥æŸ¥æ‰¾ã€‚ interpolate ç”¨äºæ˜¯å¦è§£æå­—ç¬¦ä¸²ä¸­çš„å˜é‡ï¼Œæ¯”å¦‚ PATH=${PATH}:/usr/share/bin ï¼Œå°±ä¼šæŠŠPATHå˜é‡è¿›è¡Œè§£ææ›¿æ¢ã€‚ å…¶ä¸­ dotenv.main.resolve_variables å¯¹äºinterpolate åŠŸèƒ½çš„å®ç°å¾ˆæœ‰æ„æ€ï¼Œä½¿ç”¨äº†æ­£åˆ™æ–¹æ³•æ¥åŒ¹é…å¹¶åˆ†åˆ«è¿›è¡Œæ›¿æ¢ã€‚ def load_dotenv( dotenv_path: Optional[StrPath] = None, stream: Optional[IO[str]] = None, verbose: bool = False, override: bool = False, interpolate: bool = True, encoding: Optional[str] = \u0026#34;utf-8\u0026#34;, ) -\u0026gt; bool: \u0026#34;\u0026#34;\u0026#34;Parse a .env file and then load all the variables found as environment variables. Parameters: dotenv_path: Absolute or relative path to .env file. stream: Text stream (such as `io.StringIO`) with .env content, used if `dotenv_path` is `None`. verbose: Whether to output a warning the .env file is missing. override: Whether to override the system environment variables with the variables from the `.env` file. encoding: Encoding to be used to read the file. Returns: Bool: True if at least one environment variable is set else False If both `dotenv_path` and `stream` are `None`, `find_dotenv()` is used to find the .env file with it\u0026#39;s default parameters. If you need to change the default parameters of `find_dotenv()`, you can explicitly call `find_dotenv()` and pass the result to this function as `dotenv_path`. If the environment variable `PYTHON_DOTENV_DISABLED` is set to a truthy value, .env loading is disabled. \u0026#34;\u0026#34;\u0026#34; Project 02 APIs ChatMessagePromptTemplate å’Œ ChatPromptTemplate æ˜¯ä¸¤ä¸ªä¸åŒçš„ç±»ï¼Œä¸»è¦åŒºåˆ«å¦‚ä¸‹ï¼š ChatMessagePromptTemplate ç”¨äºè¡¨ç¤ºå•ä¸ªèŠå¤©æ¶ˆæ¯çš„æ¨¡æ¿ å¯¹åº”å•æ¡æ¶ˆæ¯ï¼ŒåŒ…å«æ¶ˆæ¯çš„è§’è‰²ï¼ˆå¦‚ç³»ç»Ÿã€ç”¨æˆ·ã€åŠ©æ‰‹ï¼‰å’Œå†…å®¹æ¨¡æ¿ æ˜¯æ„æˆèŠå¤©æ¨¡æ¿çš„åŸºæœ¬å•å…ƒ ChatPromptTemplate ç”¨äºè¡¨ç¤ºæ•´ä¸ªèŠå¤©å¯¹è¯çš„æ¨¡æ¿ å¯ä»¥åŒ…å«å¤šä¸ª ChatMessagePromptTemplate å®ä¾‹ ç”¨äºæ„å»ºå®Œæ•´çš„å¯¹è¯å†å²æ¨¡æ¿ï¼Œæ”¯æŒå¤šè½®å¯¹è¯åœºæ™¯ ç®€è€Œè¨€ä¹‹ï¼ŒChatMessagePromptTemplate æ˜¯å•æ¡æ¶ˆæ¯æ¨¡æ¿ï¼Œè€Œ ChatPromptTemplate æ˜¯æ•´ä¸ªå¯¹è¯æ¨¡æ¿ï¼Œåè€…å¯ä»¥åŒ…å«å¤šä¸ªå‰è€…æ¥æ„å»ºå®Œæ•´çš„å¯¹è¯ä¸Šä¸‹æ–‡ã€‚ ChatPromptTemplate from_messages ä»è‹¥å¹²messageä¸­æ„é€ æ¨¡æ¿ from_template ä»å•ä¸ª message çš„ template æ¥æ„é€  HumanMessageï¼Œå¹¶ç»„è£…ä¸ºä¸€ä¸ªChatã€‚ FewShotChatMessagePromptTemplate langchain_core.promptsä¸­çš„å„ç§promptã€‚ ChatOpenAIçš„ä½¿ç”¨æ–¹æ³• langchain_openai.chat_models.base.ChatOpenAI â€” ğŸ¦œğŸ”— LangChain 0.2.17 StrOutputParser å¦‚ä½•è§£æchainä¹‹å‰éƒ¨åˆ†çš„å†…å®¹ langchain_core.outputs.chat_generation.ChatGeneration.set_text ä¸­æŒ‡æ˜äº†ä»messageä¸­çš„contentå±æ€§æ¥è·å–å†…å®¹ã€‚ Project 04 Retriever and Chain create_stuff_documents_chain RunnablePassthrough å³ identity functionï¼Œæ’ç­‰å‡½æ•°ï¼Œè¾“å…¥ä»€ä¹ˆå°±è¾“å‡ºä»€ä¹ˆã€‚ RunnablePassthrough.assign ï¼š Merge the Dict input with the output produced by the mapping argument. chainçš„è°ƒç”¨è¿‡ç¨‹ è¾“å…¥ï¼šè¾“å…¥æ•°æ®ä¸ºdictï¼Œæœ‰inputè¿™ä¸ªkeyã€‚ retrieval_docs ï¼šå…ˆå¯¹ æ•°æ®è¿›è¡Œæ£€ç´¢ï¼Œå³ä»xä¸­è·å– inputè¿™ä¸€é¡¹ï¼Œç„¶åé€å…¥æ£€ç´¢å™¨ã€‚æ£€ç´¢å™¨æœ¬è´¨ä¸Šæ˜¯è°ƒç”¨äº† __ror__æ–¹æ³•ï¼Œè¿›ä¸€æ­¥è°ƒç”¨äº† VectorStoreRetrieverçš„ _get_relevant_documents æ–¹æ³•ï¼Œè¿›ä¸€æ­¥è°ƒç”¨äº† self.vectorstore.similarity_searchæ–¹æ³•ã€‚æ£€ç´¢å®Œä¹‹åï¼Œå°†ç›¸ä¼¼æ–‡æ¡£ç»„è£…ä¸ºä¸€ä¸ªitemæ”¾å…¥åˆ° contextè¿™ä¸ªkeyä¸‹ã€‚ æ•°æ®å˜ä¸º {input:XXX, context:[docs]}ã€‚ format_docs ï¼šæ£€ç´¢å‡ºç›¸ä¼¼æ–‡æ¡£ä¹‹åï¼Œé€å…¥format_inputsè¿‡ç¨‹ï¼Œå³å°†æ•°æ®ä¸­çš„contexté¡¹æ ¼å¼ä¸ºå­—ç¬¦ä¸²ï¼Œå¹¶ç”¨ åŒæ¢è¡Œç¬¦è¿›è¡Œåˆ†éš”è¿æ¥ã€‚æ•°æ®å˜ä¸º {input:XXX, context:doc_str} promptï¼š é€å…¥promptï¼Œpromptçš„invokeæ–¹æ³•ä¸­æœ¬è´¨å°±æ˜¯å¯¹ templateå­—ç¬¦ä¸²å’Œ ä¸Šä¸€æ­¥è®¡ç®—å‡ºçš„æ•°æ®è¿›è¡Œæ ¼å¼åŒ–ã€‚ llmï¼šæ¨¡å‹ç»™å‡ºå“åº” _output_parser æœ¬è´¨å°±æ˜¯å¯¹ è¾“å‡ºçš„responseæ¶ˆæ¯è¿›è¡Œæ ¼å¼åŒ–ï¼Œæœ¬è´¨å°±æ˜¯æå–æ¶ˆæ¯ä¸­çš„keyä¸º\u0026quot;text\u0026quot;å¯¹åº”çš„å±æ€§ã€‚ ç›¸å…³å…³é”®ä»£ç å¦‚ä¸‹\nresponse=retriever.invoke(input=\u0026#34;\u0026#34;\u0026#34;image processing with an introduction to techniques for image pattern classification\u0026#34;\u0026#34;\u0026#34;) #langchain_classic/chains/retrieval.py:64 if not isinstance(retriever, BaseRetriever): retrieval_docs: Runnable[dict, RetrieverOutput] = retriever else: retrieval_docs = (lambda x: x[\u0026#34;input\u0026#34;]) | retriever return ( RunnablePassthrough.assign( context=retrieval_docs.with_config(run_name=\u0026#34;retrieve_documents\u0026#34;), ).assign(answer=combine_docs_chain) ).with_config(run_name=\u0026#34;retrieval_chain\u0026#34;) def format_docs(inputs: dict) -\u0026gt; str: return document_separator.join( format_document(doc, _document_prompt) for doc in inputs[document_variable_name] ) return ( RunnablePassthrough.assign(**{document_variable_name: format_docs}).with_config( run_name=\u0026#34;format_inputs\u0026#34;, ) | prompt | llm | _output_parser ).with_config(run_name=\u0026#34;stuff_documents_chain\u0026#34;) Project 05 Advanced RAG Q\u0026amp;A Project create_retriever_tool æœ¬è´¨å°±æ˜¯ å°†æ£€ç´¢ã€æ ¼å¼åŒ–ã€æ‹¼æ¥å·¥ä½œç»„è£…ä¸ºä¸€ä¸ªæ•´ä½“åŠŸèƒ½ç„¶åï¼Œå®ä¾‹åŒ–ä¸ºä¸€ä¸ªtoolã€‚ Scratchpad å«ä¹‰ ç›´è¯‘ä¸ºè‰ç¨¿çº¸ åœ¨ LangChain æˆ–ç±»ä¼¼æ¡†æ¶ä¸­ï¼Œscratchpad é€šå¸¸æŒ‡ä»£ç†(Agent)çš„ä¸´æ—¶å·¥ä½œç©ºé—´ï¼Œç”¨äºï¼š å­˜å‚¨ä¸­é—´æ€è€ƒè¿‡ç¨‹ è®°å½•å½“å‰ä»»åŠ¡çŠ¶æ€ ä¿å­˜ä¸´æ—¶è®¡ç®—ç»“æœ è¿›è¡Œæ¨ç†å’Œå†³ç­–çš„ç¼“å†²åŒº è¿™æ˜¯ä¸€ä¸ªé€šç”¨çš„è®¡ç®—æœºç§‘å­¦æ¦‚å¿µï¼Œè¡¨ç¤ºä»»ä½•ç”¨äºä¸´æ—¶å­˜å‚¨å’Œå¤„ç†çš„å†…å­˜åŒºåŸŸã€‚ æœ€ç»ˆtoolsæ˜¯åœ¨ ollama._types.ChatRequest è¿›è¡Œè§£æï¼Œå…·ä½“è§ä¸‹é¢ä»£ç ã€‚ è¿™é‡Œçš„llmèµ°çš„æ˜¯chatç±»å‹çš„llmï¼Œæ‰€ä»¥åº•å±‚æ˜¯èµ° /api/chat æ¥å£ï¼Œè¯¥æ¥å£çš„å‚æ•°åˆ—è¡¨ä¸­å«æœ‰toolsã€‚ç›¸å½“äºè¯¥æ¥å£å·²ç»æŠŠtoolsçš„æè¿°å¦‚ä½•æ ¼å¼åŒ–éƒ½å·²ç»åœ¨å†…éƒ¨è§£å†³æ‰ï¼Œä¸éœ€è¦è°ƒç”¨æ–¹å°†toolsçš„æè¿°æ ¼å¼åŒ–åˆ° prompté‡Œé¢ã€‚ AgentExecutoré‡Œæœ€é‡è§†ä¾èµ– iteræ–¹æ³•æ¥ä¸æ–­è¿­ä»£ï¼Œåº•å±‚æ˜¯ä¾èµ–_iter_next_stepæ¥è¿›è¡Œ thoughtã€actionæ­¥éª¤çš„ã€‚ å³chat_modelçš„æ¥å£éƒ½æ˜¯æ”¯æŒåœ¨è¯·æ±‚ä¸­åŠ å…¥toolså‚æ•°çš„ã€‚ prompt hub https://smith.langchain.com/hub/hwchase17/openai-functions-agent å‡½æ•°è°ƒç”¨ - OpenAI API \u0026mdash; Function calling - OpenAI API ç›¸å…³å…³é”®ä»£ç å¦‚ä¸‹\n#Runnableçš„æ–¹æ³• def bind(self, **kwargs: Any) -\u0026gt; Runnable[Input, Output]: \u0026#34;\u0026#34;\u0026#34;Bind arguments to a `Runnable`, returning a new `Runnable`. Useful when a `Runnable` in a chain requires an argument that is not in the output of the previous `Runnable` or included in the user input. \u0026#34;\u0026#34;\u0026#34; #langchain_ollama.chat_models.ChatOllama._create_chat_stream # ollama/_client.py:351 # ollama._client.Client.chat return self._request( ChatResponse, \u0026#39;POST\u0026#39;, \u0026#39;/api/chat\u0026#39;, json=ChatRequest( model=model, messages=list(_copy_messages(messages)), tools=list(_copy_tools(tools)), stream=stream, think=think, format=format, options=options, keep_alive=keep_alive, ).model_dump(exclude_none=True), stream=stream, ) #langchain_classic.agents.agent.AgentExecutor._iter_next_step def _iter_next_step( self, name_to_tool_map: dict[str, BaseTool], color_mapping: dict[str, str], inputs: dict[str, str], intermediate_steps: list[tuple[AgentAction, str]], run_manager: CallbackManagerForChainRun | None = None, ) -\u0026gt; Iterator[AgentFinish | AgentAction | AgentStep]: \u0026#34;\u0026#34;\u0026#34;Take a single step in the thought-action-observation loop. Override this to take control of how the agent makes and acts on choices. \u0026#34;\u0026#34;\u0026#34; try: intermediate_steps = self._prepare_intermediate_steps(intermediate_steps) # Call the LLM to see what to do. output = self._action_agent.plan( intermediate_steps, callbacks=run_manager.get_child() if run_manager else None, **inputs, ) except OutputParserException as e: ...... # If the tool chosen is the finishing tool, then we end and return. if isinstance(output, AgentFinish): yield output return actions: list[AgentAction] actions = [output] if isinstance(output, AgentAction) else output for agent_action in actions: yield agent_action for agent_action in actions: yield self._perform_agent_action( name_to_tool_map, color_mapping, agent_action, run_manager, ) ... Project 06 Groq inference æœ¬åœ°æœåŠ¡å’Œè¿œç¨‹æœåŠ¡çš„ä»£ç†è®¾ç½®ï¼Œå¦‚ä¸‹é¢ä»£ç  HTTP_PROXY å’Œ HTTPS_PROXYç”¨äºè®¾ç½®é€šè¿‡httpæœåŠ¡çš„ä»£ç† NO_PROXY ç”¨äºæœ¬åœ°æœåŠ¡ç»•è¿‡ä¸Šé¢è®¾ç½®çš„ä»£ç†ï¼Œå¦‚æœ¬åœ°çš„OllamaæœåŠ¡ã€‚ vectorstore.as_retriever å¯ä»¥ç›´æ¥è½¬æ¢ä¸ºæ£€ç´¢å™¨ æ–¹æ³•å‚æ•°search_kwargs ä¸­ä¹Ÿå¯ä»¥è®¾ç½®è¿”å›çš„æ–‡æ¡£æ•°ç›®kã€MMRå¤šæ ·æ€§ç®—æ³•ã€å…ƒæ•°æ®è¿‡æ»¤å™¨å‡½æ•°ç­‰ã€‚ import os # è®¾ç½®httpçš„ä»£ç†å’Œä¸ä»£ç†çš„åœ°å€ os.environ[\u0026#39;HTTP_PROXY\u0026#39;] = \u0026#34;http://127.0.0.1:7890\u0026#34; os.environ[\u0026#39;HTTPS_PROXY\u0026#39;] = \u0026#34;http://127.0.0.1:7890\u0026#34; os.environ[\u0026#39;NO_PROXY\u0026#39;] = \u0026#34;http://127.0.0.1:11434\u0026#34; #ollamaçš„æœ¬åœ°æœåŠ¡åœ°å€ Project 07 Gen AI HuggingFaceEndpoint æ¥å£é—®é¢˜ bug https://github.com/langchain-ai/langchain/issues/31434#issuecomment-2936308959 å› ä¸ºå®˜æ–¹æœåŠ¡ä¸å†æä¾› text-generationçš„æ¨¡å‹æœåŠ¡ã€‚ å¯ä»¥ä½¿ç”¨ ChatHuggingFaceæ¥ç»•è¿‡è¿™ä¸ªé—®é¢˜ã€‚ Project 08 Powerful Doc Q\u0026amp;A Chatbot OllamaEmbeddings åœ¨æœ¬åœ°çš„ç¬”è®°æœ¬ä¸Šå¯¹äº4ç¯‡è®ºæ–‡çš„è®¡ç®—éå¸¸æ…¢ã€‚ ä½¿ç”¨äº†HuggingFaceEmbeddingsåŠ ä¸€ä¸ªå°embæ¨¡å‹è®¡ç®—æ—¶é—´å˜å°‘äº†å¾ˆå¤šã€‚ Project 09 Advance Q\u0026amp;A Chatbot langchain-ObjectBox ç‰ˆæœ¬å¤ªè€ï¼Œæ²¡æ³•å®‰è£…ã€‚è¯¥æ•°æ®åº“ ObjectBox ç»´æŠ¤ä¼¼ä¹ä¸æ˜¯å¾ˆå¤šã€‚ Project 11 ImageEnhancer model_scope å…¼å®¹æ¥å£ APIæ¨ç†ä»‹ç» Â· æ–‡æ¡£ä¸­å¿ƒ å…¼å®¹openaiæ¥å£ streamlit åº”ç”¨ debug é€‰æ‹©module streamlit å‚æ•°å¡«å†™ run app.py working directory å¡«å†™app.pyçš„ç›®å½• ä½¿ç”¨modelscopeæœåŠ¡æ¥ä»£æ›¿openaiçš„å›¾åƒç”Ÿæˆæ¥å£ã€‚ æ–‡ç”Ÿå›¾æ¨¡å‹ æ”¯æŒAPIè°ƒç”¨çš„æ¨¡å‹åˆ—è¡¨ï¼Œå¯ä»¥é€šè¿‡AIGCæ¨¡å‹é¡µé¢è¿›è¡Œæœç´¢ã€‚ ä¸Šè¿°é¡µé¢ä¸­åˆ—å‡ºçš„å¾ˆå¤šæ¨¡å‹éƒ½å¾®è°ƒçš„å¾ˆå·®ï¼Œä½¿ç”¨åç”Ÿæˆç»“æœå¾ˆå¤šå¹¶ä¸èƒ½éµä»æŒ‡ä»¤ã€‚ è°ƒæ•´äº† gpu_memory_utilization ä»0.9 åˆ°0.95 æŠ¥é”™ ValueError: To serve at least one request with the models's max seq len (40960), (5.62 GiB KV cache is needed, which is larger than the available KV cache memory (4.81 GiB). å·®ä¸€ç‚¹å†…å­˜ï¼Œæ‰€ä»¥å¢åŠ äº†gpuçš„åˆ©ç”¨ç‡ã€‚ ä»è¿™ç‚¹çœ‹ï¼Œå¤§æ¨¡å‹ä¸€æ¬¡æ¨ç†éå¸¸æ¶ˆè€—æ˜¾å­˜ã€‚ ä¸€æ¡æ•°æ®çš„æœ€å¤§æ˜¾å­˜æ¶ˆè€— æ˜¾å­˜æ¶ˆè€—=2(key+value) * seq_len(40960) * model_layer * hidden_size * head_dim * 2(byte FP16) P02 demo_simple_rag_py è¯¥é¡¹ç›®å±•ç¤ºRAGåŸç†çš„æç®€ä»£ç ã€‚\nå‚è€ƒèµ„æ–™ å…³è”åšæ–‡ Code a simple RAG from scratch é¡¹ç›®ä»£ç  demo.py Â· ngxson/demo_simple_rag_py at main å¾ˆå¥½çš„å±•ç¤ºRAGåŸç†æ€§çš„å°demoï¼Œä¸éœ€è¦å®‰è£…å‘é‡æ•°æ®åº“ã€‚ æ¨¡å‹ID bartowski/Llama-3.2-1B-Instruct-GGUF è¿™ä¸ªæ¨¡å‹ä¸­çš„instructçš„æ„æ€ instructæ„æ€å°±æ˜¯æŒ‡æ¨¡å‹æ˜¯ç»è¿‡ åœ¨base modelä¸Šç»è¿‡æŒ‡ä»¤å¾®è°ƒï¼ˆæˆ–è€…å«ç›‘ç£å¾®è°ƒï¼‰è¿‡ç¨‹ä¹‹åäº§ç”Ÿçš„æ¨¡å‹ï¼Œå¯ä»¥ç›´æ¥ç”¨äºèŠå¤©ã€åŠ©æ‰‹ç±»åº”ç”¨ Ollamaé—®é¢˜ æ¨¡å‹ä¸‹è½½é—®é¢˜ ollama æ‹‰å–hf.co ç½‘ç«™çš„æ¨¡å‹å¤±è´¥ Ollama pull è¿›åº¦å·²ç»100%ï¼Œ ä½†ä¸ºä»€ä¹ˆä¼šæŠ¥å¦‚ä¸‹é”™è¯¯ Error: max retries exceeded: Get \u0026quot;https://huggingface.co/v2/bartowski/Llama-3.2-1B-Instruct-GGUF/blobs/sha256:948af2743fc78a328dcb3b0f5a31b3d75f415840fdb699e8b1235978392ecf85?__sign=eyJhbGciOiJFZERTQSJ9.eyJyZWFkIjp0cnVlLCJwZXJtaXNzaW9ucyI6eyJyZXBvLmNvbnRlbnQucmVhZCI6dHJ1ZX0sImlhdCI6MTc2Mjc1MzA3Niwic3ViIjoiL2JhcnRvd3NraS9MbGFtYS0zLjItMUItSW5zdHJ1Y3QtR0dVRiIsImV4cCI6MTc2Mjc1MzY3NiwiaXNzIjoiaHR0cHM6Ly9odWdnaW5nZmFjZS5jbyJ9.wVhqKCuc0vtHoS8DUStd86RoS1dhE0e-IqqMIpLZ_mEbfz6ahWeaoQiuTpWuaJCels7Q7uIIwEky9DhHsynYCg\u0026quot;: dial tcp 54.89.135.129:443: connect: connection refused æ£€æŸ¥ç½‘ç»œæ˜¯å¯ä»¥è¿æ¥ hf.coç½‘ç«™çš„ã€‚ æ‰¾ä¸åˆ°åŸå› ã€‚ ollama ä¹Ÿå¯ä»¥åœ¨æœ¬åœ°å¯¹æ¨¡å‹è¿›è¡Œé‡åŒ–ã€‚ quantizing-a-model - Ollama ollamaå¯¹ä»“åº“æ¨¡å‹çš„é€‰æ‹© ollama run model_repo_idï¼Œå¦‚æœrepoä¸­æœ‰å¤šç‰ˆæœ¬æ¨¡å‹ï¼Œé‚£ä¹ˆollamaä¼šé€‰æ‹©Q4ç‰ˆæœ¬çš„ã€‚æ›´å¥½çš„æ–¹æ³•æ˜¯æ˜¾å¼æŒ‡å®šå…·ä½“ç‰ˆæœ¬ ollama run hf.co/{username}/{repository}:{quantization} æ¯”å¦‚ ollama run hf.co/bartowski/Llama-3.2-3B-Instruct-GGUF:Llama-3.2-3B-Instruct-IQ3_M.gguf å‚è€ƒèµ„æ–™ Use Ollama with any GGUF Model on Hugging Face Hub æ¨¡å‹æ–‡ä»¶é—®é¢˜ GGUF æ–‡ä»¶åŒ…å«äº†tokenizerçš„æ•°æ®ã€‚ æ¨¡å‹çš„Ollamaæ„å»ºæ–¹æ³•ï¼šæ‰‹åŠ¨ä¸‹è½½ggufæ¨¡å‹æ–‡ä»¶ï¼Œç„¶åæœ¬åœ°è¿›è¡Œollamaæ‰‹åŠ¨æ„å»ºã€‚ æ‰‹åŠ¨ä¸‹è½½ https://huggingface.co/bartowski/Llama-3.2-1B-Instruct-GGUF/tree/main ä¸­çš„ Llama-3.2-1B-Instruct-Q4_K_M.ggufæ–‡ä»¶ã€‚ ç„¶åæ ¹æ®æ–‡æ¡£Importing a Model - Ollamaæ¥å¯¼å…¥åˆ°æœ¬åœ°ollamaçš„ç¼“å­˜ç›®å½•ã€‚ åˆ›å»ºä¸€ä¸ªä¸´æ—¶ç©ºç›®å½• åˆ›å»º ModelFileæ–‡ä»¶ï¼Œå†…å®¹ä¸º FROM ./Llama-3.2-1B-Instruct-Q4_K_M.gguf æ‰§è¡Œå‘½ä»¤ollama create bartowski/Llama-3.2-1B-Instruct-GGUF æ¨¡å‹å°±å¯ä»¥è¢«æ„å»ºç¼“å¹¶å¤åˆ¶åˆ° ollamaçš„ç¼“å­˜ç›®å½•ä¸­ã€‚ å¹¶åŒæ ·æ„å»º bge-base-en-v1.5-q4_k_m.gguf æ¨¡å‹ ollama.embed(model=\u0026quot;CompendiumLabs/bge-base-en-v1.5-gguf\u0026quot;) è¿™é‡Œçš„æ¨¡å‹åæŒ‰ç…§/æ¥åˆ†å‰²ï¼Œå³è¯´æ˜æ˜¯æœ¬åœ°æ–‡ä»¶çš„æ¨¡å‹ã€‚ å¦‚æœæ˜¯æ­£å¸¸çš„:åˆ†å‰²çš„æ¨¡å‹åï¼Œåˆ™ollamaä¼šè‡ªåŠ¨ä»ç¼“å­˜ç›®å½•ä¸­çš„ libraryå­ç›®å½•ä¸­æŸ¥æ‰¾ã€‚ åœ¨ChatModelçš„streamæ¨¡å¼ä¸‹ï¼Œè¿”å›æ˜¯ä¸€ä¸ªè¯ä¸€ä¸ªè¯çš„è¿›è¡Œè¿”å›çš„ã€‚ åœ¨è¯¥demoç¤ºä¾‹ä¸­ï¼Œæ£€ç´¢åˆ°çš„æ–‡æ¡£æ˜¯å…¨è¢«å¡åˆ°ä¸€ä¸ªsystem messageä¸‹ï¼Œç„¶ååç»­çš„å¯¹è¯ä½†å°±æ˜¯æ ¹æ®æ­¤æ¥è¿›è¡Œäº¤äº’ã€‚ P03 RAG-Optimization-Practices é¡¹ç›®åŸç†å’Œç»“æœ ç›¸å…³èµ„æ–™ é¡¹ç›®æ¥æº kanhaoning/RAG-Optimization-Practices Quickstart â€” Sentence Transformers documentation å®˜æ–¹æ–‡æ¡£å¾ˆä¸é”™ã€‚ é˜¿é‡Œäº‘æœåŠ¡å™¨ uv ä¸‹è½½ç»å¸¸è¶…æ—¶çš„è§£å†³æ–¹æ¡ˆï¼Œéå¸¸å¥½ç”¨ã€‚ export UV_HTTP_TIMEOUT=240 export UV_CONCURRENT_DOWNLOADS=2 å¦‚ä½•åŠ å¿«å®‰è£…uvç¯å¢ƒã€ç¼“å­˜ åœ¨ä¸€å°ä¾¿å®œçš„æœºå™¨ä¸Šä½¿ç”¨uvæ¥æ„å»ºä¸€ä¸ªdummyé¡¹ç›®ï¼Œuvçš„ç¼“å­˜å°±ä¼šç•™ä¸‹ã€‚ rsync uvç¼“å­˜ç›®å½•åˆ° ç›®æ ‡æœåŠ¡å™¨çš„uvç¼“å­˜ç›®å½•ä¸‹ã€‚åŒä¸€ä¸ªvpcä¸‹ä¸¤ä¸ªæœåŠ¡å™¨çš„rsyncé€Ÿåº¦éå¸¸å¿«ï¼Œ300M/sã€‚å¹¶ä¸”rsyncä¼šä¿æŒæ–‡ä»¶çš„è½¯é“¾æ¥ã€‚ è¿™æ ·æ•´ä½“èŠ±é’±å°‘ï¼Œå¹¶ä¸”æ„å»ºé€Ÿåº¦å¿«ã€‚ Qwen-rerankerå’Œbertä¸€æ ·æ˜¯åŒå‘æ³¨æ„åŠ›è®¡ç®—æ–¹å¼ã€‚ å¯¹äºä¸€ä¸ªbatchå†…çš„æ•°æ®ï¼Œæœ‰å¾ˆå¤šæ¡æ•°æ®æœ‰å…±åŒçš„å‰ç¼€ï¼Œé‚£ä¹ˆvLLMä¸­æœ‰é’ˆå¯¹è¿™ç§æƒ…å†µçš„ä¼˜åŒ–æ¨ç†ç­–ç•¥ é˜¿é‡Œäº‘ossfsçš„ä»£ç å­˜æ¡£ã€‚ å®‰è£…ossfs wget https://github.com/aliyun/ossfs/releases/download/v1.91.8/ossfs_1.91.8_ubuntu24.04_amd64.deb sudo apt install ./ossfs_1.91.8_ubuntu24.04_amd64.deb ç¯å¢ƒé…ç½® A10 GPUï¼ˆæ˜¾å­˜24Gï¼‰ Reranker distillationæ•´ä½“æ­¥éª¤ è¯´æ˜ æ¨¡å‹æœ¬è´¨å°±æ˜¯cross-encoderï¼Œå³å°†QAè¿›è¡Œæ‹¼æ¥ï¼Œè¾“å…¥LLMè¿›è€Œå¾—åˆ°ç›¸ä¼¼åº¦ã€‚ generate_logits ç”Ÿæˆ59ä¸‡æ¡æ•°æ®ï¼ˆè®­ç»ƒé›†+æµ‹è¯•é›†ï¼‰ï¼Œè¿è¡Œæ—¶é•¿ï¼ˆ250minï¼‰ã€‚ å³é’ˆå¯¹ query å’Œdoc ç”Ÿæˆä¸€ä¸ªlogprobåˆ†æ•°ï¼Œå³ (query, passage, score)ã€‚ logprobåˆ†æ•°åˆ©ç”¨äº† promptæ¨¡æ¿ + LLMçš„chatæ¥å£ è¿›è¡Œæ‰“åˆ†ã€‚ promptæ¨¡æ¿å¦‚ä¸‹ã€‚ Judge whether the Document meets the requirements based on the Query and the Instruct provided. Note that the answer can only be \u0026quot;yes\u0026quot; or \u0026quot;no\u0026quot;. \u0026lt;Instruct\u0026gt;: {instruction}\\n\u0026lt;Query\u0026gt;: {query}\\n\u0026lt;Document\u0026gt;: {doc} å…¶ä¸­ instructå˜é‡ä¸º Given a web search query, retrieve relevant passages that answer the query prompt é™åˆ¶äº†è¾“å‡ºtokençš„èŒƒå›´ä¸º ä¸¤ä¸ªtoken ï¼ˆyes or noï¼‰ ã€‚ æ¨ç†ä½¿ç”¨ vLLMçš„sdkï¼ŒåŠ è½½æœ¬åœ°æ¨¡å‹æ–‡ä»¶ã€‚ ä¸‰å…ƒç»„è’¸é¦æ•°æ®ï¼ˆè®­ç»ƒé›†+æµ‹è¯•é›†ï¼‰ ç”Ÿæˆä¸‰å…ƒç»„è’¸é¦æ•°æ® (query, positive passage, negative passage, logits_diff) æ­£æ ·æœ¬ä¸ºlogits æœ€é«˜top_ké‡ŒæŠ½æ ·ã€‚ è´Ÿæ ·æœ¬æŒ‰ç…§logitsæ’åº æ¯ä¸ªæ­£æ ·æœ¬ä½ç½®åé¢çš„æ ·æœ¬ã€‚ å³ä¸¤ä¸¤ç»„åˆï¼Œç»„åˆæ•°é‡ä¸º n*(n-1)/2 å¹¶éä½¿ç”¨è¯¥é¡¹ç›®æ•°æ®é›†çœŸæ­£çš„åŸå§‹ ground-truth labelã€‚ è®­ç»ƒ åˆ©ç”¨ embeddingå°æ¨¡å‹ + ä¸‰å…ƒç»„è’¸é¦æ•°æ® è¿›è¡Œè®­ç»ƒï¼Œå°†é¢†åŸŸçŸ¥è¯†è’¸é¦è¿›å°æ¨¡å‹ã€‚ è¯„ä¼° å¯¹å¾®è°ƒå‰çš„æ¨¡å‹å’Œå¾®è°ƒåçš„æ¨¡å‹åˆ©ç”¨æµ‹è¯•é›†æ•°æ®è¿›è¡Œå¯¹æ¯”ã€‚ Embedding-distillatioinæ•´ä½“æ­¥éª¤ è¯´æ˜ æ¨¡å‹å…¶å®å°±æ˜¯bi-encoderï¼Œå³æ¨¡å‹è¾“å‡ºembeddingï¼Œç„¶åè®¡ç®—QAç›¸ä¼¼åº¦ã€‚ ç”¨KLæ•£åº¦å°†Qwen3-Embedding-8Bå‘é‡å¤§æ¨¡å‹çŸ¥è¯†è’¸é¦ç»™å°æ¨¡å‹BGE-m3 - çŸ¥ä¹ generate_logits é’ˆå¯¹åŸå§‹æ•°æ®ä¸­æ¯ä¸€è¡Œä¸­çš„ ä¸€ä¸ªqueryã€å¤šä¸ªpositiveæ–‡æ¡£ã€å¤šä¸ªnegativeæ–‡æ¡£ åˆ†åˆ«è¾“å…¥ Qwen3-embeddingæ¨¡å‹ï¼Œå¾—åˆ°å‘é‡ã€‚ é’ˆå¯¹æ•°æ®å½¢å¼ ï¼ˆqueryï¼ŒpositiveDocï¼Œ[negativeDoc,negativeDoc2ï¼Œ...]ï¼‰ï¼Œåˆ†åˆ«è®¡ç®—queryå’Œæ¯ä¸ªdocçš„ä½™å¼¦ç›¸ä¼¼åº¦ï¼Œç„¶åå°† æ‰€æœ‰çš„ç›¸ä¼¼åº¦ è§†ä¸ºä¸€ä¸ªæ¦‚ç‡åˆ†å¸ƒã€‚ train.sh å¯¹äºå­¦ç”Ÿæ¨¡å‹åŒæ ·äº§ç”Ÿä¸€ä¸ªæ¦‚ç‡åˆ†å¸ƒï¼Œå’Œè€å¸ˆæ¨¡å‹çš„åˆ†å¸ƒè®¡ç®—KLæŸå¤±ï¼Œè¿›è€Œè®­ç»ƒå­¦ç”Ÿæ¨¡å‹ã€‚ è¯„ä¼° åˆ©ç”¨é¢„ç•™çš„æµ‹è¯•é›†è¿›è¡Œè¯„ä¼°ã€‚ uv ç¼“å­˜ç®¡ç†é—®é¢˜ å› ä¸º é¡¹ç›®ç›®å½•å’Œ uvç¼“å­˜ç›®å½•ä¸åœ¨åŒä¸€ä¸ªæ–‡ä»¶ç³»ç»Ÿä¸‹ï¼Œæ‰€ä»¥uvç¼“å­˜æ— æ³•é«˜æ•ˆè¿è½¬ï¼Œåªèƒ½åªç”¨ç¡¬å¤åˆ¶æ¥æ„å»ºvenvç¯å¢ƒã€‚æ‰€ä»¥éœ€è¦è¿ç§»uvç¼“å­˜åˆ°åŒä¸€ä¸ªæ–‡ä»¶ç³»ç»Ÿä¸‹ã€‚ æ¸…ç†ç¼“å­˜é¡¹ç›®ï¼Œuvç®¡ç†ã€‚ du -sh ~/.cache/uv .venv å¯ä»¥ç”¨æ¥ç»Ÿè®¡ venvæ˜¯å¦çœŸæ­£å¤šå ç”¨äº†å­˜å‚¨ã€‚ uv ç¼“å­˜è¿ç§»çš„æ—¶å€™ ä¸èƒ½ä½¿ç”¨ mv å’Œ cpå‘½ä»¤ï¼Œå¿…é¡»ä½¿ç”¨ rsync -av å‘½ä»¤ï¼Œä¸ç„¶æ— æ³•ä¿æŒ è½¯ç¡¬é“¾æ¥çš„å…³ç³»ã€‚ uv ç¼“å­˜ é€šè¿‡ .bashrc ç¯å¢ƒå˜é‡æ¥æŒ‡å®š export UV_CACHE_DIR=/mnt/fast-ssd/uv-cache ä¸Šè¿°å®Œæˆä¹‹åï¼Œé¡¹ç›®çš„uvæ„å»ºé€Ÿåº¦å¤§å¹…æå‡è‡³\u0026lt;1ç§’ã€‚ CrossEncoder Cross-Encoders â€” Sentence Transformers documentation Cross-Encoder achieve higher performance than Bi-Encoders, however, they do not scale well for large datasets. Here, it can make sense to combine Cross- and Bi-Encoders, for example in Information Retrieval / Semantic Search scenarios: First, you use an efficient Bi-Encoder to retrieve e.g. the top-100 most similar sentences for a query. Then, you use a Cross-Encoder to re-rank these 100 hits by computing the score for every (query, hit) combination. promptæ ¼å¼\n# promptæ ¼å¼ message = [ {\u0026#34;role\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;Judge whether the Document meets the requirements based on the Query and the Instruct provided. Note that the answer can only be \\\u0026#34;yes\\\u0026#34; or \\\u0026#34;no\\\u0026#34;.\u0026#34;}, {\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: f\u0026#34;\u0026lt;Instruct\u0026gt;: {instruction}\\n\u0026lt;Query\u0026gt;: {query}\\n\u0026lt;Document\u0026gt;: {doc}\u0026#34;} ] #LLMé‡‡æ ·å‚æ•°ï¼Œåªå…è®¸ yes å’Œ no é€‰é¡¹çš„logproè¾“å‡ºã€‚ # å®šä¹‰å›ºå®šçš„ token å’Œé‡‡æ ·å‚æ•° true_token = tokenizer(\u0026#34;yes\u0026#34;, add_special_tokens=False).input_ids[0] false_token = tokenizer(\u0026#34;no\u0026#34;, add_special_tokens=False).input_ids[0] sampling_params = SamplingParams( temperature=0, max_tokens=1, logprobs=20, allowed_token_ids=[true_token, false_token], ) rerankerè’¸é¦è¯„ä¼°ç»“æœ\n# reranker è’¸é¦è®­ç»ƒä¹‹åçš„è¯„ä¼°ç»“æœ (rag-optimization-practices) root@dsw-1457330-845c588466-dwlc9:/mnt/workspace/large_model_demo/RAG/RAG-Level-02/P03-RAG-Optimization-Practices/Reranker-Distillation# bash evaluate.sh æ­£åœ¨ä» data/test.jsonl åŠ è½½æ•°æ®é›†... åŠ è½½å®Œæˆï¼å…± 2992 æ¡æ ·æœ¬ã€‚ --- æ­£åœ¨åŠ è½½å¹¶è¯„ä¼°æ¨¡å‹: /mnt/workspace/modelscope/BAAI/bge-reranker-v2-m3 --- --- æ­£åœ¨åŠ è½½å¹¶è¯„ä¼°æ¨¡å‹: ./output/checkpoint-1217 --- ================================================== âœ… æœ€ç»ˆè¯„ä¼°ç»“æœæ±‡æ€» ================================================== ã€è’¸é¦å‰ã€‘æ¨¡å‹æ€§èƒ½: - MAP: 0.472061 - MRR@10: 0.478234 - NDCG@10: 0.547284 ã€è’¸é¦åã€‘æ¨¡å‹æ€§èƒ½: - MAP: 0.564523 - MRR@10: 0.573106 - NDCG@10: 0.638634 ================================================== ğŸš€ æ€§èƒ½å˜åŒ–åˆ†æ (è’¸é¦å vs. è’¸é¦å‰) ================================================== æŒ‡æ ‡ [MAP]: - ç»å¯¹æå‡: +0.092462 - ç›¸å¯¹æå‡: +19.59% â†‘ æŒ‡æ ‡ [MRR@10]: - ç»å¯¹æå‡: +0.094872 - ç›¸å¯¹æå‡: +19.84% â†‘ æŒ‡æ ‡ [NDCG@10]: - ç»å¯¹æå‡: +0.091349 - ç›¸å¯¹æå‡: +16.69% â†‘ è¯„ä¼°å®Œæˆï¼âœ¨ embeddingè’¸é¦è¯„ä¼°ç»“æœ\n(rag-optimization-practices) root@dsw-1457330-845c588466-dwlc9:/mnt/workspace/large_model_demo/RAG/RAG-Level-02/P03-RAG-Optimization-Practices/Embedding-Distillation# bash evaluation.sh ============================================================ æ¨¡å‹æ€§èƒ½å¯¹æ¯”è¯„ä¼° ============================================================ ------------------------------ é¢†åŸŸå†…æ•°æ®é›†è¯„ä¼° ------------------------------ æ­£åœ¨åŠ è½½æ¨¡å‹: /mnt/workspace/modelscope/BAAI/bge-m3 æ­£åœ¨åŠ è½½æ•°æ®é›†: data/dataset_scidocs/test.jsonl æˆåŠŸåŠ è½½ 3978 æ¡æ ·æœ¬ å¼€å§‹è¯„ä¼°... Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63/63 [00:06\u0026lt;00:00, 9.34it/s] Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1854/1854 [03:29\u0026lt;00:00, 8.85it/s] æ­£åœ¨åŠ è½½æ¨¡å‹: output/checkpoint-477 æ­£åœ¨åŠ è½½æ•°æ®é›†: data/dataset_scidocs/test.jsonl æˆåŠŸåŠ è½½ 3978 æ¡æ ·æœ¬ å¼€å§‹è¯„ä¼°... Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63/63 [00:06\u0026lt;00:00, 9.28it/s] Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1854/1854 [03:34\u0026lt;00:00, 8.63it/s] ------------------------------ é¢†åŸŸå¤–æ•°æ®é›†è¯„ä¼° ------------------------------ æ­£åœ¨åŠ è½½æ¨¡å‹: /mnt/workspace/modelscope/BAAI/bge-m3 æ­£åœ¨åŠ è½½æ•°æ®é›†: data/dataset_stackoverflowdupquestions/test.jsonl æˆåŠŸåŠ è½½ 2992 æ¡æ ·æœ¬ å¼€å§‹è¯„ä¼°... Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:04\u0026lt;00:00, 10.51it/s] Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1398/1398 [01:56\u0026lt;00:00, 12.03it/s] æ­£åœ¨åŠ è½½æ¨¡å‹: output/checkpoint-477 æ­£åœ¨åŠ è½½æ•°æ®é›†: data/dataset_stackoverflowdupquestions/test.jsonl æˆåŠŸåŠ è½½ 2992 æ¡æ ·æœ¬ å¼€å§‹è¯„ä¼°... Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:04\u0026lt;00:00, 10.15it/s] Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1398/1398 [01:57\u0026lt;00:00, 11.88it/s] ============================================================ é¢†åŸŸå†…æ•°æ®é›† æ€§èƒ½å¯¹æ¯” ============================================================ æŒ‡æ ‡ è’¸é¦å‰ è’¸é¦å ç»å¯¹å˜åŒ– ç›¸å¯¹å˜åŒ–(%) ------------------------------------------------------------ map 0.7744 0.8516 +0.0773 +9.98 mrr@10 0.9321 0.9548 +0.0227 +2.43 ndcg@10 0.8296 0.8956 +0.0660 +7.96 ============================================================ é¢†åŸŸå¤–æ•°æ®é›† æ€§èƒ½å¯¹æ¯” ============================================================ æŒ‡æ ‡ è’¸é¦å‰ è’¸é¦å ç»å¯¹å˜åŒ– ç›¸å¯¹å˜åŒ–(%) ------------------------------------------------------------ map 0.5166 0.5034 -0.0132 -2.56 mrr@10 0.5238 0.5110 -0.0127 -2.43 ndcg@10 0.5902 0.5778 -0.0124 -2.10 è¯„ä¼°å®Œæˆ é—®é¢˜ï¼šå¯¹äºä¸€ä¸ªbatchå†…çš„æ•°æ®ï¼Œæœ‰å¾ˆå¤šæ¡æ•°æ®æœ‰å…±åŒçš„å‰ç¼€ï¼Œé‚£ä¹ˆvLLMä¸­æœ‰é’ˆå¯¹è¿™ç§æƒ…å†µçš„ä¼˜åŒ–æ¨ç†ç­–ç•¥ æ˜¯çš„ï¼vLLM ç¡®å®é’ˆå¯¹ã€Œbatch å†…å¤šæ¡è¯·æ±‚å…·æœ‰å…±åŒå‰ç¼€ï¼ˆshared prefixï¼‰ã€çš„åœºæ™¯æä¾›äº†ä¸“é—¨çš„ä¼˜åŒ–ç­–ç•¥ï¼Œè¿™é¡¹æŠ€æœ¯ç§°ä¸ºï¼š\nâœ… Prefix Cachingï¼ˆå‰ç¼€ç¼“å­˜ï¼‰ æˆ– Prompt Sharing è¿™æ˜¯ vLLM çš„æ ¸å¿ƒä¼˜åŒ–ä¹‹ä¸€ï¼Œèƒ½æ˜¾è‘—èŠ‚çœæ˜¾å­˜ã€æå‡ååã€é™ä½å»¶è¿Ÿï¼Œå°¤å…¶é€‚ç”¨äºä»¥ä¸‹åœºæ™¯ï¼š\nRAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰ï¼šå¤šä¸ªæ–‡æ¡£å…±äº«ç›¸åŒçš„ prompt æ¨¡æ¿ å¤šè½®å¯¹è¯ç³»ç»Ÿï¼šå†å²ä¸Šä¸‹æ–‡ç›¸åŒï¼Œä»…ç”¨æˆ·æœ€æ–°è¾“å…¥ä¸åŒ æ‰¹é‡æ¨ç†ï¼šå¦‚ â€œæ€»ç»“ä»¥ä¸‹æ–‡æœ¬ï¼š\u0026lt;text\u0026gt;â€ï¼Œå…¶ä¸­ \u0026lt;text\u0026gt; ä¸åŒä½†æŒ‡ä»¤ç›¸åŒ ğŸ” å·¥ä½œåŸç†\n1. KV Cache å…±äº«\nLLM æ¨ç†ä¸­ï¼ŒPrefill é˜¶æ®µä¼šä¸º prompt ç”Ÿæˆ KV Cacheï¼ˆKey/Value ç¼“å­˜ï¼‰ å¦‚æœå¤šä¸ªè¯·æ±‚çš„ prompt å‰ç¼€å®Œå…¨ç›¸åŒï¼Œå®ƒä»¬çš„ KV Cache å‰ç¼€éƒ¨åˆ†ä¹Ÿå®Œå…¨ç›¸åŒ vLLM ä¼šï¼š åªè®¡ç®—ä¸€æ¬¡è¯¥å…¬å…±å‰ç¼€çš„ KV Cache å¤šä¸ªè¯·æ±‚å…±äº«è¿™ä»½ç¼“å­˜ åç»­å„è‡ªä¸åŒçš„éƒ¨åˆ†ç‹¬ç«‹è®¡ç®— ğŸ“Œ æœ¬è´¨ï¼šé¿å…é‡å¤è®¡ç®—å’Œå­˜å‚¨ç›¸åŒçš„ä¸Šä¸‹æ–‡\n2. ä¸ PagedAttention ååŒ\nvLLM ä½¿ç”¨ PagedAttention ç®¡ç† KV Cacheï¼ˆç±»ä¼¼æ“ä½œç³»ç»Ÿçš„è™šæ‹Ÿå†…å­˜åˆ†é¡µï¼‰ å…¬å…±å‰ç¼€çš„ KV Cache è¢«å­˜å‚¨åœ¨å…±äº«ç‰©ç†é¡µä¸­ æ¯ä¸ªè¯·æ±‚çš„é€»è¾‘å—ï¼ˆlogical blocksï¼‰æŒ‡å‘è¿™äº›å…±äº«é¡µ + è‡ªæœ‰é¡µ Request 1: [Shared Prefix] + [Suffix A] Request 2: [Shared Prefix] + [Suffix B] Request 3: [Shared Prefix] + [Suffix C] â†’ KV Cache: Shared Pages: [K/V of \u0026#34;Shared Prefix\u0026#34;] Private Pages: [K/V of \u0026#34;Suffix A\u0026#34;], [Suffix B], [Suffix C] ğŸš€ æ€§èƒ½æ”¶ç›Š\næŒ‡æ ‡ ä¼˜åŒ–æ•ˆæœ æ˜¾å­˜å ç”¨ â†“ æ˜¾è‘—å‡å°‘ï¼ˆå…¬å…±éƒ¨åˆ†åªå­˜ä¸€ä»½ï¼‰ Prefill è®¡ç®—é‡ â†“ å‡å°‘ï¼ˆå…¬å…±å‰ç¼€åªè®¡ç®—ä¸€æ¬¡ï¼‰ ååï¼ˆthroughputï¼‰ â†‘ æå‡ 2â€“5 å€ï¼ˆå®æµ‹å¸¸è§ï¼‰ æ”¯æŒ batch size â†‘ å¯å®¹çº³æ›´å¤šè¯·æ±‚ ğŸ’¡ å®æµ‹æ¡ˆä¾‹ï¼ˆRAG åœºæ™¯ï¼‰ï¼š\n10 ä¸ªè¯·æ±‚ï¼Œå…±äº« 2K token çš„ prompt æ¨¡æ¿ æ˜¾å­˜èŠ‚çœ \u0026gt;60%ï¼Œååæå‡ 3.2 å€ ğŸ›  å¦‚ä½•å¯ç”¨ï¼Ÿï¼ˆvLLM ä¸­é»˜è®¤å¼€å¯ï¼ï¼‰\næ— éœ€é¢å¤–é…ç½®ï¼švLLM é»˜è®¤è‡ªåŠ¨æ£€æµ‹å¹¶å¯ç”¨ Prefix Caching æ¡ä»¶ï¼š å¤šä¸ªè¯·æ±‚çš„ prompt å‰ç¼€å¿…é¡»å­—èŠ‚çº§å®Œå…¨ç›¸åŒ ä½¿ç”¨ç›¸åŒçš„æ¨¡å‹å’Œå‚æ•°ï¼ˆtemperature ç­‰ä¸å½±å“ï¼‰ ç¤ºä¾‹ï¼ˆPython clientï¼‰ï¼š\nfrom vllm import LLM, SamplingParams llm = LLM(model=\u0026#34;Qwen/Qwen-7B-Chat\u0026#34;) **å…±äº«å‰ç¼€ï¼š\u0026#34;ä½ æ˜¯ä¸€ä¸ª helpful AIã€‚è¯·å›ç­”ï¼š\u0026#34;** prompts = [ \u0026#34;ä½ æ˜¯ä¸€ä¸ª helpful AIã€‚è¯·å›ç­”ï¼šå·´é»æ˜¯å“ªä¸ªå›½å®¶çš„é¦–éƒ½ï¼Ÿ\u0026#34;, \u0026#34;ä½ æ˜¯ä¸€ä¸ª helpful AIã€‚è¯·å›ç­”ï¼šé‡å­åŠ›å­¦æ˜¯è°æå‡ºçš„ï¼Ÿ\u0026#34;, \u0026#34;ä½ æ˜¯ä¸€ä¸ª helpful AIã€‚è¯·å›ç­”ï¼šPython å¦‚ä½•è¯»å–æ–‡ä»¶ï¼Ÿ\u0026#34; ] outputs = llm.generate(prompts, SamplingParams(temperature=0.7)) **â†’ vLLM è‡ªåŠ¨å…±äº«å‰ç¼€çš„ KV Cacheï¼** âš ï¸ æ³¨æ„äº‹é¡¹\né—®é¢˜ è¯´æ˜ å‰ç¼€å¿…é¡»å®Œå…¨ä¸€è‡´ åŒ…æ‹¬ç©ºæ ¼ã€æ ‡ç‚¹ã€æ¢è¡Œç¬¦ã€‚\u0026quot;ä½ å¥½\u0026quot; â‰  \u0026quot;ä½ å¥½ \u0026quot; ä¸æ”¯æŒåŠ¨æ€æ’å…¥ å¦‚æœå‰ç¼€åœ¨è¿è¡Œæ—¶æ‹¼æ¥ï¼ˆå¦‚åŠ æ—¶é—´æˆ³ï¼‰ï¼Œåˆ™æ— æ³•å…±äº« ä¸ LoRA å…¼å®¹æ€§ è‹¥ä½¿ç”¨ä¸åŒ LoRA adapterï¼Œå³ä½¿ prompt ç›¸åŒä¹Ÿæ— æ³•å…±äº« ä»…é™ Prefill é˜¶æ®µ Decode é˜¶æ®µå› è¾“å‡ºä¸åŒï¼Œæ— æ³•å…±äº« ğŸ”§ é«˜çº§ç”¨æ³•ï¼šæ‰‹åŠ¨æ§åˆ¶ï¼ˆvLLM â‰¥ 0.4.0ï¼‰ å¯é€šè¿‡ enable_prefix_caching=True æ˜¾å¼å¯ç”¨ï¼ˆé»˜è®¤å·²å¼€ï¼‰ï¼š\nllm = LLM( model=\u0026#34;meta-llama/Llama-3-8b\u0026#34;, enable_prefix_caching=True # é»˜è®¤ True ) ä¹Ÿå¯é€šè¿‡ç¯å¢ƒå˜é‡ï¼š\nVLLM_ENABLE_PREFIX_CACHING=1 ğŸ†š ä¸å…¶ä»–ç³»ç»Ÿçš„å¯¹æ¯”\nç³»ç»Ÿ æ˜¯å¦æ”¯æŒå‰ç¼€å…±äº« vLLM âœ… æ˜¯ï¼ˆåŸºäº PagedAttentionï¼‰ HuggingFace TGI âŒ å¦ï¼ˆæ¯ä¸ªè¯·æ±‚ç‹¬ç«‹ KV Cacheï¼‰ TensorRT-LLM âœ… æ˜¯ï¼ˆéœ€æ‰‹åŠ¨æ„å»º shared contextï¼‰ SGLang âœ… æ˜¯ï¼ˆRadixAttention æœºåˆ¶ï¼‰ ğŸ’¡ vLLM çš„å®ç°æ˜¯è‡ªåŠ¨ã€é€æ˜ã€é«˜æ•ˆçš„ä»£è¡¨ã€‚\nâœ… æ€»ç»“\nvLLM æ”¯æŒ Prefix Cachingï¼Œè‡ªåŠ¨ä¼˜åŒ–å…±äº«å‰ç¼€çš„ batch è¯·æ±‚ æ— éœ€ä»£ç ä¿®æ”¹ï¼Œåªè¦ prompt å‰ç¼€ç›¸åŒå³å¯ç”Ÿæ•ˆ æ˜¾è‘—èŠ‚çœæ˜¾å­˜ + æå‡ååï¼Œç‰¹åˆ«é€‚åˆ RAGã€æ‰¹é‡æŒ‡ä»¤ç­‰åœºæ™¯ ç¡®ä¿ä½ çš„ prompt æ¨¡æ¿ä¸¥æ ¼ä¸€è‡´ï¼ˆé¿å…å°¾éƒ¨ç©ºæ ¼/æ¢è¡Œå·®å¼‚ï¼‰ å¦‚æœä½ æ­£åœ¨åš RAG æˆ–æ‰¹é‡æ¨ç†ï¼ŒPrefix Caching æ˜¯ vLLM ç»™ä½ çš„ä¸€ä»½å…è´¹æ€§èƒ½å¤§ç¤¼åŒ…ï¼ğŸ‰\né—®é¢˜ï¼šä½†æ˜¯ä¸€ä¸ªbatchå†…çš„æ•°æ®æ˜¯ä¸€èµ·è¿›è¡Œå¹¶è¡Œæ¨ç†çš„å‘€ï¼Œé‚£ä¹ˆè¿™ä¸ªæ—¶å€™ cacheè¿˜æ²¡äº§ç”Ÿå§ï¼Ÿ è¿™æ˜¯ä¸€ä¸ªéå¸¸å…³é”®ä¸”æ·±åˆ»çš„é—®é¢˜ï¼ä½ çš„ç›´è§‰æ˜¯å¯¹çš„ï¼šå¦‚æœæ•´ä¸ª batch æ˜¯â€œåŒæ—¶â€è¿›è¡Œ prefillï¼ˆå³å¹¶è¡Œå¤„ç†æ‰€æœ‰ promptï¼‰ï¼Œé‚£ä¼¼ä¹è¿˜æ²¡ç”Ÿæˆ KV Cacheï¼Œæ€ä¹ˆå…±äº«ï¼Ÿ ä½†å®é™…æƒ…å†µæ˜¯ï¼švLLM çš„ Prefix Caching å¹¶ä¸æ˜¯åœ¨â€œbatch å†…éƒ¨å¹¶è¡Œæ—¶â€åŠ¨æ€å‘ç°å…±äº«çš„ï¼Œè€Œæ˜¯åœ¨è°ƒåº¦é˜¶æ®µé€šè¿‡â€œå‰ç¼€æ ‘ï¼ˆRadix Tree / Trieï¼‰â€é¢„å…ˆç»„ç»‡è¯·æ±‚ï¼Œä½¿å¾—ç›¸åŒå‰ç¼€çš„è¯·æ±‚åœ¨é€»è¾‘ä¸Šè¢«è¯†åˆ«å¹¶å¤ç”¨å·²ç¼“å­˜çš„ KV å—ã€‚ ä¸‹é¢æˆ‘ä»¬ä¸€æ­¥æ­¥æ¾„æ¸…è¿™ä¸ªçœ‹ä¼¼çŸ›ç›¾çš„é—®é¢˜ï¼š\nâœ… æ ¸å¿ƒç­”æ¡ˆ\nPrefix Caching çš„â€œcacheâ€å¹¶ä¸æ˜¯æ¥è‡ªå½“å‰ batch å†…éƒ¨çš„å…¶ä»–è¯·æ±‚ï¼Œè€Œæ˜¯æ¥è‡ªï¼š\nä¹‹å‰å·²å®Œæˆçš„è¯·æ±‚ï¼ˆè·¨ batch å…±äº«ï¼‰ï¼Œæˆ– åœ¨å½“å‰ batch å†…éƒ¨ï¼ŒvLLM è°ƒåº¦å™¨ä¼šå…ˆå¤„ç†å…¬å…±å‰ç¼€ä¸€æ¬¡ï¼Œå†å¹¿æ’­ç»™å…¶ä»–è¯·æ±‚ï¼ˆé€»è¾‘ä¸Šä¸²è¡ŒåŒ–å‰ç¼€è®¡ç®—ï¼‰ ä½†åœ¨ çº¯é¦–æ¬¡ batchï¼ˆæ²¡æœ‰ä»»ä½•å†å² cacheï¼‰ä¸”æ‰€æœ‰è¯·æ±‚é¦–æ¬¡å‡ºç° çš„æƒ…å†µä¸‹ï¼ŒåŒä¸€ä¸ª batch å†…çš„è¯·æ±‚ç¡®å®æ— æ³•å½¼æ­¤å…±äº« KV Cache â€”â€” é™¤é vLLM æ˜¾å¼åœ°å°†å…¬å…±å‰ç¼€æå–å‡ºæ¥å•ç‹¬è®¡ç®—ä¸€æ¬¡ã€‚ è€Œ vLLM æ­£æ˜¯è¿™ä¹ˆåšçš„ï¼ ğŸ” æ·±å…¥æœºåˆ¶ï¼švLLM å¦‚ä½•åœ¨å•ä¸ª batch å†…å®ç°å‰ç¼€å…±äº«ï¼Ÿ\nå…³é”®æŠ€æœ¯ï¼šRadix Treeï¼ˆåŸºæ•°æ ‘ï¼‰ + Block-wise KV Cache Management vLLM åœ¨è°ƒåº¦ä¸€ä¸ª batch å‰ï¼Œä¼šåšä»¥ä¸‹äº‹æƒ…ï¼š\næ­¥éª¤ 1ï¼šæ„å»º Radix Tree\nå°† batch ä¸­æ‰€æœ‰ prompt æ’å…¥ä¸€æ£µ å‰ç¼€æ ‘ï¼ˆTrieï¼‰ è‡ªåŠ¨è¯†åˆ«æœ€é•¿å…¬å…±å‰ç¼€ï¼ˆLCPï¼‰ Prompts: \u0026#34;ä½ æ˜¯AIã€‚Q: å·´é»?\u0026#34; \u0026#34;ä½ æ˜¯AIã€‚Q: é‡å­?\u0026#34; \u0026#34;ä½ æ˜¯AIã€‚Q: Python?\u0026#34; â†’ Radix Tree: root â””â”€â”€ \u0026#34;ä½ æ˜¯AIã€‚Q: \u0026#34; â”œâ”€â”€ \u0026#34;å·´é»?\u0026#34; â”œâ”€â”€ \u0026#34;é‡å­?\u0026#34; â””â”€â”€ \u0026#34;Python?\u0026#34; æ­¥éª¤ 2ï¼šåˆ†å±‚ Prefillï¼ˆHierarchical Prefillï¼‰\nå…ˆå¯¹å…¬å…±å‰ç¼€ \u0026quot;ä½ æ˜¯AIã€‚Q: \u0026quot; æ‰§è¡Œä¸€æ¬¡ prefill ç”Ÿæˆå…¶å¯¹åº”çš„ KV Cache blocks å†å¯¹æ¯ä¸ªåç¼€ï¼ˆ\u0026ldquo;å·´é»?\u0026rdquo; ç­‰ï¼‰åˆ†åˆ«æ‰§è¡Œ prefill æ¯ä¸ªåç¼€çš„ attention è®¡ç®—ä¼š æ‹¼æ¥å…¬å…±å‰ç¼€çš„ KV blocks + è‡ªèº«åç¼€çš„ KV blocks ğŸ¯ è¿™ç›¸å½“äº æŠŠä¸€ä¸ªé•¿ prompt æ‹†æˆ â€œshared part + unique partâ€ï¼Œå¹¶åœ¨è®¡ç®—æ—¶ç»„åˆã€‚\næ­¥éª¤ 3ï¼šPagedAttention æ”¯æŒéè¿ç»­ KV å—\næ¯ä¸ªè¯·æ±‚çš„å®Œæ•´ KV Cache = [shared_block_ids] + [unique_block_ids] Attention è®¡ç®—æ—¶ï¼ŒPagedAttention è‡ªåŠ¨ä»å¤šä¸ªç‰©ç†é¡µè¯»å–ï¼Œå¯¹æ¨¡å‹é€æ˜ ğŸ“Œ é‡è¦æ¾„æ¸…\nè¯¯è§£ äº‹å® â€œbatch å†…æ‰€æœ‰ prompt åŒæ—¶å¹¶è¡Œè®¡ç®—â€ âŒ å®é™…æ˜¯ï¼šå…¬å…±å‰ç¼€å…ˆç®—ä¸€æ¬¡ï¼Œåç¼€å†å¹¶è¡Œï¼ˆé€»è¾‘ä¸Šåˆ†é˜¶æ®µï¼‰ â€œcache å¿…é¡»æ¥è‡ªå†å²è¯·æ±‚â€ âŒ å³ä½¿å…¨æ˜¯æ–°è¯·æ±‚ï¼ŒvLLM ä¹Ÿèƒ½åœ¨ batch å†…éƒ¨æ„é€ å…±äº« â€œPrefill æ˜¯å®Œå…¨ç‹¬ç«‹çš„â€ âŒ vLLM çš„è°ƒåº¦å™¨ä¼šä¸»åŠ¨é‡ç»„è®¡ç®—å›¾ä»¥å¯ç”¨å…±äº« ğŸ§ª å®éªŒéªŒè¯ï¼ˆæ€æƒ³å®éªŒï¼‰ å‡è®¾ batch æœ‰ 3 ä¸ªå…¨æ–°è¯·æ±‚ï¼Œæ— ä»»ä½•å†å² cacheï¼š\nprompts = [ \u0026#34;Hello world A\u0026#34;, \u0026#34;Hello world B\u0026#34;, \u0026#34;Hello world C\u0026#34; ] vLLM çš„æ‰§è¡Œæµç¨‹ï¼š\nè°ƒåº¦å™¨å‘ç°å…¬å…±å‰ç¼€ \u0026quot;Hello world \u0026quot; åˆ›å»ºä¸€ä¸ªè™šæ‹Ÿâ€œå…±äº«è¯·æ±‚â€ï¼Œprefill \u0026quot;Hello world \u0026quot; â†’ å¾—åˆ° KV blocks S å¯¹æ¯ä¸ªåç¼€ \u0026quot;A\u0026quot;, \u0026quot;B\u0026quot;, \u0026quot;C\u0026quot;ï¼š æ„é€ è¾“å…¥ï¼š\u0026quot;Hello world X\u0026quot; ä½† KV Cache = S + prefill(\u0026ldquo;X\u0026rdquo;) çš„ç»“æœ æœ€ç»ˆæ¯ä¸ªè¯·æ±‚çš„è¾“å‡ºæ­£ç¡®ï¼Œä¸” S åªè®¡ç®—äº†ä¸€æ¬¡ ğŸ’¡ è¿™æœ¬è´¨ä¸Šæ˜¯ä¸€ç§ è®¡ç®—å›¾èåˆä¼˜åŒ–ï¼Œç”± vLLM çš„ scheduler è‡ªåŠ¨å®Œæˆã€‚\nğŸ“š å®˜æ–¹ä¾æ®\nvLLM è®ºæ–‡ï¼ˆvLLM: Easy, Fast, and Cheap LLM Servingï¼‰æåˆ°ï¼š \u0026ldquo;PagedAttention enables sharing of memory blocks across requests with common prefixes.\u0026rdquo;\næºç ä¸­ RadixAttentionï¼ˆåç»­æ¼”è¿›ï¼‰å’Œ PrefixCacher ç»„ä»¶æ˜ç¡®æ”¯æŒ intra-batch prefix sharing ğŸ”— å‚è€ƒï¼švLLM Prefix Caching Design Doc\nâœ… æ€»ç»“\né—®é¢˜ å›ç­” åŒä¸€ä¸ª batch å†…çš„è¯·æ±‚èƒ½å…±äº«å‰ç¼€å—ï¼Ÿ âœ… èƒ½ï¼å³ä½¿å…¨æ˜¯æ–°è¯·æ±‚ cache æ˜¯å“ªé‡Œæ¥çš„ï¼Ÿ æ¥è‡ª å½“å‰ batch å†…éƒ¨å¯¹å…¬å…±å‰ç¼€çš„é¦–æ¬¡è®¡ç®—ï¼ˆè°ƒåº¦å™¨ä¸»åŠ¨æå–ï¼‰ æ˜¯å¦éœ€è¦å†å²è¯·æ±‚ï¼Ÿ âŒ ä¸éœ€è¦ï¼ˆè·¨ batch å…±äº«æ˜¯é¢å¤– bonusï¼‰ æ˜¯å¦ç ´åå¹¶è¡Œæ€§ï¼Ÿ âš ï¸ å…¬å…±å‰ç¼€è®¡ç®—æ˜¯ä¸²è¡Œçš„ï¼Œä½†åç¼€ä»å¯å¹¶è¡Œï¼Œæ•´ä½“ååä»å¤§å¹…æå‡ ğŸ’¡ æ‰€ä»¥ä½ çš„è§‚å¯Ÿå¾ˆæ•é”ï¼Œä½† vLLM é€šè¿‡ æ™ºèƒ½è°ƒåº¦ + Radix Tree + PagedAttention è§£å†³äº†è¿™ä¸ªâ€œé¸¡ç”Ÿè›‹â€é—®é¢˜ã€‚ è¿™æ­£æ˜¯ vLLM ç›¸æ¯”ä¼ ç»Ÿæ¨ç†å¼•æ“ï¼ˆå¦‚ HF Transformersï¼‰çš„å…ˆè¿›ä¹‹å¤„ï¼\nP04 rag-best-practices é¡¹ç›®åŸç†å’Œç»“æœ å‚è€ƒé¡¹ç›® chaoql/rag-best-practices: å¤§æ¨¡å‹æ£€ç´¢å¢å¼ºç”ŸæˆæŠ€æœ¯æœ€ä½³å®è·µã€‚\nQdrantçš„ä»£ç ç»„ç»‡éå¸¸ç³Ÿç³•ã€‚ QdrantVectorStore é‡Œé¢è¿˜å¥—äº†ä¸€ä¸ªfastembedæ¨¡å‹ã€‚ å¯¹äºæ¨¡å‹ä¸‹è½½æ¨¡å—çš„é—®é¢˜å®šä¹‰äº†ç‹¬ç«‹çš„ç¼“å­˜ç›®å½•ï¼Œä½†æ˜¯åˆå’Œhfçš„ç›®å½•æ··åˆ°äº†ä¸€å—ã€‚å¹¶ä¸”å‡½æ•°æ¥å£å†™å¾—å¾ˆä¸é€šç”¨ã€‚ æ‰€ä»¥æ”¾å¼ƒè¿™å—åŠŸèƒ½çš„è·‘é€šã€‚ åŸç† æ‰€è°“æ··åˆæ£€ç´¢å°±æ˜¯å¿«æ…¢ç»“åˆï¼Œfastembed(sparse embed) å’Œdenseembed HyDE Hypothetical Document Embeddingsï¼ˆHyDEï¼‰ æ˜¯ä¸€ç§æå‡æ£€ç´¢è´¨é‡çš„é«˜çº§åµŒå…¥æŠ€æœ¯ï¼Œç”± Gao et al. åœ¨ 2022 å¹´æå‡ºï¼ˆè®ºæ–‡ï¼šPrecise Zero-Shot Dense Retrieval without Relevance Labelsï¼‰ã€‚å®ƒçš„æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š ä¸ç›´æ¥ç”¨ç”¨æˆ·æŸ¥è¯¢ï¼ˆqueryï¼‰å»æ£€ç´¢ï¼Œè€Œæ˜¯å…ˆè®©å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç”Ÿæˆä¸€ä¸ªâ€œå‡è®¾æ€§ç­”æ¡ˆâ€ï¼ˆhypothetical documentï¼‰ï¼Œå†ç”¨è¿™ä¸ªå‡è®¾ç­”æ¡ˆçš„åµŒå…¥å‘é‡å»æ£€ç´¢çœŸå®æ–‡æ¡£ã€‚ è¿™ä¸ªé¡¹ç›®ä¸­çš„hybrid æ¨¡å¼çš„æ„æ€æ˜¯ï¼Œqueryç”Ÿæˆä¸€ä¸ªç¨€ç–å‘é‡ã€ä¸€ä¸ªç¨ å¯†å‘é‡ï¼Œä¸¤ç§åŒæ—¶è¯·æ±‚æ•°æ®åº“ï¼Œè€Œç¨€ç–å‘é‡å¯èƒ½æ˜¯æŒ‰ç…§ä¼ ç»Ÿå€’æ’ç´¢å¼•æ¥è¿›è¡Œç´¢å¼•æ„å»ºçš„ï¼Œå³æœ€ç»ˆæ—¢æœ‰ å€’æ’ç´¢å¼•æœç´¢ åˆæœ‰å‘é‡æœç´¢ã€‚ å½“ç„¶Qrant æœ¬èº«ä¹Ÿå…è®¸è¯·æ±‚å¸¦ filterï¼Œå³å…³é”®è¯æ£€ç´¢ã€ç±»åˆ«æ£€ç´¢ç­‰ã€‚ embedding æ¨¡å‹å¾®è°ƒè¿‡ç¨‹ å¯¹äºè¾“å…¥æ•°æ®æ–‡ä»¶ä¸­çš„æ¯ä¸€æ¡æ•°æ®ï¼Œé€šè¿‡chatglmæ¨¡å‹ï¼Œæ„é€ promptï¼ˆå…¶ä¸­åŒ…å«ä¸€æ¡æ–‡æ¡£ï¼‰ï¼Œè¦æ±‚æ¨¡å‹è¿”å›ä¸€äº›å’Œä¸Šä¸‹æ–‡ç›¸å…³çš„é—®é¢˜ï¼Œå³å½¢æˆäº†Answer-Question å¯¹ã€‚ ç„¶ååè½¬A-Qå¯¹ï¼ˆæ˜ å°„å…³ç³»ä¸ºn-to-1ï¼‰ï¼Œæ„é€ å‡ºå¾®è°ƒæ•°æ®ã€‚ æ€»ä½“æ¥è¯´ï¼Œå°±æ˜¯ä¾èµ–ä¸€ä¸ªè¶…å¤§çš„chatå¤§æ¨¡å‹å’Œä¸€ä¸ªæ–‡æ¡£æ•°æ®é›†ï¼Œæ„é€ å‡ºQ-Aç›¸ä¼¼å¯¹ï¼Œè¿›è€Œå°†chatå¤§æ¨¡å‹çš„å¯¹è¯¥æ–‡æ¡£çš„ç›¸å…³çŸ¥è¯†ï¼ˆå¯¹æ–‡æ¡£æ•°æ®é›†é¢†åŸŸçš„çŸ¥è¯†ç†è§£æ›´é€å½»ã€æ›´ç²¾ç»†ï¼‰ å¾®è°ƒåˆ°ä¸€ä¸ªembå°æ¨¡å‹å†…ã€‚ æ¨¡å‹å¾®è°ƒä½¿ç”¨çš„æ˜¯llama-index ä¸­ embedding æ¨¡å‹å¾®è°ƒçš„åŠŸèƒ½ç±» llama_index.finetuning.embeddings.sentence_transformer.SentenceTransformersFinetuneEngineã€‚ å…¶ä¸­æŸå¤±å‡½æ•°æ˜¯ MultipleNegativesRankingLoss MultipleNegativesRankingLoss å¯¹äºæœ¬æ–‡çš„æ•°æ®å½¢å¼ å³ Q-Aå¯¹ï¼Œå³å°†Aè§†ä½œä¸€ä¸ªæ­£æ ·æœ¬ï¼ŒåŒæ—¶é‡‡æ · in-batchå†…çš„å…¶ä»–æ ·æœ¬ä½œä¸ºå¤šä¸ªè´Ÿæ ·æœ¬ï¼Œæ¥è®¡ç®—å‡ºä¸€ä¸ª Softmax Cross-Entropy Lossï¼Œç„¶åå†Qç»´åº¦ä¸Šå–å‡å€¼å³ä¸ºbatchæŸå¤±ã€‚ Configuring the Response Mode æ¨¡å‹ä¸‹è½½ HuggingfaceEmbedding ç±» å¦‚ä½•è§£å†³å¤–ç½‘ä¸å¯è®¿é—®çš„é—®é¢˜ã€‚ ä½¿ç”¨ modelscopeä¸‹è½½æ¨¡å‹ï¼Œç„¶ååˆ¶å®š HuggingfaceEmbeddingçš„æ¨¡å‹åŠ è½½è·¯å¾„ä¸º modelscopeç¼“å­˜ä¸­æ¨¡å‹çš„ç»å¯¹è·¯å¾„ã€‚ï¼ˆä¸æ˜¯æ¨¡å‹ç¼“å­˜çš„çˆ¶ç›®å½•ï¼Œè€Œæ˜¯å…·ä½“åˆ°ä¸€ä¸ªæ¨¡å‹çš„ç›®å½•ï¼‰ modelscopeä¸Šçš„æ¨¡å‹ä¸å…¨ï¼Œæœ‰äº›çŸ¥ååº¦ä¸é«˜çš„æ¨¡å‹ hfä¸Šæ¸¸ï¼Œä½†modelscopeä¸Šç¼ºå°‘ã€‚ æœåŠ¡å™¨ é˜¿é‡Œäº‘æœåŠ¡å™¨å¯ä»¥ä½¿ç”¨ modelscope æ¥è¿›è¡Œä¸‹è½½ï¼Œç„¶åç„¶åæ¨¡å‹åŠ è½½éƒ½ä½¿ç”¨ç»å¯¹è·¯å¾„æ¥åŠ è½½ã€‚ æœ¬åœ°å¼€å‘ å¯ä»¥ä½¿ç”¨ huggingface æ¥è¿›è¡Œä¸‹è½½å’Œç®¡ç†ã€‚ FlagEmbeddingReranker â€œFlagâ€ in FlagEmbeddingReranker = BAAIï¼ˆæ™ºæºç ”ç©¶é™¢ï¼‰çš„å¼€æºæ¨¡å‹å“ç‰Œæ ‡è¯†ï¼Œæ„ä¸ºâ€œæ——èˆ°çº§åµŒå…¥/é‡æ’æ¨¡å‹â€ï¼Œæ— ç‰¹æ®ŠæŠ€æœ¯å«ä¹‰ï¼Œä¸»è¦æ˜¯é¡¹ç›®å‘½åçš„ä¸€éƒ¨åˆ†ã€‚ modelscopeçš„æ¨¡å‹ç›®å½•æ¶æ„å’Œhuggingfaceçš„æ¨¡å‹ç›®å½•ç»“æ„ å·®å¼‚å¾ˆå¤§ï¼Œä¸èƒ½ç›´æ¥å¤ç”¨ã€‚æ‰€ä»¥å¦‚æœè¦åŠ è½½æœ¬åœ°æ¨¡å‹ï¼ŒåŠ¡å¿…ä½¿ç”¨æ¨¡å‹ç»å¯¹è·¯å¾„ã€‚ å·¥ç¨‹ Qdrant é«˜çº§è¿‡æ»¤èƒ½åŠ›ï¼š æ”¯æŒç»“åˆå‘é‡ç›¸ä¼¼æ€§æœç´¢å’Œä»»æ„ Payload ç»“æ„åŒ–æ•°æ®è¿‡æ»¤ï¼ˆç§°ä¸º Hybrid Searchï¼‰ã€‚ node_parser llama_index.core.node_parser.text.sentence_window.SentenceWindowNodeParser æŒ‰ç…§å¥å­è¿›è¡Œåˆ‡å‰²ï¼Œå¤šä¸ªå¥å­ä½œä¸ºä¸€ä¸ªç´¢å¼•æ–‡æ¡£ã€‚ Node Parser Modules | LlamaIndex Python Documentation pickleæ–¹å¼ä¸å®‰å…¨æ˜¯å› ä¸º __reduce__æ–¹æ³•ä¸­å¯ä»¥å®šä¹‰ä¸€ä¸ª æŒ‡ä»¤å­—èŠ‚æµï¼Œåœ¨ååºåˆ—åŒ–çš„æ—¶å€™å¯ä»¥è§¦å‘å¯¹åº”æŒ‡ä»¤çš„æ‰§è¡Œã€‚ é—®é¢˜ï¼špytorch_model.bin å’Œ model.safetensors åˆ†åˆ«æ˜¯ä»€ä¹ˆ pytorch_model.bin å’Œ model.safetensors æ˜¯ä¸¤ç§å¸¸è§çš„ç”¨äºå­˜å‚¨æ·±åº¦å­¦ä¹ æ¨¡å‹æƒé‡ï¼ˆå‚æ•°ï¼‰çš„æ–‡ä»¶æ ¼å¼ï¼Œå¹¿æ³›ç”¨äº Hugging Face Transformers ç­‰ç”Ÿæ€ä¸­ã€‚å®ƒä»¬çš„æ ¸å¿ƒç›®çš„ç›¸åŒï¼šä¿å­˜ç¥ç»ç½‘ç»œçš„å¯è®­ç»ƒå‚æ•°ï¼Œä½†åœ¨è®¾è®¡å“²å­¦ã€å®‰å…¨æ€§ã€æ€§èƒ½å’Œå…¼å®¹æ€§æ–¹é¢æœ‰æ˜¾è‘—åŒºåˆ«ã€‚\n1. pytorch_model.bin\næ˜¯ä»€ä¹ˆï¼Ÿ\nè¿™æ˜¯ PyTorch åŸç”Ÿçš„æ¨¡å‹æƒé‡ä¿å­˜æ ¼å¼ã€‚ æœ¬è´¨ä¸Šæ˜¯ä¸€ä¸ªé€šè¿‡ torch.save() ä¿å­˜çš„ Python pickle æ–‡ä»¶ï¼Œé€šå¸¸åŒ…å«ä¸€ä¸ªå­—å…¸ï¼Œé”®ä¸ºå‚æ•°åï¼ˆå¦‚ \u0026quot;transformer.h.0.attn.c_attn.weight\u0026quot;ï¼‰ï¼Œå€¼ä¸ºå¯¹åº”çš„ torch.Tensorã€‚ ç‰¹ç‚¹ï¼š\næ–¹é¢ è¯´æ˜ æ ¼å¼ åŸºäº Python çš„ pickle åºåˆ—åŒ– å…¼å®¹æ€§ åªèƒ½åœ¨ PyTorch ç¯å¢ƒä¸­åŠ è½½ï¼ˆéœ€åŒ¹é…ç‰ˆæœ¬ï¼‰ å®‰å…¨æ€§ â— ä¸å®‰å…¨ï¼špickle å¯æ‰§è¡Œä»»æ„ä»£ç ï¼ŒåŠ è½½ä¸å—ä¿¡ä»»çš„ .bin æ–‡ä»¶å¯èƒ½å¯¼è‡´è¿œç¨‹ä»£ç æ‰§è¡Œï¼ˆRCEï¼‰æ¼æ´ é€Ÿåº¦ åŠ è½½/ä¿å­˜è¾ƒå¿«ï¼Œä½†ä¾èµ– Python ååºåˆ—åŒ– è·¨è¯­è¨€ ä¸æ”¯æŒï¼ˆå¼ºä¾èµ– Python å’Œ PyTorchï¼‰ å…¸å‹ç”¨é€” Hugging Face æ¨¡å‹ä»“åº“ä¸­çš„é»˜è®¤æƒé‡æ ¼å¼ï¼ˆå°¤å…¶æ—§æ¨¡å‹ï¼‰ ç¤ºä¾‹åŠ è½½æ–¹å¼ï¼š\nimport torch state_dict = torch.load(\u0026#34;pytorch_model.bin\u0026#34;, map_location=\u0026#34;cpu\u0026#34;) model.load_state_dict(state_dict) âš ï¸ è­¦å‘Šï¼šæ°¸è¿œä¸è¦åŠ è½½æ¥è‡ªä¸å¯ä¿¡æ¥æºçš„ pytorch_model.binï¼\n2. model.safetensors\næ˜¯ä»€ä¹ˆï¼Ÿ\nç”± Hugging Face å’Œ CarperAI è”åˆå¼€å‘çš„ä¸€ç§å®‰å…¨ã€å¿«é€Ÿã€æ¡†æ¶æ— å…³çš„æ¨¡å‹æƒé‡å­˜å‚¨æ ¼å¼ã€‚ ä¸ä½¿ç”¨ pickleï¼Œè€Œæ˜¯å°†å¼ é‡æ•°æ®ä»¥åŸå§‹äºŒè¿›åˆ¶å½¢å¼å­˜å‚¨ï¼Œå¹¶é™„å¸¦ JSON å…ƒæ•°æ®æè¿°å¼ é‡ç»“æ„ã€‚ ç‰¹ç‚¹ï¼š\næ–¹é¢ è¯´æ˜ æ ¼å¼ è‡ªå®šä¹‰äºŒè¿›åˆ¶æ ¼å¼ + JSON headerï¼ˆæ— ä»£ç æ‰§è¡Œï¼‰ å®‰å…¨æ€§ âœ… å®‰å…¨ï¼šä»…åŒ…å«æ•°å€¼æ•°æ®ï¼Œæ— æ³•æ‰§è¡Œä»»æ„ä»£ç  é€Ÿåº¦ åŠ è½½é€šå¸¸æ¯” .bin æ›´å¿«ï¼ˆå°¤å…¶å¤§æ¨¡å‹ï¼‰ï¼Œæ”¯æŒå†…å­˜æ˜ å°„ï¼ˆmmapï¼‰ è·¨æ¡†æ¶ æ”¯æŒ PyTorchã€TensorFlowã€Flaxã€JAX ç­‰ï¼ˆåªè¦èƒ½è¯»å– NumPy-like å¼ é‡ï¼‰ æ–‡ä»¶å¤§å° ä¸ .bin å‡ ä¹ç›¸åŒï¼ˆæœªå‹ç¼©ï¼Œä½†å¯é€‰ gzipï¼‰ å…¸å‹ç”¨é€” Hugging Face æ–°æ¨¡å‹æ¨èæ ¼å¼ï¼Œå°¤å…¶åœ¨å…¬å¼€åˆ†äº«æˆ– Web æœåŠ¡ä¸­ æ–‡ä»¶ç»“æ„ç®€è¿°ï¼š\n[JSON metadata header (UTF-8, padded to 8-byte align)] { \u0026#34;weight1\u0026#34;: {\u0026#34;dtype\u0026#34;: \u0026#34;F32\u0026#34;, \u0026#34;shape\u0026#34;: [1024, 1024], \u0026#34;data_offsets\u0026#34;: [0, 4194304]}, \u0026#34;weight2\u0026#34;: {\u0026#34;dtype\u0026#34;: \u0026#34;F16\u0026#34;, \u0026#34;shape\u0026#34;: [512], \u0026#34;data_offsets\u0026#34;: [4194304, 4195328]} } [Raw binary tensor data (concatenated)] ç¤ºä¾‹åŠ è½½æ–¹å¼ï¼ˆPyTorchï¼‰ï¼š\nfrom safetensors.torch import load_file state_dict = load_file(\u0026#34;model.safetensors\u0026#34;, device=\u0026#34;cpu\u0026#34;) model.load_state_dict(state_dict) å¯¹æ¯”æ€»ç»“\nç‰¹æ€§ pytorch_model.bin model.safetensors åº•å±‚æœºåˆ¶ Python pickle è‡ªå®šä¹‰äºŒè¿›åˆ¶ + JSON å®‰å…¨æ€§ âŒ å±é™©ï¼ˆå¯æ‰§è¡Œä»£ç ï¼‰ âœ… å®‰å…¨ï¼ˆçº¯æ•°æ®ï¼‰ åŠ è½½é€Ÿåº¦ å¿« é€šå¸¸æ›´å¿«ï¼ˆæ”¯æŒ mmapï¼‰ è·¨å¹³å°/è¯­è¨€ å¦ï¼ˆPyTorch + Pythonï¼‰ æ˜¯ï¼ˆå¤šæ¡†æ¶æ”¯æŒï¼‰ Hugging Face æ¨è æ—§æ¨¡å‹é»˜è®¤ æ–°æ¨¡å‹é¦–é€‰ æ–‡ä»¶æ‰©å±•å .bin .safetensors å®é™…å»ºè®®\nâœ… ä¼˜å…ˆä½¿ç”¨ .safetensorsï¼šå°¤å…¶å½“ä½ ä»ç½‘ä¸Šä¸‹è½½æ¨¡å‹ã€éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒæˆ–æä¾› API æœåŠ¡æ—¶ã€‚ ğŸ”’ é¿å…åŠ è½½æœªçŸ¥æ¥æºçš„ .bin æ–‡ä»¶ï¼šé™¤éä½ å®Œå…¨ä¿¡ä»»æä¾›è€…ã€‚ ğŸ”„ å¾ˆå¤šæ¨¡å‹ä»“åº“åŒæ—¶æä¾›ä¸¤ç§æ ¼å¼ï¼ˆå¦‚ Llama 3ã€Mistralï¼‰ï¼Œä½ å¯ä»¥è‡ªç”±é€‰æ‹©ã€‚ ğŸ› ï¸ å¯ç”¨å·¥å…·è½¬æ¢ï¼š # ä½¿ç”¨ Hugging Face transformers è‡ªåŠ¨è½¬æ¢ from transformers import AutoModel model = AutoModel.from_pretrained(\u0026#34;your-model\u0026#34;, use_safetensors=True) # è‡ªåŠ¨ä¼˜å…ˆåŠ è½½ .safetensors å¦‚æœä½ æ­£åœ¨å¼€å‘ä¸€ä¸ªéœ€è¦åŠ è½½å¤–éƒ¨æ¨¡å‹çš„åº”ç”¨ï¼ˆå¦‚ Web UIã€æ¨ç†æœåŠ¡ï¼‰ï¼Œå¼ºçƒˆå»ºè®®åªæ”¯æŒ .safetensors æ ¼å¼ä»¥è§„é¿å®‰å…¨é£é™©ã€‚\né—®é¢˜ï¼šSparse text embeddings å’Œ dense text embeddings çš„åŒºåˆ« Sparse text embeddings å’Œ dense text embeddings æ˜¯ä¸¤ç§ä¸åŒçš„æ–‡æœ¬è¡¨ç¤ºæ–¹æ³•ï¼Œå®ƒä»¬åœ¨ç»“æ„ã€ç”Ÿæˆæ–¹å¼ã€åº”ç”¨åœºæ™¯å’Œæ€§èƒ½ç‰¹ç‚¹ä¸Šæœ‰æ˜¾è‘—åŒºåˆ«ã€‚ä»¥ä¸‹æ˜¯è¯¦ç»†å¯¹æ¯”ï¼š\nä¸€ã€æ ¸å¿ƒå®šä¹‰\nç±»å‹ å®šä¹‰ Dense Embeddingsï¼ˆç¨ å¯†åµŒå…¥ï¼‰ å°†æ–‡æœ¬æ˜ å°„ä¸ºä¸€ä¸ªä½ç»´ï¼ˆé€šå¸¸å‡ ç™¾åˆ°å‡ åƒç»´ï¼‰ã€è¿ç»­ã€ç¨ å¯†çš„å®æ•°å‘é‡ï¼Œå‡ ä¹æ‰€æœ‰ç»´åº¦éƒ½æœ‰éé›¶å€¼ã€‚ Sparse Embeddingsï¼ˆç¨€ç–åµŒå…¥ï¼‰ å°†æ–‡æœ¬è¡¨ç¤ºä¸ºä¸€ä¸ªé«˜ç»´ï¼ˆå¯èƒ½æ•°ä¸‡åˆ°ç™¾ä¸‡ç»´ï¼‰ã€ç¦»æ•£ã€ç¨€ç–çš„å‘é‡ï¼Œç»å¤§å¤šæ•°ç»´åº¦ä¸º 0ï¼Œåªæœ‰å°‘æ•°ç»´åº¦æœ‰éé›¶å€¼ï¼ˆé€šå¸¸æ˜¯æ­£æƒé‡ï¼‰ã€‚ äºŒã€å…¸å‹ä»£è¡¨\nç±»å‹ æ¨¡å‹/æ–¹æ³•ç¤ºä¾‹ Dense - BERT, RoBERTa - Sentence-BERT (SBERT) - BGE (BAAI General Embedding) - OpenAI Embeddings - Cohere Embeddings Sparse - BM25ï¼ˆä¼ ç»Ÿï¼Œéå­¦ä¹ å‹ï¼‰ - SPLADE - uniCOIL - DeepImpact - ColBERTï¼ˆéƒ¨åˆ†ç¨€ç–ï¼Œå¸¦åæœŸäº¤äº’ï¼‰ ğŸ’¡ æ³¨æ„ï¼šBM25 è™½ç„¶å¸¸è¢«å½’ä¸ºâ€œç¨€ç–æ£€ç´¢â€ï¼Œä½†å®ƒä¸æ˜¯â€œembedding æ¨¡å‹â€ï¼ˆæ— ç¥ç»ç½‘ç»œï¼‰ï¼Œè€Œ SPLADE ç­‰æ˜¯åŸºäºæ·±åº¦å­¦ä¹ çš„ç¨€ç– embedding æ¨¡å‹ã€‚\nä¸‰ã€ç»“æ„å¯¹æ¯”ï¼ˆä¸¾ä¾‹ï¼‰ å‡è®¾è¯æ±‡è¡¨å¤§å°ä¸º 30,000ï¼š\nSparse embeddingï¼ˆå¦‚ SPLADEï¼‰ï¼š [0, 0, 0, ..., 2.1, 0, 0, ..., 0.8, ..., 0] # é•¿åº¦=30,000ï¼Œä»…å‡ åä¸ªéé›¶å€¼ â†’ æ¯ä¸ªéé›¶ä½ç½®å¯¹åº”ä¸€ä¸ªè¯ï¼ˆå¦‚ \u0026ldquo;apple\u0026rdquo; åœ¨ç´¢å¼• 12345ï¼‰ï¼Œå€¼è¡¨ç¤ºé‡è¦æ€§ã€‚ Dense embeddingï¼ˆå¦‚ BGEï¼‰ï¼š [0.23, -0.41, 0.88, ..., 0.05] # é•¿åº¦=1024ï¼Œå‡ ä¹æ¯ä¸ªå€¼éƒ½éé›¶ â†’ å‘é‡ç»´åº¦ä¸è¯æ±‡è¡¨æ— å…³ï¼Œè¯­ä¹‰ä¿¡æ¯åˆ†å¸ƒåœ¨æ•´ä¸ªå‘é‡ä¸­ã€‚ å››ã€å…³é”®åŒºåˆ«æ€»ç»“\nç»´åº¦ Sparse Embeddings Dense Embeddings ç»´åº¦ é«˜ç»´ï¼ˆâ‰ˆè¯æ±‡è¡¨å¤§å°ï¼Œå¦‚ 30kâ€“1Mï¼‰ ä½ç»´ï¼ˆé€šå¸¸ 384â€“4096ï¼‰ éé›¶å…ƒç´  æå°‘ï¼ˆ\u0026lt; 100 ä¸ªï¼‰ å‡ ä¹å…¨éƒ¨éé›¶ å¯è§£é‡Šæ€§ âœ… é«˜ï¼ˆæ¯ä¸ªéé›¶ç»´å¯¹åº”ä¸€ä¸ªè¯ï¼‰ âŒ ä½ï¼ˆè¯­ä¹‰åˆ†å¸ƒåœ¨éšç©ºé—´ï¼‰ å­˜å‚¨æ•ˆç‡ âœ… é«˜ï¼ˆå¯ç”¨å€’æ’ç´¢å¼•å‹ç¼©å­˜å‚¨ï¼‰ âš ï¸ ä¸­ç­‰ï¼ˆéœ€å­˜å‚¨å®Œæ•´æµ®ç‚¹æ•°ç»„ï¼‰ æ£€ç´¢æ–¹å¼ å€’æ’ç´¢å¼•ï¼ˆInverted Indexï¼‰ + TF-IDF/BM25 é£æ ¼æ‰“åˆ† å‘é‡ç›¸ä¼¼åº¦ï¼ˆå¦‚ä½™å¼¦ã€å†…ç§¯ï¼‰+ ANNï¼ˆå¦‚ FAISS, HNSWï¼‰ è®­ç»ƒç›®æ ‡ ä¼˜åŒ–è¯çº§é‡è¦æ€§ï¼ˆå¦‚é€šè¿‡ KL æ•£åº¦å¯¹é½ BM25ï¼‰ ä¼˜åŒ–å¥å­/æ®µè½çº§è¯­ä¹‰ç›¸ä¼¼åº¦ï¼ˆå¦‚å¯¹æ¯”å­¦ä¹ ï¼‰ å¤šè¯­è¨€æ”¯æŒ ä¾èµ–è¯æ±‡è¡¨ï¼Œè·¨è¯­è¨€è¾ƒéš¾ æ›´å®¹æ˜“é€šè¿‡å…±äº«è¯­ä¹‰ç©ºé—´å®ç° ç¡¬ä»¶åŠ é€Ÿ CPU å‹å¥½ï¼Œé€‚åˆå¤§è§„æ¨¡æ–‡æ¡£åº“ GPU/ANN åŠ é€Ÿæ•ˆæœæ›´å¥½ äº”ã€åº”ç”¨åœºæ™¯\nâœ… Sparse æ›´é€‚åˆï¼š\nå¤§è§„æ¨¡æ–‡æ¡£æ£€ç´¢ï¼ˆå¦‚æœç´¢å¼•æ“ï¼‰ï¼š==åˆ©ç”¨æˆç†Ÿçš„å€’æ’ç´¢å¼•æŠ€æœ¯==ï¼Œé«˜æ•ˆè¿‡æ»¤æµ·é‡æ–‡æ¡£ã€‚ å…³é”®è¯æ•æ„Ÿä»»åŠ¡ï¼šéœ€è¦ç²¾ç¡®åŒ¹é…æœ¯è¯­ï¼ˆå¦‚æ³•å¾‹ã€åŒ»ç–—æ£€ç´¢ï¼‰ã€‚ èµ„æºå—é™ç¯å¢ƒï¼šæ— éœ€ GPUï¼Œçº¯ CPU å³å¯é«˜æ•ˆè¿è¡Œã€‚ âœ… Dense æ›´é€‚åˆï¼š\nè¯­ä¹‰ç›¸ä¼¼åº¦ä»»åŠ¡ï¼šç†è§£åŒä¹‰ã€ paraphraseã€ä¸Šä¸‹æ–‡å«ä¹‰ï¼ˆå¦‚ â€œcarâ€ â‰ˆ â€œautomobileâ€ï¼‰ã€‚ å°æ ·æœ¬æˆ– zero-shot åœºæ™¯ï¼šæ³›åŒ–èƒ½åŠ›å¼ºã€‚ RAG ç³»ç»Ÿä¸­çš„ç²¾æ’ï¼šä¸ LLM ç»“åˆæ•ˆæœå¥½ã€‚ å…­ã€æ··åˆæ–¹æ³•ï¼ˆHybrid Retrievalï¼‰ ç°ä»£ç³»ç»Ÿå¸¸ç»“åˆä¸¤è€…ä¼˜åŠ¿ï¼š\nQuery â†’ [Sparse Retriever (BM25/SPLADE)] â†’ Top K candidates + [Dense Retriever (BGE)] â†’ Top K candidates â†’ åˆå¹¶å»é‡ â†’ Reranker (e.g., BGE-reranker) ColBERTï¼šè™½è¾“å‡ºç¨ å¯† token å‘é‡ï¼Œä½†é€šè¿‡ MaxSim å®ç°ç±»ä¼¼ç¨€ç–çš„ç»†ç²’åº¦åŒ¹é…ã€‚ BGE-M3ï¼ˆBAAI æœ€æ–°æ¨¡å‹ï¼‰ï¼šåŒæ—¶è¾“å‡º denseã€sparse å’Œ multi-vector è¡¨ç¤ºï¼Œæ”¯æŒç»Ÿä¸€æ£€ç´¢ã€‚ ä¸ƒã€å¯è§†åŒ–æ¯”å–»\nSparseï¼šåƒä¸€æœ¬ç´¢å¼•ç›®å½•â€”â€”åªåˆ—å‡ºå…³é”®è¯åŠå…¶é¡µç ï¼ˆä½ç½®+æƒé‡ï¼‰ã€‚ Denseï¼šåƒä¸€å¹…æŠ½è±¡ç”»â€”â€”æ•´ä½“è¡¨è¾¾è¯­ä¹‰ï¼Œæ— æ³•æ‹†è§£å•ä¸ªå…ƒç´ å«ä¹‰ã€‚ æ€»ç»“ä¸€å¥è¯ï¼š\nSparse embeddings = å…³é”®è¯åŠ æƒï¼ˆå¯è§£é‡Šã€é«˜æ•ˆï¼‰ï¼›Dense embeddings = è¯­ä¹‰å‹ç¼©ï¼ˆæ³›åŒ–å¼ºã€éœ€å‘é‡æ£€ç´¢ï¼‰ã€‚ æ ¹æ®ä½ çš„ä»»åŠ¡éœ€æ±‚ï¼ˆç²¾åº¦ vs æ•ˆç‡ã€å…³é”®è¯åŒ¹é… vs è¯­ä¹‰ç†è§£ï¼‰ï¼Œå¯ä»¥é€‰æ‹©åˆé€‚ç±»å‹ï¼Œæˆ–ç›´æ¥ä½¿ç”¨ hybrid æ–¹æ¡ˆè·å¾—æœ€ä½³æ•ˆæœã€‚\né—®é¢˜ï¼šSparse Embeddingsçš„æ¨¡å‹å¦‚ä½•åšåˆ° è¾“å‡ºç¨€ç–å‘é‡çš„ è¿™æ˜¯ä¸€ä¸ªéå¸¸å¥½çš„é—®é¢˜ï¼Sparse Embeddings æ¨¡å‹ï¼ˆå¦‚ SPLADEã€uniCOILã€DeepImpact ç­‰ï¼‰ä¹‹æ‰€ä»¥èƒ½è¾“å‡ºâ€œç¨€ç–ä½†æœ‰ä¿¡æ¯é‡â€çš„å‘é‡ï¼Œå…³é”®åœ¨äºå®ƒä»¬é€šè¿‡ç¥ç»ç½‘ç»œå­¦ä¹ æ¯ä¸ªè¯é¡¹ï¼ˆtermï¼‰çš„é‡è¦æ€§æƒé‡ï¼Œå¹¶å¼ºåˆ¶ç»å¤§å¤šæ•°æƒé‡ä¸ºé›¶æˆ–æ¥è¿‘é›¶ã€‚ä¸‹é¢ä»åŸç†ã€æŠ€æœ¯æ‰‹æ®µå’Œè®­ç»ƒç›®æ ‡ä¸‰ä¸ªæ–¹é¢è¯¦ç»†è§£é‡Šï¼š\nä¸€ã€æ ¸å¿ƒæ€æƒ³ï¼šå°†æ–‡æœ¬æ˜ å°„åˆ°â€œè¯æ±‡è¡¨ç»´åº¦â€çš„ç¨€ç–å‘é‡ ä¸ dense embedding è¾“å‡ºä¸€ä¸ªå›ºå®šä½ç»´å‘é‡ä¸åŒï¼Œsparse embedding æ¨¡å‹çš„è¾“å‡ºç»´åº¦ = è¯æ±‡è¡¨å¤§å°ï¼ˆVï¼‰ï¼ˆä¾‹å¦‚ V = 30,000ï¼‰ã€‚\nå¯¹äºè¾“å…¥æ–‡æœ¬ï¼Œæ¨¡å‹ä¼šä¸ºè¯æ±‡è¡¨ä¸­çš„æ¯ä¸ªè¯ $w_i$ é¢„æµ‹ä¸€ä¸ª éè´Ÿé‡è¦æ€§åˆ†æ•° $s_i \\geq 0$ï¼Œæœ€ç»ˆè¾“å‡ºå‘é‡ä¸ºï¼š $$ \\mathbf{e} = [s_1, s_2, \u0026hellip;, s_V] $$ å…¶ä¸­ ç»å¤§å¤šæ•° $s_i = 0$ï¼Œåªæœ‰å°‘æ•°å…³é”®è¯çš„ $s_i \u0026gt; 0$ï¼Œå½¢æˆç¨€ç–è¡¨ç¤ºã€‚\nâœ… è¿™ä¸ªå‘é‡å¯ä»¥ç›´æ¥ç”¨äº å€’æ’ç´¢å¼•ï¼ˆInverted Indexï¼‰æ£€ç´¢ï¼Œå°±åƒ BM25 ä¸€æ ·é«˜æ•ˆã€‚\näºŒã€å¦‚ä½•å®ç°â€œç¨€ç–æ€§â€ï¼Ÿå…³é”®æŠ€æœ¯æ‰‹æ®µ\n1. ä½¿ç”¨å¸¦ç¨€ç–è¯±å¯¼çš„æ¿€æ´»å‡½æ•° æœ€å¸¸ç”¨çš„æ˜¯ ReLU + å¯¹æ•°å˜æ¢ + FLOPS æ­£åˆ™åŒ–ï¼ˆä»¥ SPLADE ä¸ºä»£è¡¨ï¼‰ï¼š\nï¼ˆ1ï¼‰åŸºäº BERT çš„ token-level logits\nè¾“å…¥æ–‡æœ¬ â†’ BERT ç¼–ç å™¨ â†’ å¾—åˆ°æ¯ä¸ª token çš„ä¸Šä¸‹æ–‡è¡¨ç¤ºã€‚ é€šè¿‡ä¸€ä¸ªçº¿æ€§å±‚ï¼ˆæˆ– MLM headï¼‰é¢„æµ‹ æ•´ä¸ªè¯æ±‡è¡¨ä¸Šæ¯ä¸ªè¯çš„ logitsï¼ˆç±»ä¼¼æ©ç è¯­è¨€å»ºæ¨¡ï¼‰ã€‚ ï¼ˆ2ï¼‰åº”ç”¨ $\\text{ReLU}(\\log(1 + \\exp(x)))$ æˆ–ç›´æ¥ $\\text{F}(x) = \\max(0, x)$\nå°† logits ç»è¿‡ éè´Ÿæ¿€æ´»ï¼Œç¡®ä¿è¾“å‡º â‰¥ 0ã€‚ å®é™…ä¸­å¸¸ç”¨ï¼š\n$$s_i = \\text{ReLU}\\left( \\text{MLM logits}_i \\right)$$ æˆ–æ›´å¹³æ»‘çš„ï¼š $$ s_i = \\log\\left(1 + \\exp(\\text{MLM logits}_i)\\right) \\quad \\text{(softplus)} $$ ğŸ“Œ æ³¨æ„ï¼šå³ä½¿ logits æ˜¯ç¨ å¯†çš„ï¼Œåç»­ä¼šé€šè¿‡æ­£åˆ™åŒ–è®©å¤§å¤šæ•° $s_i \\to 0$ã€‚\n2. å¼•å…¥ç¨€ç–æ€§æ­£åˆ™åŒ–ï¼ˆSparsity Regularizationï¼‰ è¿™æ˜¯å®ç°â€œçœŸæ­£ç¨€ç–â€çš„å…³é”®ï¼æ¨¡å‹åœ¨è®­ç»ƒæ—¶ä¼šæƒ©ç½šéé›¶å…ƒç´ çš„æ•°é‡æˆ–å¤§å°ã€‚\nå¸¸è§æ­£åˆ™é¡¹ï¼ˆåŠ åœ¨ loss ä¸­ï¼‰ï¼š\nL1 æ­£åˆ™åŒ–ï¼š$\\lambda \\sum_i |s_i|$\nâ†’ é¼“åŠ±æƒé‡è¶‹è¿‘äº 0ã€‚ FLOPS æ­£åˆ™åŒ–ï¼ˆSPLADE æå‡ºï¼‰ï¼š\n$$ \\mathcal{L}_{\\text{flops}} = \\left( \\frac{1}{V} \\sum_i \\mathbb{E}[s_i] \\right)^2 $$ â†’ æƒ©ç½šå¹³å‡æ¿€æ´»å¼ºåº¦ï¼Œä¿ƒä½¿æ¨¡å‹åªæ¿€æ´»æå°‘æ•°è¯ã€‚ Group Lasso / Top-k çº¦æŸï¼šå¼ºåˆ¶åªä¿ç•™ top-k ä¸ªæœ€å¤§æƒé‡ã€‚ ğŸ’¡ è®­ç»ƒå®Œæˆåï¼Œæ¨ç†æ—¶å¯è®¾ç½®é˜ˆå€¼ï¼ˆå¦‚ $s_i \u0026lt; 1e-4$ åˆ™ç½® 0ï¼‰ï¼Œè¿›ä¸€æ­¥æå‡ç¨€ç–åº¦ã€‚\n3. åˆ©ç”¨é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹çš„ MLM Head\nSPLADE ç­‰æ¨¡å‹ç›´æ¥å¤ç”¨ BERT çš„ Masked Language Model (MLM) å¤´ã€‚ MLM å¤´æœ¬æ¥å°±èƒ½é¢„æµ‹â€œå“ªäº›è¯å¯èƒ½å‡ºç°åœ¨ä¸Šä¸‹æ–‡ä¸­â€ï¼Œå¤©ç„¶å…·æœ‰è¯çº§è¯­ä¹‰æ„ŸçŸ¥èƒ½åŠ›ã€‚ é€šè¿‡å¾®è°ƒ MLM å¤´ï¼Œä½¿å…¶è¾“å‡ºçš„ logits ä¸å†ç”¨äºé¢„æµ‹è¢«é®ç›–è¯ï¼Œè€Œæ˜¯ä½œä¸ºå…¨æ–‡çš„è¯é‡è¦æ€§åˆ†å¸ƒã€‚ âœ… è¿™æ ·æ—¢åˆ©ç”¨äº†é¢„è®­ç»ƒçŸ¥è¯†ï¼Œåˆå®ç°äº†ç«¯åˆ°ç«¯çš„ç¨€ç–è¡¨ç¤ºå­¦ä¹ ã€‚\nä¸‰ã€è®­ç»ƒç›®æ ‡ï¼šå¯¹é½ç›¸å…³æ€§ä¿¡å· ä¸ºäº†è®©ç¨€ç–å‘é‡â€œæœ‰ä¿¡æ¯é‡â€ï¼ˆå³èƒ½æœ‰æ•ˆæ’åºç›¸å…³æ–‡æ¡£ï¼‰ï¼Œæ¨¡å‹é€šå¸¸é‡‡ç”¨ä»¥ä¸‹ç›‘ç£ä¿¡å·ï¼š\næ–¹æ³• è®­ç»ƒç›®æ ‡ SPLADE æœ€å¤§åŒ–æŸ¥è¯¢-æ­£æ ·æœ¬æ–‡æ¡£çš„ç›¸ä¼¼åº¦ï¼ˆå†…ç§¯ï¼‰ï¼Œæœ€å°åŒ–æŸ¥è¯¢-è´Ÿæ ·æœ¬çš„ç›¸ä¼¼åº¦ + ç¨€ç–æ­£åˆ™ DeepImpact / uniCOIL å›å½’åˆ°ä¼ªæ ‡ç­¾ï¼ˆå¦‚ BM25 åˆ†æ•°ã€æ•™å¸ˆæ¨¡å‹æ‰“åˆ†ï¼‰ æ— ç›‘ç£ SPLADE ä½¿ç”¨å¯¹æ¯”å­¦ä¹ æˆ–è‡ªç›‘ç£ï¼ˆå¦‚æ–‡æ¡£-æ ‡é¢˜å¯¹ï¼‰ ç›¸ä¼¼åº¦è®¡ç®—æ–¹å¼ï¼š $$ \\text{score}(q, d) = \\sum_{i=1}^V \\text{ReLU}(q_i) \\cdot \\text{ReLU}(d_i) $$ â†’ æœ¬è´¨æ˜¯ åŠ æƒè¯é‡å ï¼ˆWeighted Term Matchingï¼‰ï¼Œä½†æƒé‡ç”±ç¥ç»ç½‘ç»œå­¦ä¹ å¾—åˆ°ï¼Œæ¯” TF-IDF/BM25 æ›´æ™ºèƒ½ã€‚ å››ã€ä¸¾ä¸ªå…·ä½“ä¾‹å­ï¼šSPLADE å¦‚ä½•å·¥ä½œï¼Ÿ\nè¾“å…¥æŸ¥è¯¢ \u0026quot;How to bake a cake?\u0026quot; ç»è¿‡ BERT + MLM head â†’ è¾“å‡º 30,000 ç»´ logits åº”ç”¨ $\\text{ReLU}(\\cdot)$ â†’ å¾—åˆ°éè´Ÿåˆ†æ•° åŠ å…¥ FLOPS æ­£åˆ™ â†’ æ¨¡å‹å­¦ä¼šåªç»™ \u0026quot;bake\u0026quot;, \u0026quot;cake\u0026quot;, \u0026quot;recipe\u0026quot; ç­‰è¯é«˜åˆ†ï¼Œå…¶ä½™ä¸º 0 æœ€ç»ˆè¾“å‡ºç¨€ç–å‘é‡ï¼šä»…å‡ åä¸ªéé›¶å€¼ï¼Œæ¯ä¸ªå¯¹åº”ä¸€ä¸ªå…³é”®è¯åŠå…¶è¯­ä¹‰é‡è¦æ€§ ğŸ” æ£€ç´¢æ—¶ï¼š æ–‡æ¡£ä¹Ÿç”¨åŒæ ·æ–¹å¼ç¼–ç æˆç¨€ç–å‘é‡ é€šè¿‡å€’æ’ç´¢å¼•å¿«é€Ÿè®¡ç®—å†…ç§¯å¾—åˆ†ï¼ˆåªè®¡ç®—éé›¶ç»´åº¦äº¤é›†ï¼‰ äº”ã€ä¸ºä»€ä¹ˆå«â€œå“äº®â€ï¼ˆinformativeï¼‰ï¼Ÿ\nè™½ç„¶ç¨€ç–ï¼Œä½†éé›¶ç»´åº¦æ˜¯æ¨¡å‹ç²¾å¿ƒæŒ‘é€‰çš„å…³é”®è¯ï¼Œä¸”æƒé‡åæ˜ å…¶åœ¨å½“å‰ä¸Šä¸‹æ–‡ä¸­çš„è¯­ä¹‰é‡è¦æ€§ã€‚ ç›¸æ¯” BM25 çš„é™æ€ TF-IDFï¼Œsparse embedding èƒ½ï¼š ç†è§£åŒä¹‰è¯ï¼ˆ\u0026ldquo;car\u0026rdquo; â†’ æ¿€æ´» \u0026ldquo;automobile\u0026rdquo;ï¼‰ æŠ‘åˆ¶åœç”¨è¯ï¼ˆ\u0026ldquo;the\u0026rdquo;, \u0026ldquo;how\u0026rdquo; æƒé‡â‰ˆ0ï¼‰ æ ¹æ®ä¸Šä¸‹æ–‡åŠ¨æ€è°ƒæ•´ï¼ˆ\u0026ldquo;apple\u0026rdquo; åœ¨ç§‘æŠ€ vs æ°´æœè¯­å¢ƒä¸‹æ¿€æ´»ä¸åŒè¯ï¼‰ æ€»ç»“\nå…³é”®ç‚¹ è¯´æ˜ è¾“å‡ºç»´åº¦ = è¯æ±‡è¡¨å¤§å°ï¼ˆé«˜ç»´ï¼‰ ç¨€ç–æ€§æ¥æº ReLU/Softplus æ¿€æ´» + L1/FLOPS æ­£åˆ™åŒ– ä¿¡æ¯é‡æ¥æº åŸºäºé¢„è®­ç»ƒ MLM å¤´ + ç›¸å…³æ€§ç›‘ç£å­¦ä¹  æ£€ç´¢å…¼å®¹æ€§ å®Œå…¨å…¼å®¹ä¼ ç»Ÿå€’æ’ç´¢å¼•ç³»ç»Ÿï¼ˆå¦‚ Lucene, Elasticsearchï¼‰ ä»£è¡¨æ¨¡å‹ SPLADEï¼ˆæœ€ç»å…¸ï¼‰ã€uniCOILã€DeepImpactã€BGE-M3ï¼ˆæ”¯æŒ sparse è¾“å‡ºï¼‰ âœ… æ‰€ä»¥ï¼Œâ€œç¨€ç–ä½†å“äº®â€ = åªä¿ç•™æœ€å…³é”®çš„å‡ ä¸ªè¯ï¼Œä½†æ¯ä¸ªè¯çš„æƒé‡éƒ½ç»è¿‡æ·±åº¦è¯­ä¹‰ç†è§£ä¼˜åŒ–ã€‚ å¦‚æœä½ æ­£åœ¨æ„å»ºæ£€ç´¢ç³»ç»Ÿï¼Œsparse embeddings èƒ½è®©ä½ åœ¨ä¸ç‰ºç‰²å¤ªå¤šè¯­ä¹‰èƒ½åŠ›çš„å‰æä¸‹ï¼Œäº«å—ä¼ ç»Ÿæœç´¢å¼•æ“çš„é«˜æ•ˆä¸å¯æ‰©å±•æ€§ã€‚\nå…¶ä»–é—®é¢˜ é—®é¢˜ï¼šlangchainä¸­çš„ç«–çº¿è¿ç®—ç¬¦æ˜¯ç”±å“ªäº›æ–¹æ³•æ¥å®ç°çš„ åœ¨ langchain ä¸­ï¼Œç«–çº¿è¿ç®—ç¬¦ï¼ˆ|ï¼‰çš„å®ç°ä¸»è¦ä¾èµ–äºä»¥ä¸‹æ–¹æ³•ï¼š\næ ¸å¿ƒå®ç°æ–¹æ³•\n__or__ æ–¹æ³• è¿™æ˜¯ Python ä¸­å®ç°ç«–çº¿è¿ç®—ç¬¦çš„æ ¸å¿ƒé­”æœ¯æ–¹æ³• å½“ä½¿ç”¨ a | b è¯­æ³•æ—¶ï¼ŒPython ä¼šè°ƒç”¨ a.__or__(b) __ror__ æ–¹æ³• å³ä¾§å¯¹è±¡çš„åå‘æˆ–è¿ç®—æ–¹æ³• å½“å·¦ä¾§å¯¹è±¡æ²¡æœ‰å®ç° __or__ æ—¶è°ƒç”¨ åœ¨ Langchain ä¸­çš„åº”ç”¨ åœ¨ä½ çš„ä»£ç ä¸­ prompt|llm|output_parser è¿™ä¸ªé“¾æ¡ä¸­ï¼š\npromptï¼ˆChatPromptTemplate å¯¹è±¡ï¼‰å®ç°äº† __or__ æ–¹æ³• llmï¼ˆChatOpenAI å¯¹è±¡ï¼‰ä¹Ÿå®ç°äº† __or__ æ–¹æ³• output_parserï¼ˆStrOutputParser å¯¹è±¡ï¼‰åŒæ ·æ”¯æŒé“¾å¼æ“ä½œ å®ç°æœºåˆ¶\n**ä¼ªä»£ç ç¤ºä¾‹** class BaseComponent: def __or__(self, other): return Chain(self, other) è¿™ç§è®¾è®¡æ¨¡å¼å…è®¸ä¸åŒçš„ langchain ç»„ä»¶ï¼ˆå¦‚ promptã€llmã€output_parserï¼‰é€šè¿‡ç«–çº¿è¿ç®—ç¬¦ç»„åˆæˆä¸€ä¸ªå®Œæ•´çš„å¤„ç†é“¾ chainã€‚\né—®é¢˜ï¼šlangchainä¸­çš„StrOutputParser æ˜¯å¦‚ä½•è‡ªåŠ¨å¯¹ chatbotçš„ç»“æœè¿›è¡Œæ¸²æŸ“çš„ ä½œä¸ºä¸€åèµ„æ·±æŠ€æœ¯å¯¼å¸ˆï¼Œæˆ‘æ¥è¯¦ç»†è§£é‡Š LangChain ä¸­çš„ StrOutputParser ä¸æ˜¯å¦‚ä½•â€œè‡ªåŠ¨æ¸²æŸ“â€ç»“æœçš„ï¼Œè€Œæ˜¯å®ƒåœ¨ LangChain è¡¨è¾¾å¼è¯­è¨€ (LCEL) ç®¡é“ä¸­æ‰®æ¼”çš„å…³é”®è§’è‰²ã€‚\næ ¸å¿ƒè§‚ç‚¹ï¼šStrOutputParser å¹¶éæ¸²æŸ“å™¨ï¼Œè€Œæ˜¯è½¬æ¢å™¨ StrOutputParser çš„ä½œç”¨ä¸æ˜¯å¯¹ç»“æœè¿›è¡Œå¤æ‚çš„â€œæ¸²æŸ“â€ï¼ˆå¦‚æ ¼å¼åŒ–ä¸º Markdown æˆ– HTMLï¼‰ï¼Œè€Œæ˜¯æ‰§è¡Œä¸€ä¸ªéå¸¸ç®€å•ä½†è‡³å…³é‡è¦çš„ç±»å‹è½¬æ¢ï¼š å®ƒç¡®ä¿ç®¡é“ï¼ˆChainï¼‰çš„æœ€ç»ˆè¾“å‡ºæ˜¯æ ‡å‡†çš„ Python å­—ç¬¦ä¸²ï¼ˆstrï¼‰ç±»å‹ã€‚ åœ¨ LangChain ç®¡é“ä¸­ï¼Œâ€œæ¸²æŸ“â€è¿™ä¸ªè¯é€šå¸¸æ„å‘³ç€å°†è¾“å‡ºä»ä¸€ä¸ªå¤æ‚å¯¹è±¡è½¬æ¢ä¸ºç”¨æˆ·æˆ–ä¸‹ä¸€ä¸ªç»„ä»¶å¯ä»¥ä½¿ç”¨çš„æ ¼å¼ã€‚\n1. ä¸ºä»€ä¹ˆéœ€è¦ StrOutputParserï¼Ÿ LLM æ¨¡å‹çš„åŸå§‹è¾“å‡ºé€šå¸¸æ˜¯ä¸€ä¸ªå¤æ‚çš„å¯¹è±¡ï¼Œè€Œä¸æ˜¯ä¸€ä¸ªç®€å•çš„å­—ç¬¦ä¸²ï¼š\nåŸå§‹è¾“å‡ºç±»å‹ è§£é‡Š BaseMessage å¯¹äº Chat æ¨¡å‹ (ChatOpenAI, ChatGroq ç­‰)ï¼Œå®ƒä»¬çš„ invoke() æˆ– stream() æ–¹æ³•è¿”å›çš„æ˜¯ä¸€ä¸ª BaseMessage å¯¹è±¡ï¼ˆé€šå¸¸æ˜¯ AIMessage æˆ– HumanMessage çš„å­ç±»ï¼‰ã€‚ Generation å¯¹äº Completion æ¨¡å‹ (OpenAI ç­‰)ï¼Œå®ƒä»¬çš„ invoke() è¿”å›çš„æ˜¯ä¸€ä¸ª Generation å¯¹è±¡çš„åˆ—è¡¨ï¼ˆåŒ…è£…åœ¨ LLMResult ä¸­ï¼‰ã€‚ StrOutputParser çš„å·¥ä½œå°±æ˜¯ä»è¿™äº›å¤æ‚çš„å¯¹è±¡ä¸­ï¼Œå®‰å…¨åœ°æå–å‡ºäººç±»å¯è¯»çš„å­—ç¬¦ä¸²å†…å®¹ã€‚ 2. StrOutputParser çš„å·¥ä½œæœºåˆ¶ StrOutputParser åœ¨ LCEL ç®¡é“ä¸­å®ç°äº† BaseOutputParser æ¥å£ï¼Œå®ƒçš„æ ¸å¿ƒé€»è¾‘éå¸¸ç®€å•ï¼š\nA. å¤„ç† Chat æ¨¡å‹è¾“å‡º (BaseMessage å¯¹è±¡) å½“å®ƒæ¥æ”¶åˆ° AIMessage æˆ–å…¶ä»– BaseMessage å¯¹è±¡æ—¶ï¼Œå®ƒä¼šè°ƒç”¨è¯¥å¯¹è±¡çš„ .content å±æ€§ã€‚\nè¾“å…¥ç¤ºä¾‹ï¼š \u0026lt;AIMessage content='ä½ å¥½ï¼æˆ‘æ˜¯ä¸€ä¸ªAIã€‚'\u0026gt; è¾“å‡ºç»“æœï¼š 'ä½ å¥½ï¼æˆ‘æ˜¯ä¸€ä¸ªAIã€‚' B. å¤„ç† Completion æ¨¡å‹è¾“å‡º (LLMResult / Generation å¯¹è±¡) å¦‚æœå®ƒæ¥æ”¶åˆ°çš„æ˜¯ Completion æ¨¡å‹è¿”å›çš„ç»“æ„ï¼Œå®ƒä¼šæå–ç¬¬ä¸€ä¸ª Generation å¯¹è±¡çš„æ–‡æœ¬å†…å®¹ã€‚\nC. å¤„ç†æµå¼è¾“å‡º (Streaming) åœ¨æµå¼ä¼ è¾“ä¸­ï¼ŒStrOutputParser ä¼šæŒç»­æ¥æ”¶åˆ°ç‰‡æ®µï¼ˆChunksï¼‰çš„ BaseMessage å¯¹è±¡æˆ–å­—ç¬¦ä¸²ã€‚å®ƒçš„ä½œç”¨æ˜¯ï¼š\næå–å†…å®¹ï¼š ä»æ¯ä¸ªä¼ å…¥çš„ Chunk ä¸­æå– .content å±æ€§ã€‚ æ‹¼æ¥å†…å®¹ï¼š å°†è¿™äº›å†…å®¹ç‰‡æ®µå®‰å…¨åœ°æ‹¼æ¥èµ·æ¥ï¼Œå½¢æˆæœ€ç»ˆçš„å®Œæ•´å­—ç¬¦ä¸²ã€‚è¿™ç¡®ä¿äº†å‰ç«¯æˆ–ç”¨æˆ·æ¥æ”¶åˆ°çš„æµæ˜¯è¿ç»­ä¸”æ­£ç¡®çš„æ–‡æœ¬ã€‚ 3. å¦‚ä½•â€œè‡ªåŠ¨æ¸²æŸ“â€çš„è¯¯è§£ ç”¨æˆ·ä¹‹æ‰€ä»¥è§‰å¾—å®ƒæ˜¯â€œè‡ªåŠ¨æ¸²æŸ“â€çš„ï¼Œæ˜¯å› ä¸ºå®ƒå°†ä¸€ä¸ªä¸é€æ˜çš„ LangChain å†…éƒ¨å¯¹è±¡ï¼ˆå¦‚ AIMessageï¼‰è½¬æ¢æˆäº†åº”ç”¨ç¨‹åºå‰ç«¯å¯ä»¥ç›´æ¥æ˜¾ç¤ºçš„ Python str ç±»å‹ã€‚ åœ¨ LCEL ç®¡é“ä¸­ï¼ŒStrOutputParser é€šå¸¸ä½äºç®¡é“çš„æœ«ç«¯ï¼Œå› ä¸ºå®ƒç¡®ä¿äº†ç®¡é“çš„è¾“å‡ºèƒ½å¤Ÿè¢«åç»­çš„ç³»ç»Ÿï¼ˆå¦‚ Flask API å“åº”ã€Streamlit ç•Œé¢æˆ–ç®€å•çš„ print() è¯­å¥ï¼‰è½»æ¾æ¶ˆè´¹ã€‚\næ€»ç»“ StrOutputParser æ˜¯ LangChain ç®¡é“ä¸­ä¸€ä¸ªç±»å‹è½¬æ¢ç»„ä»¶ï¼Œå®ƒçš„ä½œç”¨æ˜¯ï¼š\nä» LLM è¿”å›çš„å¤æ‚å¯¹è±¡ï¼ˆå¦‚ AIMessageï¼‰ä¸­æå–çº¯æ–‡æœ¬å†…å®¹ã€‚ ç¡®ä¿ Chain çš„è¾“å‡ºç±»å‹å§‹ç»ˆæ˜¯æ ‡å‡†çš„ strï¼Œä»¥ä¾¿äºåç»­å¤„ç†å’Œå±•ç¤ºã€‚ åœ¨æµå¼ä¼ è¾“ä¸­ï¼Œè´Ÿè´£å°†æ¥æ”¶åˆ°çš„å†…å®¹ç‰‡æ®µå®‰å…¨æ‹¼æ¥ã€‚ é—®é¢˜ï¼šé‚£ä¹ˆstreamlitçš„writeæ–¹æ³•æ˜¯å¦‚ä½•å°†markdownæ ¼å¼æ–‡æœ¬è‡ªåŠ¨æ¸²æŸ“ä¸ºæœ‰æ ¼å¼çš„htmlçš„ ä»£ç  streamlit.elements.write.WriteMixin.write ä¸­æœ‰è®²è§£è¿™éƒ¨åˆ†å†…å®¹ã€‚\nè¿™æ˜¯ä¸€ä¸ªéå¸¸å¥½çš„é—®é¢˜ï¼Œå®ƒè§¦åŠäº† Streamlit çš„æ ¸å¿ƒæœºåˆ¶å’Œå‰ç«¯äº¤äº’åŸç†ã€‚ streamlit.write() æ–¹æ³•è‡ªèº«ä¸ä¼šæ‰§è¡Œ Markdown æ¸²æŸ“ï¼Œå®ƒæ˜¯ä¸€ä¸ªâ€œä¸‡èƒ½â€å‘½ä»¤ï¼Œä¼šæ ¹æ®ä¼ å…¥çš„æ•°æ®ç±»å‹è¿›è¡Œåˆ†æ´¾ï¼ˆDispatchï¼‰ã€‚å½“å®ƒæ¥æ”¶åˆ°å­—ç¬¦ä¸²æ—¶ï¼Œå®ƒä¼šå°†æ¸²æŸ“å·¥ä½œå§”æ‰˜ç»™ä¸“é—¨çš„å‡½æ•°ã€‚ ä¸‹é¢æ˜¯ st.write() å¦‚ä½•å°† Markdown æ–‡æœ¬è‡ªåŠ¨è½¬æ¢ä¸º HTML æ ¼å¼åŒ–æ˜¾ç¤ºçš„è¯¦ç»†è¿‡ç¨‹ã€‚\n1. st.write() çš„åˆ†æ´¾æœºåˆ¶ (The Swiss Army Knife) st.write() è¢«ç§°ä¸º Streamlit çš„â€œç‘å£«å†›åˆ€â€ï¼Œå®ƒä¼šæ£€æŸ¥ä¼ å…¥çš„å‚æ•°ç±»å‹ï¼š\nä¼ å…¥å‚æ•°ç±»å‹ st.write() å®é™…è°ƒç”¨ str (å­—ç¬¦ä¸²) å§”æ‰˜ç»™ st.markdown() pd.DataFrame å§”æ‰˜ç»™ st.dataframe() dict æˆ– list å§”æ‰˜ç»™ st.json() Altair/Plotly Chart å§”æ‰˜ç»™ç›¸åº”çš„å›¾è¡¨å‡½æ•° Exception å§”æ‰˜ç»™ st.exception() å› æ­¤ï¼Œå½“ä½ ä¼ å…¥ä¸€ä¸ªåŒ…å« Markdown æ ¼å¼çš„å­—ç¬¦ä¸²æ—¶ï¼Œå®é™…æ‰§è¡Œæ¸²æŸ“çš„æ˜¯ st.markdown() å‡½æ•°ã€‚ 2. st.markdown() çš„æ ¸å¿ƒæ¸²æŸ“è¿‡ç¨‹ st.markdown() æ˜¯ä¸“é—¨è´Ÿè´£å°† Markdown æ–‡æœ¬è½¬æ¢ä¸º HTML çš„å‡½æ•°ã€‚è¿™ä¸ªè½¬æ¢è¿‡ç¨‹åœ¨ Streamlit å†…éƒ¨æ˜¯è¿™æ ·è¿ä½œçš„ï¼š\nA. åç«¯ï¼ˆPythonï¼‰å¤„ç†ï¼šä½¿ç”¨ Markdown è§£æåº“\nè§£æå™¨ä½¿ç”¨ï¼š Streamlit çš„ Python åç«¯ä¸ä¼šè‡ªå·±ç¼–å†™ Markdown è½¬æ¢é€»è¾‘ã€‚å®ƒä¼šä¾èµ–ä¸€ä¸ªæˆ–å¤šä¸ªæˆç†Ÿçš„ã€é«˜æ€§èƒ½çš„ Python Markdown è§£æåº“ï¼ˆä¾‹å¦‚ï¼Œæ—©æœŸç‰ˆæœ¬å¯èƒ½ä¾èµ– markdown-it-py æˆ–ç±»ä¼¼çš„åº“ï¼‰ã€‚ ç”Ÿæˆ HTML/æŠ½è±¡ç»“æ„ï¼š å½“ä½ è°ƒç”¨ st.markdown(body) æ—¶ï¼Œbody å­—ç¬¦ä¸²ä¼šè¢«è¿™ä¸ªå†…éƒ¨çš„ Markdown è§£æå™¨å¤„ç†ï¼Œå¹¶è½¬æ¢æˆå¯¹åº”çš„ HTML ç»“æ„ï¼ˆæˆ–ä¸€ä¸ªåŒ…å«æ¸²æŸ“æŒ‡ä»¤çš„ä¸­é—´æ•°æ®ç»“æ„ï¼‰ã€‚ ä¾‹å¦‚ï¼Œ**bold** è¢«è½¬æ¢ä¸º \u0026lt;strong\u0026gt;bold\u0026lt;/strong\u0026gt;ã€‚ åºåˆ—åŒ–ä¸ä¼ è¾“ï¼š Streamlit å°†è¿™ä¸ª HTML ç»“æ„æˆ–æ¸²æŸ“æŒ‡ä»¤åºåˆ—åŒ–ï¼ˆé€šå¸¸ä¸º JSON æ ¼å¼ï¼‰ã€‚ WebSocket ä¼ è¾“ï¼š åºåˆ—åŒ–åçš„æ•°æ®é€šè¿‡ WebSocket è¿æ¥ï¼Œä» Python åç«¯å‘é€åˆ° Streamlit çš„å‰ç«¯ï¼ˆæµè§ˆå™¨ï¼‰ã€‚ B. å‰ç«¯ï¼ˆæµè§ˆå™¨ï¼‰æ¸²æŸ“ï¼šReact + CSS\nå‰ç«¯æ¥æ”¶ï¼š Streamlit çš„å‰ç«¯ï¼ˆä½¿ç”¨ React æ¡†æ¶æ„å»ºï¼‰æ¥æ”¶åˆ°é€šè¿‡ WebSocket å‘é€è¿‡æ¥çš„æŒ‡ä»¤/æ•°æ®ã€‚ DOM æ“ä½œï¼š React ç»„ä»¶æ ¹æ®æ”¶åˆ°çš„ HTML ç»“æ„æˆ–æŒ‡ä»¤ï¼Œå°†å…¶å®‰å…¨åœ°æ’å…¥åˆ° Web é¡µé¢çš„ DOM (Document Object Model) ä¸­ã€‚ æµè§ˆå™¨æ¸²æŸ“ï¼š æµè§ˆå™¨è¯†åˆ«è¿™äº› HTML æ ‡ç­¾ï¼ˆå¦‚ \u0026lt;h1\u0026gt;, \u0026lt;p\u0026gt;, \u0026lt;strong\u0026gt;ï¼‰å¹¶åº”ç”¨é»˜è®¤æˆ– Streamlit è‡ªå®šä¹‰çš„ CSS æ ·å¼ã€‚ æ ·å¼åº”ç”¨ï¼š Streamlit å…·æœ‰å†…ç½®çš„æ ·å¼è¡¨ï¼Œç¡®ä¿æ‰€æœ‰çš„ Markdown å…ƒç´ ï¼ˆæ ‡é¢˜ã€åˆ—è¡¨ã€ä»£ç å—ç­‰ï¼‰éƒ½éµå¾ªåº”ç”¨çš„ä¸»é¢˜å’Œå¤–è§‚ï¼Œçœ‹èµ·æ¥ç¾è§‚ä¸”ä¸€è‡´ã€‚ 3. ä¸ºä»€ä¹ˆæ˜¯è‡ªåŠ¨çš„ï¼Ÿ å¯¹äºå¼€å‘è€…æ¥è¯´ï¼Œæ•´ä¸ªè¿‡ç¨‹æ˜¯è‡ªåŠ¨ä¸”æ— æ„Ÿçš„ï¼Œå› ä¸ºï¼š\nå°è£…ï¼š st.write() å’Œ st.markdown() å°è£…äº†ä» Markdown å­—ç¬¦ä¸²åˆ° HTML æ¸²æŸ“çš„æ‰€æœ‰æ­¥éª¤ã€‚ å®æ—¶åŒæ­¥ï¼š Streamlit çš„æ¶æ„æœ¬èº«å°±æ˜¯ä¸ºäº†åœ¨ Python åç«¯ä»£ç ä¸æµè§ˆå™¨å‰ç«¯ä¹‹é—´æä¾›å®æ—¶åŒæ­¥ã€‚å½“ä½ è°ƒç”¨ä¸€ä¸ª Streamlit å‘½ä»¤æ—¶ï¼ŒPython æ¡†æ¶ä¼šç«‹å³å¤„ç†æ•°æ®å¹¶å‘Šè¯‰å‰ç«¯å¦‚ä½•æ›´æ–°ã€‚ é—®é¢˜ï¼šPydantic ä¸­ BaseModel çš„æ ¸å¿ƒä½œç”¨ï¼šæ•°æ®æ¨¡å‹å’Œæ•°æ®æ ¡éªŒ åœ¨ Python çš„ pydantic åº“ä¸­ï¼ŒBaseModel æ˜¯æ„å»ºæ•°æ®æ¨¡å‹çš„åŸºçŸ³ã€‚å®ƒçš„ä¸»è¦ä½œç”¨æ˜¯å®šä¹‰æ•°æ®çš„ç»“æ„ã€ç±»å‹ï¼Œå¹¶è‡ªåŠ¨è¿›è¡ŒéªŒè¯ã€‚ ç®€å•æ¥è¯´ï¼ŒBaseModel å°†æ¾æ•£çš„ Python å­—å…¸æ•°æ®æå‡ä¸ºå…·æœ‰æ˜ç¡®ç»“æ„ã€ç±»å‹å’Œå†…ç½®éªŒè¯çš„å¼ºå¤§æ•°æ®å¯¹è±¡ã€‚\nğŸš€ BaseModel çš„ä¸»è¦åŠŸèƒ½\n1. å®šä¹‰æ¸…æ™°çš„æ•°æ®ç»“æ„ (Schema Definition) BaseModel å…è®¸ä½ ä½¿ç”¨æ ‡å‡†çš„ Python ç±»å‹æ³¨è§£æ¥å®šä¹‰ä½ çš„æ•°æ®å¯¹è±¡åº”è¯¥é•¿ä»€ä¹ˆæ ·ï¼ŒåŒ…æ‹¬å“ªäº›å­—æ®µã€æ¯ä¸ªå­—æ®µçš„ç±»å‹ã€‚\nç¤ºä¾‹: Python from pydantic import BaseModel from datetime import datetime class User(BaseModel): id: int name: str = \u0026#34;John Doe\u0026#34; # å¸¦æœ‰é»˜è®¤å€¼ signup_ts: datetime | None = None # è”åˆç±»å‹ is_active: bool è¿™ä¸ªç±»æ¸…æ¥šåœ°å®šä¹‰äº†ä¸€ä¸ªç”¨æˆ·å¯¹è±¡å¿…é¡»åŒ…å« idï¼ˆæ•´æ•°ï¼‰ã€nameï¼ˆå­—ç¬¦ä¸²ï¼‰ã€signup_tsï¼ˆæ—¥æœŸæ—¶é—´æˆ– Noneï¼‰å’Œ is_activeï¼ˆå¸ƒå°”å€¼ï¼‰ã€‚ 2. è‡ªåŠ¨æ•°æ®æ ¡éªŒ (Data Validation) è¿™æ˜¯ BaseModel æœ€æ ¸å¿ƒçš„åŠŸèƒ½ã€‚å½“ä½ å°è¯•åˆ›å»ºä¸€ä¸ª BaseModel å®ä¾‹æ—¶ï¼ŒPydantic ä¼šè‡ªåŠ¨æ£€æŸ¥ä¼ å…¥çš„æ•°æ®æ˜¯å¦ç¬¦åˆä½ å®šä¹‰çš„ç±»å‹å’Œç»“æ„ã€‚\nå¦‚æœæ•°æ®ç±»å‹æ­£ç¡®ï¼š å®ƒä¼šå°†è¾“å…¥æ•°æ®ï¼ˆæ¯”å¦‚ JSON å­—ç¬¦ä¸²ã€å­—å…¸ï¼‰è½¬æ¢ä¸ºæ­£ç¡®çš„ Python ç±»å‹ï¼ˆä¾‹å¦‚å°† JSON å­—ç¬¦ä¸² \u0026ldquo;1\u0026rdquo; è½¬æ¢ä¸ºæ•´æ•° 1ï¼‰ã€‚ å¦‚æœæ•°æ®æ ¡éªŒå¤±è´¥ï¼š å®ƒä¼šæŠ›å‡ºä¸€ä¸ªæ¸…æ™°çš„ ValidationErrorï¼Œå‘Šè¯‰ä½ å“ªä¸ªå­—æ®µå‡ºäº†é—®é¢˜ï¼Œä»¥åŠä¸ºä»€ä¹ˆã€‚è¿™æå¤§åœ°å‡å°‘äº†è¿è¡Œæ—¶é”™è¯¯å’Œè°ƒè¯•æ—¶é—´ã€‚ 3. è‡ªåŠ¨æ•°æ®è½¬æ¢ (Data Coercion) BaseModel ä¸ä»…è¿›è¡Œæ ¡éªŒï¼Œè¿˜å°è¯•è¿›è¡Œåˆç†çš„ç±»å‹è½¬æ¢ï¼š\nå­—ç¬¦ä¸²åˆ°æ•°å­—ï¼š å­—ç¬¦ä¸² \u0026quot;123\u0026quot; ä¼šè¢«è‡ªåŠ¨è½¬æ¢ä¸ºæ•´æ•° 123ã€‚ å­—ç¬¦ä¸²åˆ°æ—¥æœŸ/æ—¶é—´ï¼š éµå¾ª ISO æ ¼å¼çš„æ—¥æœŸå­—ç¬¦ä¸²ä¼šè¢«è‡ªåŠ¨è½¬æ¢ä¸º datetime å¯¹è±¡ã€‚ 4. å¼ºå¤§çš„åºåˆ—åŒ–å’Œååºåˆ—åŒ– BaseModel å®ä¾‹å†…ç½®äº†å°†æ•°æ®å¯¹è±¡è½¬æ¢ä¸ºå…¶ä»–æ ¼å¼çš„æ–¹æ³•ï¼š\nåºåˆ—åŒ– (Serialization): user_instance.model_dump(): å°†æ¨¡å‹å®ä¾‹è½¬æ¢ä¸ºæ ‡å‡†çš„ Python å­—å…¸ (dict)ã€‚ user_instance.model_dump_json(): å°†æ¨¡å‹å®ä¾‹è½¬æ¢ä¸º JSON å­—ç¬¦ä¸²ï¼Œæ–¹ä¾¿ç½‘ç»œä¼ è¾“ã€‚ ååºåˆ—åŒ– (Deserialization): User(**data_dict): ä»å­—å…¸åˆ›å»ºæ¨¡å‹å®ä¾‹ã€‚ User.model_validate(data_dict): ä»å­—å…¸æˆ– JSON æ•°æ®ä¸­éªŒè¯å¹¶åˆ›å»ºæ¨¡å‹å®ä¾‹ã€‚ 5. ä¸ FastAPI ç­‰æ¡†æ¶é›†æˆ åœ¨ FastAPI ä¸­ï¼ŒBaseModel æ˜¯å®šä¹‰è¯·æ±‚ä½“ (Request Body) å’Œ å“åº”ä½“ (Response Body) çš„æ ‡å‡†æ–¹å¼ã€‚\nå½“ç”¨ä½œè¯·æ±‚ä½“æ—¶ï¼ŒFastAPI è‡ªåŠ¨ä½¿ç”¨ BaseModel æ¥æ ¡éªŒå®¢æˆ·ç«¯å‘é€çš„ JSON æ•°æ®ã€‚ å½“ç”¨ä½œå“åº”ä½“æ—¶ï¼ŒFastAPI è‡ªåŠ¨ä½¿ç”¨ BaseModel æ¥åºåˆ—åŒ–ä½ çš„ Python å¯¹è±¡ä¸º JSON å“åº”ã€‚ æ€»ç»“: BaseModel çš„ä½œç”¨å°±æ˜¯å°† Python åº”ç”¨ç¨‹åºä¸­çš„æ•°æ®å¤„ç†ä»æ¾æ•£ã€æ˜“é”™çš„å­—å…¸æ“ä½œï¼Œå‡çº§ä¸ºç»“æ„åŒ–ã€ç±»å‹å®‰å…¨ä¸”è‡ªå¸¦éªŒè¯çš„å¼ºå¤§å¯¹è±¡æ¨¡å‹ã€‚ é—®é¢˜ï¼šllama2å¹¶éæ˜¯ä¸“å±çš„embeddingæ¨¡å‹ï¼Œä¹Ÿå¯ä»¥ç”¨OllamaEmbeddingsæ¥åŠ è½½ä¹ˆï¼Ÿ è¿™æ˜¯ä¸€ä¸ªéå¸¸ä¸“ä¸šå’Œå…³é”®çš„é—®é¢˜ï¼Œå®ƒæ¶‰åŠåˆ°å¤§æ¨¡å‹çš„å¤šåŠŸèƒ½æ€§å’Œ Ollama å¹³å°çš„çµæ´»æ€§ã€‚ ç­”æ¡ˆæ˜¯ï¼šæ˜¯çš„ï¼Œæ‚¨å¯ä»¥å°† Llama 2 (æˆ– Llama 3 ç­‰èŠå¤©/ç”Ÿæˆæ¨¡å‹) ç”¨ä½œ OllamaEmbeddings çš„æ¨¡å‹ï¼Œä½†å®ƒå¹¶éæœ€ä½³å®è·µã€‚ ä»¥ä¸‹æ˜¯è¯¦ç»†çš„è§£é‡Šå’Œå»ºè®®ï¼š\n1. ä¸ºä»€ä¹ˆ Llama 2 å¯ä»¥ç”¨äºåµŒå…¥ï¼Ÿï¼ˆæŠ€æœ¯å¯è¡Œæ€§ï¼‰ Ollama å¹³å°æä¾›äº†ä¸€ä¸ªé€šç”¨çš„ /api/embeddings REST API ç«¯ç‚¹ã€‚ å½“æ‚¨åœ¨ OllamaEmbeddings ä¸­æŒ‡å®šä¸€ä¸ªéä¸“ç”¨çš„èŠå¤©æ¨¡å‹ï¼ˆå¦‚ llama2ï¼‰æ—¶ï¼ŒOllama å®ˆæŠ¤è¿›ç¨‹ä¼šæ‰§è¡Œä»¥ä¸‹æ“ä½œï¼š\næå–éšè—çŠ¶æ€ (Hidden State): Ollama ä¼šè¿è¡Œ Llama 2 æ¨¡å‹ï¼Œä½†ä¸æ‰§è¡Œæœ€ç»ˆçš„**è¯­è¨€æ¨¡å‹å¤´ï¼ˆLM Headï¼‰**å±‚ï¼ˆè¯¥å±‚è´Ÿè´£é¢„æµ‹ä¸‹ä¸€ä¸ªè¯å…ƒï¼‰ã€‚ æ± åŒ– (Pooling): å®ƒä¼šä»æ¨¡å‹çš„å€’æ•°ç¬¬äºŒå±‚ï¼ˆæˆ–æ ¹æ®é…ç½®çš„ç‰¹å®šå±‚ï¼‰æå–è¯å…ƒéšè—çŠ¶æ€ï¼ˆToken Hidden Statesï¼‰ã€‚ç„¶åï¼Œå®ƒé€šå¸¸ä¼šåº”ç”¨ä¸€ä¸ªæ± åŒ–ç­–ç•¥ï¼ˆå¦‚å¹³å‡æ± åŒ–ï¼‰å°†è¿™äº›è¯å…ƒå‘é‡èšåˆä¸ºä¸€ä¸ªå•ä¸€çš„å¥å­å‘é‡ï¼Œä½œä¸ºæœ€ç»ˆçš„åµŒå…¥ï¼ˆEmbeddingï¼‰ã€‚ LangChain çš„ OllamaEmbeddings é€šè¿‡è°ƒç”¨è¿™ä¸ªé€šç”¨çš„ Ollama APIï¼Œå®ç°äº†å¯¹ Llama 2 çš„åµŒå…¥åŠŸèƒ½è°ƒç”¨ã€‚ 2. ä¸ºä»€ä¹ˆ Llama 2 ä¸æ¨èç”¨äºåµŒå…¥ï¼Ÿï¼ˆæ•ˆæœè€ƒé‡ï¼‰ å°½ç®¡æŠ€æœ¯ä¸Šå¯è¡Œï¼Œä½† Llama 2 æˆ–å…¶ä»–èŠå¤©æ¨¡å‹ï¼ˆå¦‚ Mistralï¼‰åœ¨æ²¡æœ‰ç»è¿‡ç‰¹å®šå¾®è°ƒçš„æƒ…å†µä¸‹ï¼Œä½œä¸ºåµŒå…¥æ¨¡å‹çš„æ•ˆæœé€šå¸¸è¿œä¸å¦‚ä¸“ç”¨åµŒå…¥æ¨¡å‹ã€‚\nåµŒå…¥æ¨¡å‹ç±»å‹ Llama 2 (ç”Ÿæˆæ¨¡å‹) ä¸“ç”¨åµŒå…¥æ¨¡å‹ (å¦‚ Nomic Embed, mxbai-embed-large) è®­ç»ƒç›®æ ‡ ç”Ÿæˆæ–‡æœ¬ï¼ˆé¢„æµ‹ä¸‹ä¸€ä¸ªè¯å…ƒï¼‰ã€‚ è¯­ä¹‰ç›¸ä¼¼æ€§ï¼ˆè®­ç»ƒç›®æ ‡æ˜¯è®©è¯­ä¹‰ç›¸è¿‘çš„å¥å­åœ¨å‘é‡ç©ºé—´ä¸­è·ç¦»æ›´è¿‘ï¼‰ã€‚ æ•ˆæœ/ç²¾åº¦ è¾ƒå·®ã€‚ å‘é‡ç©ºé—´æ²¡æœ‰é’ˆå¯¹ç›¸ä¼¼æ€§æœç´¢è¿›è¡Œä¼˜åŒ–ï¼Œæ£€ç´¢ç²¾åº¦ä½ã€‚ ä¼˜ç§€ã€‚ åœ¨ MTEB ç­‰åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼ŒRAG æ•ˆæœå¥½ã€‚ èµ„æºæ¶ˆè€— é«˜ã€‚ Llama 2 å°ºå¯¸è¾ƒå¤§ï¼ˆå¦‚ 7Bï¼‰ï¼Œæ¨ç†æ…¢ï¼Œå†…å­˜å ç”¨é«˜ã€‚ ä½ã€‚ ä¸“ç”¨æ¨¡å‹é€šå¸¸æ›´å°ï¼ˆå¦‚ 300Mï¼‰ï¼Œé€Ÿåº¦å¿«ï¼Œèµ„æºæ¶ˆè€—ä½ã€‚ ç®€è€Œè¨€ä¹‹ï¼š Llama 2 ç”Ÿæˆçš„å‘é‡å¯èƒ½æ— æ³•å‡†ç¡®æ•æ‰ä¸åŒå¥å­ä¹‹é—´çš„è¯­ä¹‰ç›¸ä¼¼æ€§ï¼Œè¿™ä¼šä¸¥é‡æŸå®³æ‚¨çš„ RAG æ£€ç´¢è´¨é‡ã€‚ 3. æ¶æ„å¸ˆå»ºè®® ä½œä¸ºä¸€åèµ„æ·±æ¶æ„å¸ˆï¼Œæˆ‘çš„å»ºè®®æ˜¯ï¼š\nå¯¹äº RAG æˆ–è¯­ä¹‰æœç´¢ï¼š å§‹ç»ˆä¼˜å…ˆä½¿ç”¨ä¸“ç”¨çš„åµŒå…¥æ¨¡å‹ã€‚ æ‚¨å·²ç»çœ‹åˆ°äº†ï¼ŒOllama æ”¯æŒè®¸å¤šé«˜æ€§èƒ½ã€å°å·§ä¸”ä¸“é—¨ä¸ºåµŒå…¥ä»»åŠ¡ä¼˜åŒ–çš„æ¨¡å‹ï¼ˆå¦‚ mxbai-embed-large æˆ– embeddinggemmaï¼‰ã€‚è¿™èƒ½æä¾›æ›´å¥½çš„ç²¾åº¦å’Œæ›´å¿«çš„é€Ÿåº¦ã€‚ å®éªŒå’Œè‡ªå®šä¹‰ï¼š å¦‚æœæ‚¨åªæ˜¯è¿›è¡Œå®éªŒï¼Œæˆ–è€…æ‚¨çš„ Llama 2 æ˜¯ç»è¿‡ä¸“é—¨çš„ å¯¹æ¯”å­¦ä¹ ï¼ˆContrastive Learningï¼‰å¾®è°ƒç‰ˆæœ¬ï¼ˆä¾‹å¦‚ï¼ŒAnglE-LLaMA ç­‰ï¼‰ï¼Œé‚£ä¹ˆä½¿ç”¨ Llama 2 æ˜¯æœ‰æ„ä¹‰çš„ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä½ éœ€è¦ç¡®ä¿ä½ çš„ Llama 2 æ¨¡å‹æ–‡ä»¶åœ¨ Ollama ä¸­å·²ç»åŒ…å«äº†å¿…è¦çš„åµŒå…¥é…ç½®ã€‚ ç»“è®ºï¼šä½¿ç”¨ OllamaEmbeddings(model=\u0026quot;llama2\u0026quot;) æ˜¯å¯è¡Œçš„ï¼Œä½†ä¸ºäº†æ‚¨çš„åº”ç”¨æ€§èƒ½å’Œå‡†ç¡®æ€§ï¼Œè¯·ä½¿ç”¨ä¸€ä¸ªä¸“ç”¨çš„ Ollama åµŒå…¥æ¨¡å‹ã€‚ ","permalink":"https://chesterwang.github.io/chester-blog/posts/2025-11-07-rag%E9%A1%B9%E7%9B%AE%E5%BC%80%E5%8F%91%E8%AE%B0%E5%BD%95/","summary":"é¡¹ç›®ç¯å¢ƒæ­å»º å¦‚ä½•å°†requirements.txtä¸­çš„ä¾èµ–è½¬ç§»åˆ° uvç¯å¢ƒä¸­ uv add -r requirements.txt å¦‚æœå¤ªæ…¢åˆ™åŠ  url uv add -r requirements.txt --index-url https://pypi.tuna.tsinghua.edu.cn/simple ollamaæ­å»º æŠ¥é”™ ollamaä¿®æ”¹æ¨¡å‹ä¸‹è½½ç›®å½•ä¹‹åæŠ¥é”™ error: pull model manifest: 503: no healthy upstream é‡å¯æœåŠ¡å³å¯ sudo systemctl stop ollama sudo systemctl start ollama ä¿®æ”¹æ¨¡å‹ç›®å½• sudo ln -s /home/chester/ollama/models /usr/share/ollama/.ollama/ sudo chown ollama /usr/share/ollama/.ollama/models sudo chgrp ollama /usr/share/ollama/.ollama/models åä¸¤æ¡æ˜¯ä¿è¯ç›®å½•çš„æƒé™é—®é¢˜ï¼Œä¸ç„¶o","title":"ä¸ªäººRAGé¡¹ç›®å¼€å‘è®°å½•"},{"content":"Hugging Face Hub Models, Spaces, and Datasets are hosted on the Hugging Face Hub asÂ Git repositories Do you have files larger than 10MB? Those files should be tracked withÂ git-lfs, which you can initialize with: git lfs install Note that if your files are larger thanÂ 5GBÂ youâ€™ll also need to run: hf lfs-enable-largefiles . Pull Request ä¹‹æ‰€ä»¥å«è¿™ä¸ªåå­—ï¼Œæ˜¯å› ä¸ºå®ƒå‡†ç¡®åœ°æè¿°äº†è¯·æ±‚è€…ï¼ˆä½ ï¼‰å’Œè¢«è¯·æ±‚è€…ï¼ˆé¡¹ç›®ç»´æŠ¤è€…ï¼‰ä¹‹é—´çš„åŠ¨ä½œå’Œæ–¹å‘ã€‚ PR = â€œæˆ‘æ”¹å¥½äº†ï¼Œè¯·ä½ æŠŠæˆ‘è¿™è¾¹çš„ä¿®æ”¹æ‹‰ï¼ˆpullï¼‰è¿›ä½ çš„ä¸»åˆ†æ”¯å§ã€‚â€è¿™ä¸ª â€œpullâ€ å¹¶ä¸æ˜¯æŒ‡ä½ è‡ªå·±å»æ‹‰ï¼Œè€Œæ˜¯ è¯·æ±‚é¡¹ç›®ç»´æŠ¤è€…å»æ‹‰ä½ çš„ä»£ç ã€‚ Templates transformers quickstart load a pretrained model run inference withÂ Pipeline fine-tune a model withÂ Trainer Auto Classes Instantiating one ofÂ AutoConfig,Â AutoModel, andÂ AutoTokenizerÂ will directly create a class of the relevant architecture. transformersåº“ä¸­ AutoImageProcessor å®ä¾‹è¯å‡ºæ¥çš„processor çš„ä½œç”¨éƒ½æœ‰å“ªäº› ä¸€æ—¦ä½ é€šè¿‡ AutoImageProcessor.from_pretrained() å®ä¾‹åŒ–äº†ä¸€ä¸ªå¤„ç†å™¨ï¼Œè¿™ä¸ª processor å®ä¾‹ å°±æˆä¸ºäº†ä¸€ä¸ªå¼ºå¤§çš„å·¥å…·ï¼Œä¸“é—¨ç”¨äºå‡†å¤‡å›¾åƒæ•°æ®ï¼Œä½¿å…¶èƒ½å¤Ÿè¢«ç‰¹å®šçš„é¢„è®­ç»ƒè§†è§‰æ¨¡å‹ä½¿ç”¨ã€‚å®ƒçš„ä¸»è¦ä½œç”¨å¯ä»¥æ¦‚æ‹¬ä¸ºä»¥ä¸‹å‡ ç‚¹ï¼š å›¾åƒæ ‡å‡†åŒ– (Normalization) å›¾åƒå°ºå¯¸è°ƒæ•´ (Resizing) å’Œè£å‰ª (Cropping) é€šé“æ ¼å¼è½¬æ¢ (Channel Format Conversion) å›¾åƒåˆ°å¼ é‡è½¬æ¢ (Image to Tensor Conversion) æ‰¹å¤„ç† (Batching) æ•°æ®å¢å¼º (Data Augmentation) transoformeråº“ä¸­ TFAutoModelå’ŒAutoModelçš„åŒºåˆ«æ˜¯ä»€ä¹ˆ AutoModelï¼šç”¨äºåŠ è½½ PyTorch æ¡†æ¶ä¸‹çš„æ¨¡å‹ã€‚ TFAutoModelï¼šç”¨äºåŠ è½½ TensorFlow 2.0 æ¡†æ¶ä¸‹çš„æ¨¡å‹ã€‚ FlaxAutoModel: ç”¨äºåŠ è½½ Flaxï¼ˆåŸºäº JAX çš„æ¡†æ¶ï¼‰ä¸‹çš„æ¨¡å‹ã€‚ AutoModel ç±»çš„åç¼€ LM CausalLM MaskedLM MaskedGeneration sequenceClassification TokenClassification NextSentencePrediction MultipleChoice Seq2SeqLM QuestionAnswering Backbone A backbone is a model used for feature extraction for higher level computer vision tasks such as object detection and image classification. Data Collator Data collators are objects that will form a batch by using a list of dataset elements as input. These elements are of the same type as the elements ofÂ train_datasetÂ orÂ eval_dataset. æˆ‘ç†è§£ Data Collator å°±æ˜¯æŠŠå¤šä¸ªåˆ—æ”¾åœ¨ä¸€èµ·ï¼Œå°±æ˜¯collatorçš„å­—é¢æ„æ€ï¼Œä½†å…¶å®å†…éƒ¨è¿˜æ˜¯ä¼šæœ‰ä¸€äº›å…·ä½“çš„æ•°æ®å¤„ç†é€»è¾‘ï¼Œæ¯”å¦‚paddingã€æ•°æ®æ‰©å¢ç­‰ pipeline from transformers import pipeline generator = pipeline(model=\u0026quot;openai-community/gpt2\u0026quot;) generator(\u0026quot;I can't believe you did such a \u0026quot;, do_sample=False) [{'generated_text': \u0026quot;I can't believe you did such a icky thing to me. I'm so sorry. I'm so sorry. I'm so sorry. I'm so sorry. I'm so sorry. I'm so sorry. I'm so sorry. I\u0026quot;}] chat with models Templates Diffusers LoRA Add a LoRA to a pipeline with theÂ load_lora_weights()Â method. Some LoRAâ€™s require a special word to trigger it, such asÂ Realism, in the example below. Check a LoRAâ€™s model card to see if it requires a trigger word. LoRAæ–‡ä»¶å°±æ˜¯ä¸€ç§æ’ä»¶ Sentence Transformers sentence embedding demo\nfrom sentence_transformers import SentenceTransformer # 1. Load a pretrained Sentence Transformer model model = SentenceTransformer(\u0026#34;all-MiniLM-L6-v2\u0026#34;) # The sentences to encode sentences = [ \u0026#34;The weather is lovely today.\u0026#34;, \u0026#34;It\u0026#39;s so sunny outside!\u0026#34;, \u0026#34;He drove to the stadium.\u0026#34;, ] # 2. Calculate embeddings by calling model.encode() embeddings = model.encode(sentences) print(embeddings.shape) # [3, 384] # 3. Calculate the embedding similarities similarities = model.similarity(embeddings, embeddings) print(similarities) # tensor([[1.0000, 0.6660, 0.1046], # [0.6660, 1.0000, 0.1411], # [0.1046, 0.1411, 1.0000]]) trl Quickstart ç®€å•çš„helloworldç¨‹åºã€‚ evaluation: The important thing is that this process should yield a scalar value for each query/response pair. è¿™é‡Œçš„ä¾‹å­ä»£ç åº”è¯¥å·²ç»è¿‡æ—¶äº†ï¼ŒPPOTrainerç°åœ¨æ²¡æœ‰stepè¿™ä¸ªæ–¹æ³•ã€‚ Dataset formats and types How-to guides customozing the training Memory efficient fine-tuning by sharing layers PPO PPOç­–ç•¥ä¸­çš„ä¸€äº›åŸºç¡€çŸ¥è¯† æ·±åº¦å­¦ä¹ ç¡¬ä»¶é…ç½®ä¸­çš„æ¦‚å¿µ device rank world_size node åˆ†åˆ«æ˜¯æŒ‡ä»€ä¹ˆ è¿™å››ä¸ªæ¦‚å¿µçš„å…³ç³»å¯ä»¥æ¦‚æ‹¬ä¸ºï¼šnode æ˜¯ç‰©ç†æœºå™¨ã€‚ ä¸€ä¸ª node å¯ä»¥åŒ…å«å¤šä¸ª deviceï¼Œdeviceé€šå¸¸æ˜¯æŒ‡GPUã€‚ æ¯ä¸ª device é€šå¸¸ç”±ä¸€ä¸ªç‹¬ç«‹çš„ rank è¿›ç¨‹æ¥æ§åˆ¶ã€‚ æ‰€æœ‰ rank è¿›ç¨‹çš„æ€»æ•°å°±æ˜¯ world_sizeã€‚ PPOç¤ºä¾‹ trl/examples/scripts/ppo/ppo.py at v0.21.0 Â· huggingface/trl model=policy, ref_model=ref_policy, reward_model=reward_model, value_model=value_model,ã€ reward_modelå…¶å®æ˜¯æ¯ä¸€å°æ­¥å†³ç­–çš„å³æ—¶çš„ã€ç›´æ¥å¥–åŠ±ï¼Œvalue_modelå¯¹æ¯ä¸€å°æ­¥å†³ç­–çš„å…¨å±€æ€§ã€é•¿æœŸæ€§åæœè¿›è¡Œé¢„æµ‹ã€‚ advantage æˆ‘ç›´è§‚ç†è§£æ˜¯å› ä¸ºQ(s,a) è¿™ä¸ªstateçš„éšæœºé€‰æ‹©å¯¼è‡´åç»­çš„æ‰€æœ‰rewardéƒ½æ¯”è¾ƒå¼‚å¸¸ï¼Œæ‰€ä»¥è¦æ¶ˆé™¤ä¸€éƒ¨åˆ†stateçš„éšæœºæ€§ï¼Œæ‰€ä»¥å‡å»stateçš„valueï¼›å¦‚æœè®­ç»ƒæ•°æ®ä¸­çš„Q(s,a)ä¸­çš„sè¶³å¤Ÿå¤šï¼Œé‚£ä¹ˆå°±å¯ä»¥ç›´æ¥ä½¿ç”¨Qï¼Œä½†å› ä¸ºä¸å¤Ÿå¤šæœ‰äº†éšæœºæ€§ï¼Œæ‰€ä»¥Qä»£è¡¨çš„returnåˆ†å¸ƒå°±åç¦»äº†æ‰€è°“çš„å…¨å±€æ€§çš„Qçš„åˆ†å¸ƒï¼Œæ‰€ä»¥é€šè¿‡å‡å»è¿™ä¸ªsçš„éšæœºæ€§ä»è€Œæ‹‰å›æ­£å¸¸åˆ†å¸ƒã€‚ Mixin ç±»æœ¬èº«ä¸èƒ½ç‹¬ç«‹å®ä¾‹åŒ–ï¼Œå®ƒä¸æ˜¯ç”¨æ¥åˆ›å»ºå¯¹è±¡çš„ã€‚ç›¸åï¼Œå®ƒåƒä¸€ä¸ªâ€œåŠŸèƒ½åŒ…â€æˆ–â€œèƒ½åŠ›æ’ä»¶â€ï¼Œä¸“é—¨è®¾è®¡ç”¨æ¥è¢«å…¶ä»–ç±»ç»§æ‰¿ã€‚å½“ä¸€ä¸ªç±»ç»§æ‰¿äº†ä¸€ä¸ªæˆ–å¤šä¸ª Mixin ç±»æ—¶ï¼Œå®ƒå°±è‡ªåŠ¨è·å¾—äº†è¿™äº› Mixin ç±»æ‰€å®šä¹‰çš„æ‰€æœ‰æ–¹æ³•å’Œå±æ€§ã€‚ PPOä¸­çš„æ•°æ®å¤„ç† transformers.tokenization_utils_base.PreTrainedTokenizerBase.batch_encode_plus æ–¹æ³•ä¸­åŒ…å«äº† tokenizerä¸­çš„paddingå¤„ç†ã€‚ PPOå®˜æ–¹ä¾‹å­ä¸­ä¸­çš„ä»£ç ï¼Œ ä¸ºä»€ä¹ˆ padding_side å’Œåé¢çš„padding=false ï¼Œè¿™ä¸¤è€…ä¸å†²çªä¹ˆ ä»£ç ä¸­ä¸¤ä¸ªåœ°æ–¹ä½¿ç”¨äº†tokenizerï¼Œ PPOTrainer( args=training_args, processing_class=tokenizer,...) è¿™é‡Œçš„tokenizerå®šä¹‰ä¸­æ˜¯å¸¦æœ‰padding=\u0026ldquo;left\u0026quot;çš„ã€‚ è¿™é‡Œçš„tokenizer åœ¨PPOTrainerä¸­æ˜¯ä½œä¸º processing_class çš„ä½œç”¨ã€‚ åœ¨PPOTrainerä¸­ ä¼šæ ¹æ® processing_class ç”Ÿæˆä¸€ä¸ª DataCollatorWithPadding ç±»ç”¨äºæ•°æ®è¿›è¡Œå¤„ç†ï¼Œè€Œè¯¥ç±»çš„è®¡ç®—é€»è¾‘æ˜¯ä½¿ç”¨tokenizerå¯¹æ•°æ®ä»…ä»…è¿›è¡Œpaddingæ“ä½œï¼ˆè¿™é‡Œçš„paddingæ˜¯å³å¯¹é½ï¼‰ï¼Œè¿™é‡Œä¸åŒ…æ‹¬encodingæ“ä½œã€‚å› ä¸ºè®­ç»ƒæ•°æ®å·²ç»æ ¹æ®ç¬¬äºŒæ¡ä¸­çš„ prepare_datasetè¿›è¡Œäº†encodingã€‚ prepare_dataset ä¸­çš„ tokenizeå‡½æ•°ã€‚ è¯¥å‡½æ•°çš„è¾“å…¥æ˜¯ä¸€æ¡æ•°æ®ï¼Œæ‰€ä»¥ä¸éœ€è¦è¿›è¡Œpaddingã€‚ æ€»ç»“ï¼š å³encoddingå’Œpaddingæ˜¯åˆ†åœ¨ä¸¤ä¸ªåœ°æ–¹è¿›è¡Œå¤„ç†çš„ï¼Œåˆ†åˆ«æ˜¯PPOTrainerå®ä¾‹åŒ–ä¹‹å‰ å’Œ PPOTrainerçš„trainæ–¹æ³•å†…éƒ¨ åˆ†åˆ«è¿›è¡Œencodingå’Œpaddingã€‚ è‡³äºä¸ºä»€ä¹ˆè¿™æ ·åšï¼Œä»ä»£ç ä¸­æ²¡æœ‰çœ‹å‡ºåŸå› ã€‚å¯èƒ½æ˜¯ä¸ºäº†æ›´ç»†ç²’åº¦çš„æ§åˆ¶è®­ç»ƒå’Œè¯„ä¼°å„è‡ªåœºæ™¯ä¸‹çš„é€»è¾‘ã€‚ trl.trainer.utils.selective_log_softmax å…¶ä¸­å®ç°é’ˆå¯¹FP32 FP64 é‡‡ç”¨äº†é«˜æ•ˆçš„ logsumexpæ–¹æ³•ï¼Œé’ˆå¯¹å…¶ä»–çš„æ ¼å¼é‡‡ç”¨äº†ä½æ•ˆçš„æ–¹æ³•ï¼Œå› ä¸ºä½ç²¾åº¦æ ¼å¼è®¡ç®—å®¹æ˜“å‡ºç°é—®é¢˜ã€‚ logsumexp çš„æ ‡å‡†å®šä¹‰æ˜¯ï¼š $$\\log \\sum_{i} \\exp(x_i)$$ï¼Œå¦‚æœç›´æ¥æŒ‰è¿™ä¸ªå…¬å¼å®ç°ï¼Œå½“ $x_i$ çš„å€¼å¾ˆå¤§æ—¶ï¼Œ$\\exp(x_i)$ å¯èƒ½ä¼šå¯¼è‡´æ•°å€¼ä¸Šæº¢ï¼ˆoverflowï¼‰ï¼Œè¶…å‡ºæµ®ç‚¹æ•°çš„è¡¨ç¤ºèŒƒå›´ï¼Œç»“æœå˜ä¸ºæ— ç©·å¤§ã€‚ å·¥ç¨‹ä¸Šçš„ç¨³å®šå®ç°æ–¹æ³• 1. ä¸ºäº†é¿å…ä¸Šæº¢ï¼Œlogsumexp åœ¨å¤§å¤šæ•°æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼ˆå¦‚ PyTorchã€TensorFlowï¼‰ä¸­éƒ½æœ‰ä¸€ä¸ªç»è¿‡ä¼˜åŒ–çš„ã€æ•°å€¼ç¨³å®šçš„å®ç°ã€‚æ ¸å¿ƒæ€æƒ³æ˜¯åˆ©ç”¨å¯¹æ•°å‡½æ•°çš„æ€§è´¨ï¼Œå°†æŒ‡æ•°è¿ç®—ä¸­çš„å¤§æ•°ç›¸åŠ é—®é¢˜ï¼Œè½¬æ¢ä¸ºå¯¹æ•°è¿ç®—ä¸­çš„å°èŒƒå›´æ•°ç›¸åŠ é—®é¢˜ã€‚ 2. å…·ä½“æ–¹æ³•å¦‚ä¸‹ï¼š æ‰¾åˆ°æœ€å¤§å€¼ï¼šé¦–å…ˆï¼Œæ‰¾åˆ°è¾“å…¥å‘é‡ $x$ ä¸­çš„æœ€å¤§å€¼ $x_{max}$ã€‚ è½¬æ¢å…¬å¼ï¼šåˆ©ç”¨ $e^{a+b} = e^a e^b$ çš„æ€§è´¨ï¼Œå°†åŸå…¬å¼è¿›è¡Œç­‰ä»·è½¬æ¢ï¼š $$\\log \\sum_{i} \\exp(x_i) = \\log \\left( \\exp(x_{max}) \\sum_{i} \\exp(x_i - x_{max}) \\right)$$ æ‹†åˆ†å¯¹æ•°ï¼šåˆ©ç”¨ $\\log(ab) = \\log(a) + \\log(b)$ çš„æ€§è´¨ï¼Œè¿›ä¸€æ­¥æ‹†åˆ†ï¼š $$= \\log(\\exp(x_{max})) + \\log \\left( \\sum_{i} \\exp(x_i - x_{max}) \\right)$$ $$= x_{max} + \\log \\left( \\sum_{i} \\exp(x_i - x_{max}) \\right)$$ ä¸ºä»€ä¹ˆè¿™ä¸ªæ–¹æ³•æ›´ç¨³å®šï¼Ÿ é˜²æ­¢ä¸Šæº¢ï¼šåœ¨è½¬æ¢åçš„å…¬å¼ä¸­ï¼Œ$x_i - x_{max}$ çš„å€¼éƒ½æ˜¯è´Ÿæ•°æˆ–è€…é›¶ã€‚è¿™æ„å‘³ç€ $\\exp(x_i - x_{max})$ çš„å€¼éƒ½åœ¨ $(0, 1]$ èŒƒå›´å†…ã€‚è¿™æ ·ï¼Œå³ä½¿ $x_i$ éå¸¸å¤§ï¼ŒæŒ‡æ•°è¿ç®—çš„ç»“æœä¹Ÿä¸ä¼šä¸Šæº¢ã€‚ ä¿æŒç²¾åº¦ï¼šè™½ç„¶ $x_i - x_{max}$ çš„å€¼æ˜¯è´Ÿæ•°ï¼Œä½†å®ƒä»¬ä¹‹é—´çš„ç›¸å¯¹å¤§å°å…³ç³»ä¿æŒä¸å˜ï¼Œè¿™ä¿è¯äº†è®¡ç®—ç»“æœçš„ç²¾ç¡®åº¦ã€‚ è®¡ç®—æ•ˆç‡ï¼šè¿™ä¸ªç¨³å®šçš„å®ç°åªéœ€è¦é¢å¤–è¿›è¡Œä¸€æ¬¡ max è¿ç®—å’Œä¸€æ¬¡åŠ æ³•è¿ç®—ï¼Œå¯¹æ•´ä½“è®¡ç®—æ•ˆç‡å½±å“å¾ˆå°ã€‚ ä¾‹å¦‚ï¼Œåœ¨ PyTorch ä¸­ï¼Œtorch.logsumexp å‡½æ•°å°±æ˜¯ä»¥è¿™ç§æ–¹å¼å®ç°çš„ã€‚å½“ä½ ä½¿ç”¨å®ƒæ—¶ï¼Œæ¡†æ¶ä¼šè‡ªåŠ¨å¤„ç†è¿™äº›æ•°å€¼ç¨³å®šæ€§çš„ç»†èŠ‚ã€‚ è¿™ä¸ªå·¥ç¨‹ä¼˜åŒ–æ–¹æ³•åœ¨æ·±åº¦å­¦ä¹ ä¸­éå¸¸é‡è¦ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤„ç†è¯¸å¦‚ Softmax äº¤å‰ç†µæŸå¤±ã€ä¿¡å¿µä¼ æ’­ï¼ˆBelief Propagationï¼‰ç­‰éœ€è¦å¤§é‡æŒ‡æ•°å’Œå¯¹æ•°è¿ç®—çš„åœºæ™¯ã€‚ PPOç­–ç•¥çš„æµç¨‹(from chatgpt) ^PPO-process ä¸€ã€PPOç®—æ³•æ ¸å¿ƒæ€æƒ³ PPO å±äº**ç­–ç•¥æ¢¯åº¦ï¼ˆPolicy Gradientï¼‰**å®¶æ—ï¼Œç›®æ ‡æ˜¯é€šè¿‡ä¸æ–­ä¼˜åŒ–ç­–ç•¥å‚æ•°ï¼Œä½¿å¾—æ™ºèƒ½ä½“åœ¨ç¯å¢ƒä¸­è·å¾—æ›´é«˜çš„æœŸæœ›å›æŠ¥ã€‚ å®ƒçš„å…³é”®åœ¨äºï¼šåœ¨æ›´æ–°ç­–ç•¥æ—¶é™åˆ¶æ›´æ–°å¹…åº¦ï¼Œé˜²æ­¢ç­–ç•¥æ”¹å˜å¤ªå¤§å¯¼è‡´è®­ç»ƒä¸ç¨³å®šã€‚ äºŒã€PPOçš„åŸºæœ¬æµç¨‹ï¼ˆå…¸å‹ç‰ˆæœ¬ï¼šPPO-Clipï¼‰ é‡‡æ ·ï¼ˆRolloutï¼‰ ä½¿ç”¨å½“å‰ç­–ç•¥ $\\pi_{\\theta_{old}}(a_t|s_t)$ï¼Œä¸ç¯å¢ƒäº¤äº’ï¼Œæ”¶é›†ä¸€æ‰¹æ•°æ®ï¼š $(s_t, a_t, r_t, s_{t+1})$ å¹¶è®¡ç®—æŠ˜æ‰£å›æŠ¥ $R_t$ ã€‚ è®¡ç®—ä¼˜åŠ¿å‡½æ•°ï¼ˆAdvantage Estimateï¼‰ é€šå¸¸ç”¨ GAEï¼ˆGeneralized Advantage Estimationï¼‰ï¼š $\\hat{A}t = \\sum{l=0}^{\\infty} (\\gamma\\lambda)^l \\delta_{t+l}$ å…¶ä¸­ $\\delta_t = r_t + \\gamma V(s_{t+1}) - V(s_t)$ã€‚ è®¡ç®—é‡è¦æ€§æ¯”ç‡ï¼ˆratioï¼‰ $r_t(\\theta) = \\frac{\\pi_\\theta(a_t|s_t)}{\\pi_{\\theta_{old}}(a_t|s_t)}$ è¡¨ç¤ºæ–°æ—§ç­–ç•¥åœ¨åŒä¸€åŠ¨ä½œä¸Šçš„â€œæ¦‚ç‡å˜åŒ–â€ã€‚ æ„å»ºPPOçš„ç›®æ ‡å‡½æ•°ï¼ˆClipped Surrogate Objectiveï¼‰ $\\large L^{CLIP}(\\theta) = \\mathbb{E}_t \\big[ \\min( r_t(\\theta) \\hat{A}_t, \\text{clip}(r_t(\\theta), 1 - \\epsilon, 1 + \\epsilon) \\hat{A}_t )\\big]$ å½“ $r_t(\\theta)$ åç¦» 1 å¤ªå¤šï¼ˆè¶…è¿‡ Â±Îµï¼‰æ—¶ï¼Œä¼šè¢«æˆªæ–­ï¼ˆclipï¼‰ï¼Œé˜²æ­¢è¿‡åº¦æ›´æ–°ã€‚ Îµ é€šå¸¸å– 0.1ï½0.2ã€‚ ä¼˜åŒ–ç›®æ ‡ + å€¼å‡½æ•° + ç†µæ­£åˆ™ å®é™…ä¼˜åŒ–çš„ç›®æ ‡å‡½æ•°é€šå¸¸æ˜¯ä¸‰é¡¹ä¹‹å’Œï¼š $L(\\theta) = L^{CLIP}(\\theta) - c_1 L^{VF}(\\theta) + c_2 S[\\pi_\\theta]$ $L^{VF}$ï¼šå€¼å‡½æ•°çš„MSEæŸå¤± $S[\\pi_\\theta]$ï¼šç­–ç•¥çš„ç†µï¼ˆé¼“åŠ±æ¢ç´¢ï¼‰ å¤šæ¬¡å°æ­¥æ›´æ–°ï¼ˆK epochsï¼‰ ç”¨åŒä¸€æ‰¹é‡‡æ ·æ•°æ®ï¼Œåœ¨æ¯ä¸ª mini-batch ä¸Šä¼˜åŒ– K è½®ã€‚ æ›´æ–°æ—§ç­–ç•¥å‚æ•° $\\theta_{old} \\leftarrow \\theta$ PPOTrainerä¸­ä»£ç çš„æµç¨‹æ€»ç»“ ^PPO-code-process\nå¤–å¾ªç¯ï¼šæ€»è®­ç»ƒbatchæ•° å¯¹ policy model ç”Ÿæˆçš„æ¯ä¸€ä¸ªåºåˆ—æ ·æœ¬ï¼Œè¾“å…¥åˆ°reward model ï¼Œåºåˆ—ä¸­æœ€åä¸€ä¸ªtokençš„ hidden state è¢«è¾“å…¥åˆ°ä¸€ä¸ªçº¿æ€§å¤´ï¼Œæœ€ç»ˆè¾“å‡ºä¸€ä¸ªæ ‡é‡å€¼ï¼Œè¡¨ç¤ºåºåˆ—äºŒåˆ†ç±»çš„æ‰“åˆ†scoreã€‚ å¯¹ policy model ç”Ÿæˆçš„æ¯ä¸€ä¸ªåºåˆ—æ ·æœ¬ï¼Œæ¯ä¸€ä¸ªtokenè¾“å‡ºå‰çš„vocabulary åˆ†å¸ƒå’Œ ref_modelçš„åˆ†å¸ƒ ä¸¤è€…è®¡ç®—klæ•£åº¦ï¼ˆä½¿ç”¨äº†è¿‘ä¼¼æ–¹æ³•ä½¿å¾—è®¡ç®—åŠ é€Ÿï¼‰ï¼Œå³è¾“å‡ºä¸€ä¸ª klæ•£åº¦åºåˆ—ï¼Œåºåˆ—ä¸­æ¯ä¸ªå…ƒç´ è¡¨ç¤ºå¯¹åº”ä½ç½®tokençš„klæ•£åº¦ã€‚ å°†åºåˆ—çº§çš„score åŠ åˆ°klåºåˆ—ä¸­æ¯ä¸€ä¸ªä½ç½®ï¼Œç»“æœå³ä¸º rewards åºåˆ— ä¾æ¬¡è®¡ç®—å¹¿ä¹‰ä¼˜åŠ¿ä¼°è®¡ gaeï¼ŒGAE(t)=rewards(t) + gamma*value(t+1) - value(t) + gamma*lam*GAE(t+1)ï¼Œè¿™é‡Œlamæ˜¯æŒ‡lambda è®¡ç®— return return(t) = GAE(t)+ value(t) ã€‚ï¼ˆè¿™é‡ŒæŠŠvalueç†è§£æˆæ˜¯ tæ­¥çš„çŠ¶æ€stateä¸‹ï¼Œæœªæ¥å¥–åŠ±çš„æ€»å’ŒæœŸæœ›ï¼Œå³ çŠ¶æ€æœ¬èº«çš„ä»·å€¼ï¼‰ã€‚ valueå³ state value functionï¼ŒGAEå³ é’ˆå¯¹çš„æ˜¯actionã€‚ å†…å¾ªç¯ï¼šé’ˆå¯¹ä¸Šè¿°æ­¥éª¤ç”Ÿæˆçš„åºåˆ—æ ·æœ¬å’Œå¯¹åº”çš„returnã€GAEã€æ¦‚ç‡logp åºåˆ—ï¼Œå°†æ ·æœ¬æ‹†åˆ†æˆ micro batchï¼Œæ‰§è¡Œä¸‹åˆ—æ­¥éª¤ value ä¼˜åŒ–çš„æŸå¤±å‡½æ•°ä¸º (return - value(t))^2ï¼Œå…¶å®å°±æ˜¯çº¦æŸ ä¼˜åŠ¿advantage GAE æœ¬èº«å°½é‡ã€‚ ä½¿ç”¨å½“å‰çš„policy model è®¡ç®—action çš„æ–°æ¦‚ç‡å€¼ $\\large \\log p_{\\theta}$ policy gradientæŸå¤±ä¸º $\\Large - GAE * exp(\\log p_{\\theta}-\\log p_{\\theta_{old}})$ æˆ‘æƒ³è¿™é‡Œè¿™ä¹ˆå†™æ˜¯ä¸ºäº†æ•°å€¼ç¨³å®šæ€§ï¼Œå› ä¸ºä¸€èˆ¬æ˜¯è®©æ¨¡å‹è¾“å‡º logpï¼Œç„¶åè®¡ç®— æ¦‚ç‡æ¯”ï¼Œé‚£ä¹ˆå°±ç›´æ¥ç›¸å‡ç„¶åå–æŒ‡æ•°ã€‚èƒŒåå…¶å®å°±æ˜¯ logsumexpç®—å­ã€‚ ä¸¤ä¸ªæŸå¤±åŠ è½½ä¸€èµ·è¿›è¡Œåå‘ä¼ æ’­ï¼Œå³ä¼šä¿®æ”¹å½“å‰çš„policy_modelå’Œvalue_model è¾“å‡ºå’Œä¿å­˜å„ç§æ¨¡å‹ local_rollout_forward_batch_size æ˜¯æ¯ä¸ªèŠ‚ç‚¹ï¼Œåœ¨æœ¬åœ°è¿›è¡Œå¤šæ‰¹æ¬¡çš„è®­ç»ƒï¼Œæ¯ä¸ªæ‰¹æ¬¡çš„å¤§å°å³ä¸º local_rollout_forward_batch_sizeã€‚\npolicy_modelå’Œref_modelåœ¨rolloutä¸­è°ƒç”¨çš„æ–¹æ³•ä¸åŒ 3. policy_modelä½¿ç”¨trl.trainer.utils.batch_generationï¼ˆæ˜¯å¯¹æ‰€æœ‰è®¡ç®—èŠ‚ç‚¹çš„å¹¶è¡Œæ‰¹é‡åŒ–è®¡ç®—ï¼‰ã€‚å°±æ˜¯åœ¨queryä¹‹åæ‹¼æ¥é¢„æµ‹å‡ºæ¥çš„responseã€‚ 1. batch_generation ä½¿ç”¨generation_configå‚æ•°ï¼Œä»£ç ä¸­è§„å®š max_new_tokens=args.response_lengthï¼Œå³ç¡¬æ€§æŒ‡å®šäº†responseé•¿åº¦ã€‚ 2. responseåœ¨ç”Ÿæˆå‡ºæ¥ä¹‹åï¼Œä¼šåˆå¹¶æ‰€æœ‰çš„ç«‹é©¬è¿›è¡Œå³paddingã€‚ 3. å…¶ä¸­è°ƒç”¨äº†GenerationMixinçš„generateæ–¹æ³•ï¼Œè¯¥æ–¹æ³•çš„è¾“å‡ºä¸ºtoken idsçš„åºåˆ—ã€‚ 4. ref_model ä½¿ç”¨ forwardã€‚å°±æ˜¯å°†æ•´ä¸ªquery_responseæ‹¼æ¥ç»“æœå…¨éƒ¨è¾“å…¥åˆ°ref_modelï¼Œä¸€æ¬¡æ€§å¾—å‡ºé”™ä½çš„é¢„æµ‹ç»“æœã€‚æ‰€ä»¥å¯¹logitsç´¢å¼•çš„æ—¶å€™ä¼šå¾€å‰é”™ä¸€ä½ï¼Œå¹¶ä¸”æœ€åä¸€ä¸ªä½ç½®æ˜¯ä¸éœ€è¦ä½¿ç”¨çš„ã€‚ 1. æˆ‘æƒ³batch_generationæ˜¯éœ€è¦è¿›è¡Œå¤æ‚paddingçš„ï¼Œä»è€Œå¯èƒ½å¯¼è‡´æ¯ä¸€ä¸ªå°batchç”Ÿæˆçš„è¾“å‡ºé•¿åº¦æ˜¯ä¸ä¸€è‡´çš„ã€‚ä½†æˆ‘æƒ³ä¸åˆ°ä¸ºä»€ä¹ˆè¿™ä¹ˆè°ƒç”¨çš„ç†ç”±ã€‚ 5. æ€»ä½“ä¸ŠPPOæœ‰ä¸¤ä¸ªåœ°æ–¹ç‰µæ¶‰åˆ°æ¦‚ç‡çš„å¯¹æ¯” 1. ç¬¬ä¸€ä¸ªæ˜¯ policy_modelå’Œref_modelä¸¤ä¸ªæ¨¡å‹çš„KLæ•£åº¦ï¼Œæ”¾ç½®policy_modelè·‘å¤ªè¿œè¿‡äºç¦»è°±ã€‚ 2. ç¬¬äºŒä¸ªæ˜¯ policy_modelå’Œold_policy_modelçš„æ ·æœ¬æ¦‚ç‡å¯¹æ¯”ï¼Œä½†ä¸éœ€è¦ä¿ç•™old_policy_oldè¿™ä¸ªæ¨¡å‹ï¼Œå› ä¸ºè®­ç»ƒä¸­ä»…ä»…æ˜¯ä½¿ç”¨äº† old_policy_modelçš„æ ·æœ¬å’Œå…¶æ ·æœ¬æ¦‚ç‡ï¼Œæ‰€ä»¥é€šè¿‡old_policy_modelä¸€æ¬¡é‡‡æ ·å‡ºæ¥ä¸€å¤§å †æ•°æ®ä¹‹åï¼ˆå…¶ä¸­ä¿ç•™äº†æ ·æœ¬æ¦‚ç‡ $\\Large p_{theta_{old}}$ï¼‰ï¼Œ old_policy_modelå°±å¯ä»¥ä¸¢å¼ƒï¼Œä»…ä»…é€šè¿‡ä½¿ç”¨é‡‡æ ·çš„æ ·æœ¬å’Œæ ·æœ¬æ¦‚ç‡æ¥è¿›è¡Œpolicy_modelçš„è®­ç»ƒä¼˜åŒ–ã€‚ é‚£ä¹ˆå°±ç›¸å½“äºæ˜¯ä¸¤ä¸ªæ¨¡å‹åˆäºŒä¸ºä¸€ã€‚\nclass Qwen2ForSequenceClassification(Qwen2PreTrainedModel): The Qwen2 Model transformer with a sequence classification head on top (linear layer).\n[Qwen2ForSequenceClassification] uses the last token in order to do the classification, as other causal models (e.g. GPT-2) do. è®¡ç®—çš„æ—¶å€™ä¼šæ‰¾åˆ° responseä¸­çš„ last_non_pad_tokenï¼Œè¾“å‡ºå¯¹åº”çš„logitisï¼Œç„¶åç»è¿‡scoreæ–¹æ³• è¿›è¡Œlinear_unit è®¡ç®—ã€‚\nclass AlbertForSequenceClassification(AlbertPreTrainedModel): Albert Model transformer with a sequence classification/regression head on top (a linear layer on top of the pooled output) e.g. for GLUE tasks.\ndataclassÂ æ³¨è§£æ˜¯ Python 3.7 åŠä»¥ä¸Šå¼•å…¥çš„ä¸€ä¸ªè£…é¥°å™¨ï¼Œä½œç”¨æ˜¯ç®€åŒ–ç±»çš„ç¼–å†™ï¼Œè®©ç±»è‡ªåŠ¨è·å¾—ä¸€äº›å¸¸ç”¨æ–¹æ³•ï¼ˆå¦‚Â __init__,Â __repr__,Â __eq__Â ç­‰ï¼‰ï¼Œç”¨äºè¡¨ç¤ºæ•°æ®ç»“æ„ã€‚\nä¸ºä»€ä¹ˆ è®¡ç®—ref_logprob ä½¿ç”¨ selective_log_softmaxæ–¹æ³•ï¼ŒæŒ‰ç†è¯´KLæ•£åº¦åº”è¯¥æ˜¯å¯¹vocabularyçš„æ‰€æœ‰è¯è¿›è¡ŒKLæ•£åº¦è®¡ç®—å•Šï¼Ÿ ç†è®ºä¸Šï¼ŒKLæ•£åº¦çš„å®šä¹‰æ˜¯ï¼š $$K L \\left(\\right. p \\parallel q \\left.\\right) = \\underset{i}{\\sum} p \\left(\\right. i \\left.\\right) log â¡ \\frac{p \\left(\\right. i \\left.\\right)}{q \\left(\\right. i \\left.\\right)}$$ è¿™é‡Œ (i) æ˜¯æ•´ä¸ª vocabulary çš„æ‰€æœ‰ tokenã€‚ å®é™…å·¥ç¨‹å®ç°ï¼ˆRLHF/PPOåœºæ™¯ï¼‰ï¼š 6. æˆ‘ä»¬é€šå¸¸åªå…³å¿ƒæ¨¡å‹å®é™…â€œèµ°å‡ºçš„è·¯å¾„â€ï¼Œå³ç”Ÿæˆçš„ token åºåˆ—ã€‚ 7. PPO/Reward Modeling é‡Œï¼ŒKLé¡¹æ˜¯ç”¨æ¥çº¦æŸæ–°æ¨¡å‹ï¼ˆpolicyï¼‰ä¸è¦åç¦»æ—§æ¨¡å‹ï¼ˆreference/policyï¼‰çš„è¡Œä¸ºï¼Œåªéœ€è¦å¯¹â€œå·²é‡‡æ ·çš„ tokenâ€ä¸Šçš„æ¦‚ç‡åˆ†å¸ƒåšçº¦æŸã€‚\nrewards[[actual_start, actual_end]] += scores èµ‹å€¼æ“ä½œï¼Œrewardsä¸­å­˜æ”¾çš„æ˜¯klæ•£åº¦ï¼Œè¿™é‡Œåˆ™æ˜¯å°†klæ•£åº¦å¯¹åº”æœ€åä¸€ä¸ªtokenä½ç½®å‘å³é”™ä¸€ä½çš„ä½ç½®åŠ ä¸Šä¸€ä¸ªæœ€ç»ˆçš„reward scoreã€‚ è¿™é‡Œçš„actual_startæ˜¯æ ·æœ¬çš„indexï¼Œactual_endæ˜¯æŒ‡æ¯ä¸€ä¸ªæ ·æœ¬çš„æœ€åä¸€ä¸ªtokenä½ç½®+1ã€‚\nåœ¨ Hugging Face Transformers ä¸­ï¼Œç±»åå‰çš„Â AutoÂ è¡¨ç¤ºè‡ªåŠ¨é€‰æ‹©æ¨¡å‹çš„æ„æ€ã€‚ 8. AutoModelForSequenceClassificationÂ ä¸æ˜¯ä¸€ä¸ªå…·ä½“çš„æ¨¡å‹ç±»ï¼Œè€Œæ˜¯ä¸€ä¸ªå·¥å‚ç±»ã€‚ 9. å®ƒå¯ä»¥æ ¹æ®ä½ åŠ è½½çš„ checkpointï¼ˆå¦‚Â \u0026quot;bert-base-uncased\u0026quot;ã€\u0026quot;roberta-base\u0026quot;ã€è‡ªå®šä¹‰è·¯å¾„ç­‰ï¼‰ï¼Œè‡ªåŠ¨å®ä¾‹åŒ–å¯¹åº”çš„å…·ä½“æ¨¡å‹ç±»ï¼ˆå¦‚Â BertForSequenceClassificationã€RobertaForSequenceClassificationÂ ç­‰ï¼‰ã€‚ 10. è¿™è®©ä½ ä¸éœ€è¦å…³å¿ƒåº•å±‚æ˜¯å“ªä¸ªæ¨¡å‹ï¼Œåªè¦ä¼ å…¥æ¨¡å‹åæˆ–è·¯å¾„ï¼Œå®ƒä¼šè‡ªåŠ¨å¸®ä½ é€‰æ‹©æ­£ç¡®çš„æ¨¡å‹å®ç°ã€‚\nPPOä¸­ value_modelä¸€èˆ¬ä½¿ç”¨çš„æ˜¯ sequence_classification modelï¼Œæ¯”å¦‚ ç¤ºä¾‹è„šæœ¬ ä¸­ä»£ç å¦‚ä¸‹ï¼Œvalue_modelå’Œreward_modelä½¿ç”¨çš„æ˜¯åŒä¸€ä¸ªæ¨¡å‹ç±»çš„ä¸åŒå®ä¾‹ã€‚\nvalue_model = AutoModelForSequenceClassification.from_pretrained( training_args.reward_model_path, trust_remote_code=model_args.trust_remote_code, num_labels=1 ) reward_model = AutoModelForSequenceClassification.from_pretrained( training_args.reward_model_path, trust_remote_code=model_args.trust_remote_code, num_labels=1 ) è¿™é‡Œä¸¾ä¾‹ transformers.models.qwen2.modeling_qwen2.Qwen2ForSequenceClassification\nPPOTrainerä¸­è°ƒç”¨get_rewardçš„æ—¶å€™ï¼Œä½¿ç”¨çš„æ˜¯ sequence_classfication_modelçš„ base_model_prefixæŒ‡å‘çš„åº•å±‚LLMåŸå§‹æ¨¡å‹ ã€ scoreæ–¹æ³•ï¼ˆscoreæ–¹æ³•å°±æ˜¯åœ¨baseLLMæ¨¡å‹åæ·»åŠ ä¸€ä¸ªçº¿æ€§å±‚ï¼Œä»¥æ˜ å°„åˆ°logitsï¼‰ã€‚å…¶æ•ˆæœå°±æ˜¯å¯¹ä¸€å¯¹é—®ç­”å­—ç¬¦ä¸²åºåˆ—è¾“å‡ºä¸€ä¸²rewardæ•°å€¼ã€‚\nget_rewardæ–¹æ³•ä¸­çš„å…·ä½“é€»è¾‘ã€‚ lm_backboneåº•å±‚ä½¿ç”¨çš„æ˜¯åŸºæ¨¡å‹ï¼Œå…¶ä¸­ output_hidden_states è¡¨ç¤ºè¦æŠŠæ¨¡å‹ä¸­æ‰€æœ‰å±‚çš„hidden_stateså…¨éƒ¨è¿›è¡Œè¾“å‡ºã€‚æ‰€ä»¥åœ¨è°ƒç”¨scoreçš„æ—¶å€™ä¼šåªå–æœ€åä¸€å±‚çš„hidden_statesï¼Œç„¶åè¾“å…¥åˆ°scoreæ–¹æ³•ä¸­ï¼ˆå³å†ç»è¿‡ä¸€å±‚çº¿æ€§å±‚å¾—åˆ°logitsï¼‰ã€‚æ•ˆæœå°±æ˜¯å¯¹äºé—®ç­”å­—ç¬¦ä¸²åºåˆ—ä¸­çš„æ¯ä¸€ä¸ªtokenéƒ½ä¼šå¾—åˆ°ä¸€ä¸ªreward_logitsæ•°å€¼ã€‚\noutput = lm_backbone( input_ids=input_ids, attention_mask=attention_mask, position_ids=position_ids, return_dict=True, output_hidden_states=True, use_cache=False, # otherwise mistral-based RM would error out ) reward_logits = model.score(output.hidden_states[-1]) # è¿™é‡Œçš„output.hidden_states è¡¨ç¤ºbase_modelçš„æ‰€æœ‰å±‚çš„è¾“å‡º # output.hidden_states[-1] åˆ™è¡¨ç¤ºæœ€åä¸€å±‚çš„è¾“å‡º # Qwen2ForSequenceClassification çš„forwardä¸­è®¡ç®— lossï¼Œå°±æ˜¯æŒ‰ç…§æœ€åä¸€ä¸ªtokençš„æœ€åä¸€å±‚è¾“å‡º + çœŸå®label ä¸€èµ·è®¡ç®—å‡ºäº¤å‰ç†µ return ( reward_logits, reward_logits[ torch.arange(reward_logits.size(0), device=reward_logits.device), sequence_lengths, ].squeeze(-1), sequence_lengths, ) # è¿™é‡Œè¡¨ç¤ºè¿”å› responseåºåˆ—ä¸­æœ€åä¸€ä¸ªåˆæ³•tokençš„logitsè¾“å‡º transformers.models.qwen2.modeling_qwen2.Qwen2ForSequenceClassification æ˜¯ä¸€ä¸ªä¾‹å­æ¨¡å‹ï¼Œè¯¥æ¨¡å‹çš„forwardæ–¹æ³•ä¸­è®¡ç®—äº†æ¯ä¸€ä¸ªtokenè¾“å‡ºçš„åˆ†ç±»çš„logitsï¼Œç„¶åä»…ä»…è·å–äº†æ¯ä¸€ä¸ªåºåˆ—çš„æœ€åä¸€ä¸ª non_padding_tokençš„logitsä½œä¸ºè¾“å‡ºã€‚\nreward_modelå¾—åˆ°çš„ä¸€ä¸ªåºåˆ—ä¸€ä¸ªrewardå€¼ï¼Œä½†å…¶å®æ˜¯æœ€åä¸€æ­¥çš„immediate rewardã€‚ value_modelå¾—åˆ°çš„æ¯ä¸€ä¸ªåŠ¨ä½œï¼ˆå³tokenï¼‰ä¸€ä¸ªvalueå€¼ï¼ˆå³é•¿æœŸæ•ˆæœçš„è¯„ä¼°çš„æŒ‡æ ‡ï¼‰ã€‚\nPPOTrainerä¸­ ä¸ºä»€ä¹ˆéœ€è¦æœ‰ missing_eos_penaltyï¼Ÿ\nåœ¨Â PPOTrainerÂ ä¸­å­˜åœ¨Â missing_eos_penaltyï¼Œä¸»è¦æ˜¯ä¸ºäº†è§£å†³Â ç”Ÿæˆç»“æœæ²¡æœ‰åŒ…å«ç»ˆæ­¢ç¬¦ï¼ˆå¦‚Â eos_token_idï¼‰çš„æƒ…å†µï¼Œé˜²æ­¢æ¨¡å‹ç”Ÿæˆä¸å®Œæ•´æˆ–å¼‚å¸¸çš„å“åº”ã€‚\nåœ¨æ–‡æœ¬ç”Ÿæˆä»»åŠ¡ä¸­ï¼Œæ¨¡å‹é€šå¸¸ä¼šåœ¨å“åº”ç»“å°¾ç”Ÿæˆä¸€ä¸ªâ€œç»ˆæ­¢ç¬¦â€ï¼ˆä¾‹å¦‚Â eos_token_idï¼‰ï¼Œè¡¨ç¤ºå“åº”ç»“æŸã€‚ å¦‚æœæ¨¡å‹æ²¡æœ‰ç”Ÿæˆç»ˆæ­¢ç¬¦ï¼Œå“åº”å¯èƒ½ï¼š è¶…é•¿ï¼ˆä¸€ç›´ç”Ÿæˆåˆ°æœ€å¤§é•¿åº¦ï¼‰ ä¸å®Œæ•´ï¼ˆç¼ºå°‘è¯­æ³•ä¸Šçš„ç»“å°¾ï¼‰ å½±å“åç»­è¯„ä¼°å’Œè®­ç»ƒï¼ˆå¦‚å¥–åŠ±æ¨¡å‹ã€PPOç­‰ï¼‰ å¦‚æœå“åº”æ²¡æœ‰ç»ˆæ­¢ç¬¦ï¼Œå¯èƒ½æ˜¯æ¨¡å‹æ²¡å­¦ä¼šâ€œä½•æ—¶ç»“æŸâ€ï¼Œè¿™ç§å“åº”ä¸€èˆ¬æ˜¯ä¸ç¬¦åˆä»»åŠ¡é¢„æœŸçš„ï¼Œéœ€è¦æƒ©ç½šã€‚ missing_eos_penaltyÂ å°±æ˜¯å¯¹è¿™ç§æƒ…å†µåŠ ä¸€ä¸ªè´Ÿåˆ†ï¼Œé¼“åŠ±æ¨¡å‹åœ¨åˆé€‚çš„æ—¶å€™ç”Ÿæˆç»ˆæ­¢ç¬¦ã€‚ Approximating KL Divergence\nPPOTrainerä¸­ä¸ºä»€ä¹ˆè¦whiten_rewards åœ¨Â PPOTrainerÂ ä¸­ï¼Œå­˜åœ¨ä¸€ä¸ªå‚æ•°Â whiten_rewardsï¼Œå…¶ä½œç”¨æ˜¯å¯¹å¥–åŠ±ï¼ˆrewardï¼‰è¿›è¡Œå½’ä¸€åŒ–/æ ‡å‡†åŒ–ï¼ˆwhiteningï¼‰ã€‚ å¥–åŠ±çš„å°ºåº¦å’Œåˆ†å¸ƒç›´æ¥å½±å“ä¼˜åŠ¿çš„åˆ†å¸ƒï¼Œè€Œä¼˜åŠ¿åˆ†å¸ƒåˆå½±å“æ¢¯åº¦æ›´æ–°çš„ç¨³å®šæ€§å’Œè®­ç»ƒé€Ÿåº¦ã€‚ å¦‚æœå¥–åŠ±å¾ˆå¤§æˆ–å¾ˆå°ï¼Œä¼šå¯¼è‡´ç­–ç•¥æ¢¯åº¦å¾ˆå¤§/å¾ˆå°ï¼Œå½±å“æ”¶æ•›é€Ÿåº¦ï¼Œç”šè‡³å¯¼è‡´æ¢¯åº¦çˆ†ç‚¸/æ¶ˆå¤±ã€‚\né‚£ä¹ˆåœ¨é‡‡æ ·é˜¶æ®µè®¡ç®—çš„rewardã€ valueç­‰æ•°æ®ï¼Œå› ä¸ºåœ¨è®­ç»ƒé˜¶æ®µè¿™äº›æ•°æ®ä¸­çš„å¾ˆå¤šä¼šé‡æ–°ç”Ÿæˆï¼Œæ‰€ä»¥é‡‡æ ·é˜¶æ®µå¾ˆå¤šè®¡ç®—æ˜¯ä¸æ˜¯æµªè´¹äº†?\né‡‡æ ·é˜¶æ®µçš„ value/logprobåªç”¨ä¸€æ¬¡ï¼Œè®­ç»ƒé˜¶æ®µä¼šé‡æ–°ç®—â€œæ–°ç­–ç•¥â€çš„ value/logprobã€‚ for t in reversed(range(gen_length)): nextvalues = values[:, t + 1] if t \u0026lt; gen_length - 1 else 0.0 delta = rewards[:, t] + args.gamma * nextvalues - values[:, t] lastgaelam = delta + args.gamma * args.lam * lastgaelam advantages_reversed.append(lastgaelam) advantages = torch.stack(advantages_reversed[::-1], axis=1) returns = advantages + values advantages = masked_whiten(advantages, ~padding_mask) advantages = torch.masked_fill(advantages, padding_mask, 0) è¿™é‡Œè®¡ç®—returnå’Œadvantageã€‚returnå°±æ˜¯ state valueçš„ä¸€ä¸ªçœŸå®é‡‡æ ·ï¼Œç”¨æ¥è®¡ç®— value_lossï¼Œå³returnå’Œä¼°è®¡çš„valueä¹‹é—´çš„å¹³æ–¹æŸå¤±ã€‚advantage å°±æ˜¯ ä¼˜åŠ¿ï¼Œå³å½“å‰æ—¶åˆ»ä»¥åŠæ¯ä¸ªä¹‹åçš„æ—¶åˆ»æ‰€è®¡ç®—çš„advantageçš„æ‰“æŠ˜ä¹‹å’Œï¼Œç”¨æ¥ç»™ç­–ç•¥æ¢¯åº¦åŠ æƒã€‚\næŸå¤±å‡½æ•°\nlogprobs_diff = new_logprobs - mb_logprobs ratio = torch.exp(logprobs_diff) pg_losses = -mb_advantage * ratio pg_losses2 = -mb_advantage * torch.clamp(ratio, 1.0 - args.cliprange, 1.0 + args.cliprange) pg_loss_max = torch.max(pg_losses, pg_losses2) pg_loss = masked_mean(pg_loss_max, ~padding_mask[micro_batch_inds]) loss = pg_loss + args.vf_coef * vf_loss è¿™å—ä»£ç ä¸­ä¸ºä»€ä¹ˆæ²¡æœ‰ä½¿ç”¨ logpçš„å¯¼æ•°ï¼ŒåŸå› æ˜¯ $\\Large \\mathbb{E}{\\beta} \\left[ \\frac{\\pi{\\theta}(a|s)}{\\beta(a|s)} Q^{\\pi}(s,a)\\nabla_{\\theta} \\ln \\pi_{\\theta}(a|s) \\right]$ ï¼Œå…¶å®å°±æ˜¯ $\\Large \\mathbb{E}{\\beta} \\left[ \\frac{\\nabla{\\theta} \\pi_{\\theta}(a|s)}{\\beta(a|s)} Q^{\\pi}(s,a) \\right]$ï¼Œé‚£ä¹ˆå¯¹åº”çš„æŸå¤±å‡½æ•°å°±æ˜¯ä»¥$\\large \\theta$ä¸ºä¼˜åŒ–å‚æ•°çš„ $\\Large - \\mathbb{E}{\\beta} \\left[ \\frac{\\pi{\\theta}(a|s)}{\\beta(a|s)} Q^{\\pi}(s,a) \\right]$ã€‚\nmb_logprobs åœ¨lossä¸­ä¸ä¼šåå‘ä¼ æ’­æ¢¯åº¦ä¹ˆ å› ä¸º mb_logprobsè®¡ç®—çš„æ—¶å€™æ˜¯åœ¨ with torch.no_grad(): ä¸­ã€‚\nvf_losses1 = torch.square(vpred - mb_return) è¿™é‡Œçš„mb_return å°±æ˜¯åç»­å¤šæ­¥ç´¯ç§¯çš„rewardå€¼ã€‚\nä¸ºä»€ä¹ˆpolicy loss å’Œ value function loss è¦åŠ èµ·æ¥è¿›è¡Œoptimizeï¼Ÿ\nå¦‚æœä½ è®¾è®¡äº†åˆ†ç¦»çš„ policy model å’Œ value modelï¼ˆå³ Actor å’Œ Critic å®Œå…¨åˆ†ç¦»ï¼‰ï¼Œé‚£ä¹ˆç¡®å®å¯ä»¥åˆ†å¼€ optimizeã€åˆ†å¼€ backwardã€‚ ä½†æœ€ä¸»æµçš„å®ç°ï¼ˆæ¯”å¦‚ Huggingface Transformers çš„ PPOTrainerï¼‰æ˜¯åˆä¸€æ¨¡å‹ï¼Œä¸€ä¸ªæ¨¡å‹é‡Œæœ‰ä¸¤ä¸ªè¾“å‡º headï¼Œå‚æ•°æ˜¯å…±äº«çš„ï¼Œæ‰€ä»¥å¿…é¡»æŠŠ loss åˆåœ¨ä¸€èµ·ï¼Œç»Ÿä¸€ backward å’Œ optimizeã€‚ ä¼˜åŒ–å™¨ï¼ˆoptimizerï¼‰ä¼šå¯¹æ‰€æœ‰å‚æ•°åšæ¢¯åº¦æ›´æ–°ï¼Œpolicy head å’Œ value headçš„æ¢¯åº¦ä¼šåˆ†åˆ«å›ä¼ åˆ°ä¸»å¹²å’Œå„è‡ª headã€‚ åœ¨train æ–¹æ³•å†…ï¼Œref_policy æ˜¯è‡ªå§‹è‡³ç»ˆ ä¸€è‡´ä¿æŒä¸å˜çš„ã€‚ref_policy åªæ˜¯é¿å… policy_model è·‘å¾—å¤ªè¿œã€‚è€Œæ ·æœ¬é‡ç”¨æ˜¯ä½¿ç”¨importantce weightæ¥è§£å†³çš„ï¼Œå³ $\\large \\mathbb{E}{\\beta} \\left[ \\frac{ \\pi{\\theta}(a|s)}{\\beta(a|s)} \\right]$ ã€‚\nè¿™ä¸ªPPOç®—æ³•çš„å®ç°ï¼Œä¸ºä»€ä¹ˆæ—¢æœ‰klæ•£åº¦è®¡ç®—ä½œä¸º rewardï¼ŒåŒæ—¶åˆæœ‰clipæ“ä½œ\nclip objectiveï¼šæ§åˆ¶å•æ¬¡æ›´æ–°ä¸è¦å¤ªå¤§ï¼Œé˜²æ­¢è®­ç»ƒä¸ç¨³å®šã€‚ KL æ•£åº¦å¥–åŠ±ï¼šä¿è¯æ•´ä½“ç­–ç•¥ä¸ä¼šé€æ¸åç¦»å‚è€ƒæ¨¡å‹ï¼ˆhuman-preference-aligned policyï¼‰å¤ªè¿œã€‚ KL æ•£åº¦ç›¸å½“äºåœ¨ å¥–åŠ±å±‚é¢æƒ©ç½šç­–ç•¥è¿œç¦»å‚è€ƒæ¨¡å‹ï¼Œé¿å…æ¨¡å‹è·‘åï¼›è¿™å°±æ˜¯æ‰€è°“çš„â€œKL å¥–åŠ±å¡‘å½¢â€ã€‚ clip è§£å†³ çŸ­æœŸè®­ç»ƒç¨³å®šæ€§ï¼› KL å¥–åŠ±è§£å†³ é•¿æœŸåç§»é—®é¢˜ï¼Œç›¸å½“äºç»™æ¨¡å‹åŠ äº†ä¸ªâ€œç‰µå¼•ç»³â€ã€‚ ä½ çœ‹åˆ°çš„å®ç°é‡Œï¼ŒKL æ•£åº¦ä¸æ˜¯ç›´æ¥å½“çº¦æŸç”¨ï¼Œè€Œæ˜¯ä½œä¸ºå¥–åŠ±é¡¹å‚ä¸å›æŠ¥è®¡ç®—ï¼›è€Œ clip åˆ™åœ¨ä¼˜åŒ–ç›®æ ‡é‡Œçº¦æŸç­–ç•¥æ›´æ–°ã€‚è¿™ä¸¤è€…æ˜¯äº’è¡¥å…³ç³»ã€‚\nDPO TRPOä¸­çš„POå’Œ DPOä¸­çš„POæŒ‡çš„ä¸æ˜¯ä¸€ä¸ªä¸œè¥¿ï¼Ÿ\nTRPOï¼šå®ƒçš„ç›®æ ‡æ˜¯æœ€å¤§åŒ–ç¯å¢ƒå¥–åŠ±ã€‚TRPO (Trust Region Policy Optimization) DPOï¼šå®ƒçš„ç›®æ ‡æ˜¯æœ€å¤§åŒ–äººç±»åå¥½ã€‚ DPO (Direct Preference Optimization) DPOçš„ç›´è§‰åŒ–ç†è§£\næ•´ä½“çš„ç›®æ ‡å‡½æ•°ä¸º $$\\large L(\\theta) = \\max_{\\pi_\\theta} \\mathbb{E}{x \\sim D, y \\sim \\pi\\theta} [r(x, y)] - \\beta \\text{KL}[\\pi_\\theta(y|x), \\pi_{\\theta_{\\text{old}}}(y|x)]$$ï¼Œå‡½æ•°è¡¨è¾¾çš„æ„ä¹‰æ˜¯ï¼Œåœ¨ä¸€ä¸ªå¥–åŠ±ç»“æ„ä¸Šï¼Œpolicyçš„ç»“æ„å¿…é¡»å°½é‡ä¸å¥–åŠ±ç»“æ„ä¿æŒä¸€è‡´ï¼Œä½†åŒæ—¶ä¸è¦åç¦»è€çš„policyå¤ªè¿œï¼Œåè€…å¯ä»¥è®¤ä¸ºæ˜¯ä¸€å®šç¨‹åº¦çš„æ­£åˆ™åŒ–ã€‚ å½¢è±¡åŒ–ç†è§£ï¼Œå¯¹äº yå˜é‡çš„æ¦‚ç‡åˆ†å¸ƒå’Œå¥–åŠ±åˆ†å¸ƒï¼ˆå³æ¨ªè½´æ˜¯y çš„å„ç§å–å€¼ï¼Œçºµè½´æ˜¯å¯¹åº”yå€¼è¡Œä¸ºçš„æ¦‚ç‡å€¼å¤§å°ã€å¥–åŠ±å¤§å°ï¼‰ï¼Œé‚£ä¹ˆç”¨å›¾å½¢ç†è§£å°±æ˜¯ä¸¤æ¡æ›²çº¿ï¼ˆåªä¸è¿‡ä¸€ä¸ªæ˜¯å½’ä¸€åŒ–çš„æ­£å€¼ï¼Œä¸€ä¸ªæ˜¯å¯èƒ½æ­£è´Ÿå€¼å‡å­˜åœ¨ï¼‰ã€‚å¯¹äºä¸Šè¿°ç›®æ ‡å‡½æ•°æ¥è¯´ï¼Œæš‚ä¸”è®¤ä¸ºå¥–åŠ±åˆ†å¸ƒ$r(x,y)$å°±æ˜¯çœŸå®çš„è®­ç»ƒæ•°æ®å€¼ï¼ˆä½†å…¶å®æ˜¯ä» æ­£è´Ÿä¾‹responseçš„ contrastive lossæ‹Ÿåˆå‡ºæ¥çš„å€¼ï¼‰ï¼Œé‚£ä¹ˆ$L(\\theta)$ä¸­çš„å”¯ä¸€å˜é‡å°±æ˜¯ ç­–ç•¥å‡½æ•° $\\pi_{\\theta}$ ï¼Œè¿™ä¸ªæ—¶å€™ç›®æ ‡å‡½æ•°$L(\\theta)$å…¶å®å°±æ˜¯ä¸€ä¸ªä»¥ $\\pi_\\theta$ä¸ºè‡ªå˜é‡çš„ä¸€ä¸ªå‡½æ•°ï¼ˆå½“ç„¶è‡ªå˜é‡æœ¬èº«å°±æ˜¯æ¦‚ç‡åˆ†å¸ƒå‡½æ•°ï¼Œé‚£ä¹ˆè¿™å…¶å®å°±æ˜¯ä¸€ä¸ªæ³›å‡½ä¼˜åŒ–é—®é¢˜ï¼‰ï¼›å¯¹ä¸Šè¿°ç›®æ ‡å‡½æ•°è¿›è¡Œå˜æ¢ï¼Œå¯ä»¥å¾—å‡º $L(\\theta)$å–å¾—æœ€å¤§å€¼å¯¹åº”çš„è‡ªå˜é‡ $\\pi_\\theta$ æ˜¯æœ‰ä¸€ä¸ªå›ºå®šå…¬å¼çš„ï¼Œå³ $$\\large \\pi_r(y|x) = \\pi^*(y|x) = \\frac{1}{Z(x)}\\pi_{\\theta_{\\text{old}}}(y|x) \\exp\\left(\\frac{1}{\\beta}r(x,y)\\right)$$ã€‚ è¿™é‡Œå¯ä»¥æç®€çš„æ–¹æ³•æ¨å¯¼å¤„ç†ï¼Œå¦‚ä¸‹ $$L =\\mathbb{E}[r]-KL = \\sum_{p} p*(r-\\log(\\frac{p}{q})) = \\sum_{p} p*(\\log(e^r)-\\log(\\frac{p}{q}))=\\sum_{p} p*(\\log(\\frac{e^rq}{p})) = - \\sum_{p} p(\\log(\\frac{e^rq}{p})) = - KL(p, e^rq)$$ï¼Œè€Œæœ€åä¸€ä¸ªå¼å­å°±æ˜¯KLæ•£åº¦çš„å…¬å¼å–è´Ÿæ•°ï¼ŒKLæ•£åº¦å…¬å¼å­˜åœ¨æœ€å°å€¼ï¼Œé‚£ä¹ˆ$L$å°±å­˜åœ¨æœ€å¤§å€¼ï¼Œæœ€ä¼˜ç‚¹å³ä¸º $\\large p = e^r*q$ï¼Œæœ€åå…¬å¼å¤–å›´å¥—ä¸ªå½’ä¸€åŒ–å°±æ˜¯æœ€ç»ˆçš„æ¨ç†ç»“æœã€‚ ç›´è§‰åŒ–çš„ç†è§£å°±æ˜¯ ç­–ç•¥å‡½æ•° -\u0026gt; å’Œå¥–åŠ±ç»“æ„å¯¹åº”çš„æœ€ä¼˜ç­–ç•¥å‡½æ•° -\u0026gt; å¾—åˆ°æœ€ä¼˜çš„æ•´ä½“ç›®æ ‡å€¼ã€‚è€Œå¥–åŠ±ç»“æ„å¿…é¡»ä¸çœŸå®çš„æ­£è´Ÿæ ·ä¾‹åå¥½ç»“æ„ä¸€è‡´ï¼Œæ‰€ä»¥æ•´ä½“ä¸Šå°±æ˜¯ å¥–åŠ±ç»“æ„å’Œç­–ç•¥å‡½æ•°æ˜¯ç»‘æ­»çš„æœ‰å›ºå®šå‡½æ•°å…³ç³»ï¼Œè€Œå¥–åŠ±ç»“æ„é€šè¿‡æŸå¤±å‡½æ•°ä¸çœŸå®æ­£è´Ÿæ ·ä¾‹åå¥½å¯¹é½ï¼Œé‚£ä¹ˆåå‘æ¥è¯´å°±æ˜¯ çœŸå®æ­£è´Ÿæ ·ä¾‹åå¥½-\u0026gt;æŒ‡å¯¼å¥–åŠ±ç»“æ„è®¡ç®— -\u0026gt;æŒ‡å¯¼å¯¹åº”çš„ç­–ç•¥å‡½æ•°ï¼Œ è€Œå¯¹åº”ç­–ç•¥å‡½æ•°å…¶å®æœ¬æ¥å°±åº”è¯¥è¾¾åˆ°ä¸€ç§æç«¯ç­–ç•¥ï¼ˆå³ä½¿å¾—å¥–åŠ±æœ€å¤§çš„responseçš„æ¦‚ç‡ç›´æ¥æ‹‰åˆ°æœ€å¤§å€¼1ï¼‰ï¼Œä½†å› ä¸ºæ­£åˆ™åŒ–çš„å­˜åœ¨ä½¿å¾— ç­–ç•¥å‡½æ•°æ˜¯ä»‹äº è€ç­–ç•¥å‡½æ•°å’Œ æç«¯ç­–ç•¥ ä¹‹é—´çš„ä¸­é—´ç­–ç•¥ã€‚ å‡å¦‚æ²¡æœ‰æ­£åˆ™åŒ–ï¼Œé‚£ä¹ˆæ•´ä¸ªè¿‡ç¨‹å°±æ˜¯æç«¯ç­–ç•¥ï¼Œè®©æ­£æ ·ä¾‹çš„ç”Ÿæˆæ¦‚ç‡æ— é™å¤§ï¼Œè´Ÿæ ·ä¾‹çš„ç”Ÿæˆæ¦‚ç‡æ— é™å°ï¼Œä¹Ÿå°±æ˜¯å¯¹åº”çš„logitsä¹‹å·®æ— é™å¤§ï¼Œé‚£ä¹ˆæ­£æ ·ä¾‹çš„æ¦‚ç‡ç›´æ¥ä¸º1ï¼Œè´Ÿæ ·ä¾‹çš„æ¦‚ç‡ç›´æ¥ä¸º0ï¼Œä½†è¿™æ ·å…¶å®å°±æ˜¯è¿‡æ‹Ÿåˆã€‚æ‰€ä»¥éœ€è¦æ­£åˆ™åŒ–æ¥é™åˆ¶ï¼Œé‚£ä¹ˆå°±æ˜¯é€šè¿‡ ç”¨æ¦‚ç‡çš„logitsæ¥è¡¨ç¤º $r(x,y)$ï¼ŒåŒæ—¶å‡å®šæŸå¤±ç»“æ„æ˜¯ è®© $r(x,y)$ å’Œ KLæ•£åº¦ç›´æ¥ç›¸åŠ ï¼Œæ¥ä½œä¸ºæœ€ç»ˆçš„ç›®æ ‡å‡½æ•°ã€‚ ç›´è§‚ä¸Šç†è§£DPOçš„å…¬å¼ï¼Œå³è®©æ­£åå¥½çš„å¯¹åº”çš„ç­–ç•¥actionæ¦‚ç‡è¶Šå¤§å¥½ï¼Œè®©è´Ÿåå¥½å¯¹åº”çš„ç­–ç•¥actionæ¦‚ç‡è¶Šå°è¶Šå¥½ã€‚ $$\\large L(\\theta)=-\\mathbb{E}{(x,y^+,y^-) \\sim \\mathcal{D}}\\left[\\log \\sigma\\left(\\beta \\log \\frac{\\pi{\\theta}(y^+|x)}{\\pi_{\\theta_{old}}(y^+|x)}-\\beta \\log \\frac{\\pi_{\\theta}(y^-|x)}{\\pi_{\\theta_{old}}(y^-|x)}\\right)\\right].$$ å…¶ä¸­$\\large \\hat{r}\\theta(x,y) = \\beta \\log \\left( \\frac{\\pi\\theta(y|x)}{\\pi_{\\theta_{old}}(y|x)} \\right)$ æ„æ€æ˜¯ï¼Œå¦‚æœå½“å‰ç­–ç•¥å¯¹åº”çš„é¢„ä¼°å¥–åŠ±æ˜¯å¤šå°‘ã€‚\nç›´è§‰ä¸Šæˆ‘å°†DPOæ¯”ä½œæ˜¯ä¸€ä¸ªä¸‰ä¸ªé“æ†ä¸Šåˆ†åˆ«å¥—ç€ä¸€ä¸ªç¯ï¼Œä¸‰ä¸ªé“ç¯ä¹‹é—´ æœ‰ä¸¤ä¸ªç»³å­è¿æ¥ï¼Œä¼ ç»Ÿçš„policy gradientæ˜¯å°†é€šè¿‡æ‹‰æœ€ä¸‹é¢ä¸€ä¸ªç¯ï¼Œè®©ä¸Šé¢ä¸¤ä¸ªé—´æ¥è¿å¸¦ç€ç§»åŠ¨ã€‚è€ŒDPOæ˜¯å°†ä¸Šé¢ä¸¤ä¸ªç¯å›ºåŒ–æˆä¸€ä½“ï¼Œåªè¦ç§»åŠ¨æœ€ä¸‹é¢ä¸€ä¸ªï¼Œå°±èƒ½è¾¾åˆ°ç›´æ¥ç§»åŠ¨æœ€ä¸Šé¢é“ç¯çš„ç›®çš„ã€‚\nDPOç®—æ³•çš„è®­ç»ƒæ ‡å‡†æ•°æ®ï¼Œéƒ½æ˜¯é…å¯¹çš„ã€‚\nDPOç®—æ³•ä¸­æŸå¤±å‡½æ•°ä¸­çš„logpæŒ‡çš„æ˜¯ä¸æ˜¯æ•´æ¡episodeä¸­ç­”æ¡ˆçš„æ¦‚ç‡logï¼Œå³åœ¨ç»™å®špromptçš„æƒ…å†µä¸‹ï¼Œç»™å‡ºresponseçš„æ¯ä¸ªtokenæ¦‚ç‡çš„ä¹˜ç§¯ï¼Œä¹Ÿå°±æ˜¯logpçš„å’Œã€‚\nGRPO DeepSeekMath è®ºæ–‡çš„è§£è¯» [[2025Q3-è®ºæ–‡å­¦ä¹ æ—¥è®°#2025-07-16 DeepSeekMath]] GRPO ä¸­ä½¿ç”¨äº†process supervision ä¿¡å·ï¼Œå³å•ä¸ªreponseçš„å¤šæ­¥æ¨ç†ï¼Œæ¯ä¸€æ­¥éƒ½æœ‰æ ‡æ³¨çš„rewardã€‚ç„¶å advantage å°±æ˜¯ å½’ä¸€åŒ–åçš„reward åœ¨tæ­¥ä¹‹åçš„ç´¯è®¡å’Œã€‚å³åŸºäºåŒä¸€ä¸ªpromptçš„æ‰€æœ‰responseçš„rewardçš„å‡å€¼å’Œæ–¹å·® è¿›è¡Œæ ‡å‡†åŒ– $\\Large \\tilde{r}i^{index(j)} = \\frac{r_i^{index(j)} - \\text{mean}(\\mathbf{R})}{\\text{std}(\\mathbf{R})}$ ï¼Œç„¶åç´¯è®¡å’Œ $\\Large \\hat{A}{i,t} = \\sum_{index(j) \\geq t} \\tilde{r}_i^{index(j)}$ ï¼Œè¿™é‡Œtå°±æ˜¯æ¯ä¸€ä¸ªtokenï¼Œjæ˜¯æ¯ä¸€ä¸ªreasoning stepï¼Œå³æ¯ä¸€ä¸ªtokenå…¶rewardå°±æ˜¯è¯¥tokenä¹‹åæ‰€æœ‰å¯¹åº”äº reasoning step end tokençš„tokençš„å¥–åŠ±ä¹‹å’Œã€‚æˆ‘æƒ³è¿™é‡Œä¹‹æ‰€ä»¥æ²¡æœ‰ä½¿ç”¨$\\gamma$ å¯èƒ½æ˜¯å› ä¸ºreasoning stepæ•°é‡æœ¬æ¥éƒ½æ˜¯æå…¶æœ‰é™çš„ï¼Œå¹¶ä¸”é‡‡æ ·åº”è¯¥ä¼šæ§åˆ¶å…¶æ•°é‡ã€‚ æ‰€ä»¥GRPOæ˜¯éœ€è¦ä½¿ç”¨ process reward model å¯¹responseçš„æ¯ä¸€ä¸ªæ¨ç†æ­¥éª¤è¿›è¡Œæ‰“åˆ†çš„ã€‚ The training data of the reward model is based on the rule judgment. Data Source: question in SFT dataset with outputs sampled from SFT model. Reward Function: Rule (whether the answer is correct or not) è®ºæ–‡é‡Œçš„å…¬å¼é‡Œæœ‰å¾ˆå¤šè®²ç©¶ã€‚\nåŸå§‹è®ºæ–‡ä¸­çš„å…¬å¼19\n$\\large \\mathcal{J}{\\text{GRPO}}(\\theta) = \\mathbb{E}{\\mathbf{q} \\sim P_{\\text{sft}}(Q), {o_i}{i=1}^G \\sim \\pi{\\theta_{old}}(O|q)} \\large \\frac{1}{G} \\sum_{i=1}^G \\frac{1}{|o_i|} \\sum_{t=1}^{|o_i|} \\left[ \\frac{\\pi_\\theta(o_{i,t}|q, o_{i,\u0026lt;t})}{\\pi_{\\theta_{old}}(o_{i,t}|q, o_{i,\u0026lt;t})} \\hat{A}{i,t} - \\beta \\left( \\frac{\\pi{ref}(o_{i,t}|q, o_{i,\u0026lt;t})}{\\pi_\\theta(o_{i,t}|q, o_{i,\u0026lt;t})} - \\log \\frac{\\pi_{ref}(o_{i,t}|q, o_{i,\u0026lt;t})}{\\pi_\\theta(o_{i,t}|q, o_{i,\u0026lt;t})} - 1 \\right) \\right].$\n$\\large w_{i,t}(\\theta) = \\frac{\\pi_\\theta(y_{i,t}|x, y_{i,\u0026lt;t})}{\\pi_{\\theta_{\\text{old}}}(y_{i,t}|x, y_{i,\u0026lt;t})}$\nGSPO GSPO Group Sequence Policy Optimization\n$\\large J_{\\text{GSPO}}(\\theta) = \\mathbb{E}{x \\sim D, {y_i}{i=1}^G \\sim \\pi_{\\theta_{\\text{old}}}(\\cdot|x)} \\left[ \\frac{1}{G}\\sum_{i=1}^G \\min\\left(s_i(\\theta)\\hat{A}_i, \\text{clip}(s_i(\\theta), 1-\\epsilon, 1+\\epsilon)\\hat{A}_i\\right) \\right]$\n$\\large \\hat{A}i = \\frac{r(x, y_i) - \\text{mean}({r(x, y_j)}{j=1}^G)}{\\text{std}({r(x, y_j)}_{j=1}^G)}$\n$\\large s_i(\\theta) = \\left(\\frac{\\pi_\\theta(y_i|x)}{\\pi_{\\theta_{\\text{old}}}(y_i|x)}\\right)^{\\frac{1}{|y_i|}} = \\exp\\left(\\frac{1}{|y_i|}\\sum_{t=1}^{|y_i|}\\log\\frac{\\pi_\\theta(y_{i,t}|x,y_{i,\u0026lt;t})}{\\pi_{\\theta_{\\text{old}}}(y_{i,t}|x,y_{i,\u0026lt;t})}\\right)$\nGSPOå’ŒGRPOå¼ºåŒ–å­¦ä¹ ç®—æ³•çš„åŒºåˆ«\nGRPO GSPO è®­ç»ƒæ•°æ® process supervision outcome supervision é‡è¦æ€§é‡‡æ · åŸºäºæ¯ä¸€ä¸ªtoken åŸºäºæ•´ä¸ªåºåˆ—ï¼Œæ‰€æœ‰tokené‡è¦æ€§çš„çš„å‡ ä½•å¹³å‡ ","permalink":"https://chesterwang.github.io/chester-blog/posts/2025-08-22-huggingface-%E7%B1%BB%E5%BA%93%E5%AD%A6%E4%B9%A0/","summary":"Hugging Face Hub Models, Spaces, and Datasets are hosted on the Hugging Face Hub as Git repositories Do you have files larger than 10MB? Those files should be tracked with git-lfs, which you can initialize with: git lfs install Note that if your files are larger than 5GB youâ€™ll also need to run: hf lfs-enable-largefiles . Pull Request ä¹‹æ‰€ä»¥å«è¿™ä¸ªåå­—ï¼Œæ˜¯å› ä¸ºå®ƒå‡†ç¡®åœ°æè¿°äº†è¯·æ±‚è€…ï¼ˆä½ ï¼‰å’Œè¢«è¯·æ±‚è€…ï¼ˆé¡¹ç›®ç»´æŠ¤è€…ï¼‰ä¹‹é—´çš„åŠ¨ä½œå’Œæ–¹å‘ã€‚ PR = â€œæˆ‘æ”¹å¥½äº†ï¼Œè¯·ä½ æŠŠæˆ‘è¿™è¾¹çš„ä¿®æ”¹æ‹‰ï¼ˆpullï¼‰è¿›ä½ çš„ä¸»åˆ†æ”¯å§","title":"Huggingfaceåº“å­¦ä¹ ç¬”è®°"},{"content":"\nğŸ¡ å…³äºæœ¬ç«™ æœ¬åšå®¢è®°å½•ä¸ªäººçš„æ„Ÿæƒ³å’Œå¼€å‘è¿‡ç¨‹ã€‚\nğŸ‘¦ğŸ» åšä¸»æ˜¯è° AIç®—æ³•å·¥ç¨‹å¸ˆ\nğŸ¹ å…´è¶£çˆ±å¥½ ğŸƒâ€â™‚ï¸è·‘æ­¥ | ğŸ§ éŸ³ä¹ | ğŸ›Œ æ‘†çƒ‚\n","permalink":"https://chesterwang.github.io/chester-blog/about/","summary":"ğŸ¡ å…³äºæœ¬ç«™ æœ¬åšå®¢è®°å½•ä¸ªäººçš„æ„Ÿæƒ³å’Œå¼€å‘è¿‡ç¨‹ã€‚ ğŸ‘¦ğŸ» åšä¸»æ˜¯è° AIç®—æ³•å·¥ç¨‹å¸ˆ ğŸ¹ å…´è¶£çˆ±å¥½ ğŸƒâ€â™‚ï¸è·‘æ­¥ | ğŸ§ éŸ³ä¹ | ğŸ›Œ æ‘†çƒ‚","title":"ğŸ™‹ğŸ»â€â™‚ï¸ å…³äº"},{"content":"ğŸ‘‰å‹é“¾ä¸ºéšæœºé¡ºåº cuikx\u0026#39;s blog cuikx\u0026#39;s blog Sulv\u0026#39;s Blog ä¸€ä¸ªè®°å½•æŠ€æœ¯ã€é˜…è¯»ã€ç”Ÿæ´»çš„åšå®¢ é™ˆæ¡‚æ—åšå®¢ æˆåŠŸæœ€æœ‰æ•ˆçš„æ–¹æ³•å°±æ˜¯å‘æœ‰ç»éªŒçš„äººå­¦ä¹ ï¼ é»„å¿ å¾·çš„åšå®¢ DevOps,SRE,Python,Golangç¨‹åºå‘˜,å¼€æºçˆ±å¥½è€… é˜¿è™šåŒå­¦çš„å‚¨ç‰©é—´ æ”¶é›†äº†å¾ˆå¤šå®ç”¨ç½‘ç«™ è€ç”Ÿæ‚è°ˆçš„ IT äºº è€ç”Ÿæ‚è°ˆï¼Œåç»§æœ‰äººã€‚ Yunyiâ€™s Blog Little squirrel Hopping around Yuinâ€™s blog The world is your oyster ğŸ‘‰å‹é“¾æ ¼å¼ åç§°: lvbibir's Blog\nç½‘å€: https://www.lvbibir.cn\nå›¾æ ‡: https://www.lvbibir.cn/https://image.lvbibir.cn/blog/avatar.webp\næè¿°: life is a fucking movie\nğŸ‘‰å‹é“¾ç”³è¯·è¦æ±‚ ç§‰æ‰¿äº’æ¢å‹é“¾åŸåˆ™ã€æ–‡ç« å®šæœŸæ›´æ–°ã€ä¸èƒ½æœ‰å¤ªå¤šå¹¿å‘Š\n","permalink":"https://chesterwang.github.io/chester-blog/links/","summary":"ğŸ‘‰å‹é“¾ä¸ºéšæœºé¡ºåº cuikx\u0026#39;s blog cuikx\u0026#39;s blog Sulv\u0026#39;s Blog ä¸€ä¸ªè®°å½•æŠ€æœ¯ã€é˜…è¯»ã€ç”Ÿæ´»çš„åšå®¢ é™ˆæ¡‚æ—åšå®¢ æˆåŠŸæœ€æœ‰æ•ˆçš„æ–¹æ³•å°±æ˜¯å‘æœ‰ç»éªŒçš„äººå­¦ä¹ ï¼ é»„å¿ å¾·çš„åšå®¢ DevOps,SRE,Python,Golangç¨‹åºå‘˜,å¼€æºçˆ±å¥½è€… é˜¿è™šåŒå­¦çš„å‚¨ç‰©é—´ æ”¶é›†äº†å¾ˆå¤šå®ç”¨ç½‘ç«™ è€ç”Ÿæ‚è°ˆçš„ IT äºº è€ç”Ÿæ‚è°ˆï¼Œåç»§æœ‰äººã€‚ Yunyiâ€™s Blog Little squirrel Hopping around Yu","title":"ğŸ¤ å‹é“¾"},{"content":" ","permalink":"https://chesterwang.github.io/chester-blog/talk/","summary":"","title":"ğŸ’¬ è¯´è¯´"}]