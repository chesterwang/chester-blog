<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>spark dataframeæ“ä½œæ€»ç»“! | Chester&#39;s Blog</title>
<meta name="keywords" content="spark">
<meta name="description" content="spark datagrameçš„æ“ä½œæ€»ç»“ èµ„æ–™ https://databricks.com/blog/2016/01/04/introducing-apache-spark-datasets.html Spark Datasets, an extension of the DataFrame API that provides a type-safe, object-oriented programming interface. Datasets extend these benefits with compile-time type safety â€“ meaning production applications can be checked for errors before they are run. è¿™ç‚¹éå¸¸é‡è¦ï¼Œå› ä¸ºåœ¨è¿™ç§å¤§æ•°æ®åº”ç”¨å¼€å‘ä¸­ï¼Œæ„é€ æµ‹è¯•æ•°æ®å’Œè¿è¡Œæµ‹è¯•ç¨‹åºéƒ½æ¯”è¾ƒéº»çƒ¦ï¼Œæœ‰äº†type-safeå°±å¯ä»¥çœå»å¾ˆå¤šéº»çƒ¦ã€‚ Both APIs make it easy to express the transformation using lambda functions. with Datasets you also have access to all the power of a full">
<meta name="author" content="ä½œè€…:lvbibir">
<link rel="canonical" href="https://chesterwang.github.io/chester-blog/en/posts/2016-07-16-spark-dataframe-summary/">
<link crossorigin="anonymous" href="/chester-blog/assets/css/stylesheet.a3b4d2cae219ae904272a1beae2d019e95573341f245e12d4effba204604461c.css" integrity="sha256-o7TSyuIZrpBCcqG&#43;ri0BnpVXM0HyReEtTv&#43;6IEYERhw=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/chester-blog/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js" integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG&#43;9vmJ0cTS&#43;ovo0FeA="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://image.lvbibir.cn/blog/avatar.webp">
<link rel="icon" type="image/png" sizes="16x16" href="https://image.lvbibir.cn/blog/avatar.webp">
<link rel="icon" type="image/png" sizes="32x32" href="https://image.lvbibir.cn/blog/avatar.webp">
<link rel="apple-touch-icon" href="https://image.lvbibir.cn/blog/avatar.webp">
<link rel="mask-icon" href="https://image.lvbibir.cn/blog/avatar.webp">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://chesterwang.github.io/chester-blog/en/posts/2016-07-16-spark-dataframe-summary/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = ""; 
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>





<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.25/dist/katex.min.css" integrity="sha384-WcoG4HRXMzYzfCgiyfrySxx90XSl2rxY5mnVY5TwtWE6KLrArNKn0T/mOgNL0Mmi" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.25/dist/katex.min.js" integrity="sha384-J+9dG2KMoiR9hqcFao0IBLwxt6zpcyN68IgwzsCSkbreXUjmNVRhPFTssqdSGjwQ" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.25/dist/contrib/auto-render.min.js" integrity="sha384-hCXGrW6PitJEwbkoStFjeJxv+fSOOQKOPbJxSfM6G5sWZjAyWhXiTIIAmQqnlLlh" crossorigin="anonymous"
    onload="renderMathInElement(document.body);"></script>


<script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
            delimiters: [
                {left: "$$", right: "$$", display: true},
                {left: "$", right: "$", display: false}
            ]
        });
    });
</script><meta property="og:title" content="spark dataframeæ“ä½œæ€»ç»“!" />
<meta property="og:description" content="spark datagrameçš„æ“ä½œæ€»ç»“ èµ„æ–™ https://databricks.com/blog/2016/01/04/introducing-apache-spark-datasets.html Spark Datasets, an extension of the DataFrame API that provides a type-safe, object-oriented programming interface. Datasets extend these benefits with compile-time type safety â€“ meaning production applications can be checked for errors before they are run. è¿™ç‚¹éå¸¸é‡è¦ï¼Œå› ä¸ºåœ¨è¿™ç§å¤§æ•°æ®åº”ç”¨å¼€å‘ä¸­ï¼Œæ„é€ æµ‹è¯•æ•°æ®å’Œè¿è¡Œæµ‹è¯•ç¨‹åºéƒ½æ¯”è¾ƒéº»çƒ¦ï¼Œæœ‰äº†type-safeå°±å¯ä»¥çœå»å¾ˆå¤šéº»çƒ¦ã€‚ Both APIs make it easy to express the transformation using lambda functions. with Datasets you also have access to all the power of a full" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://chesterwang.github.io/chester-blog/en/posts/2016-07-16-spark-dataframe-summary/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2016-07-16T00:00:00+00:00" />
<meta property="article:modified_time" content="2016-07-16T00:00:00+00:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="spark dataframeæ“ä½œæ€»ç»“!"/>
<meta name="twitter:description" content="spark datagrameçš„æ“ä½œæ€»ç»“ èµ„æ–™ https://databricks.com/blog/2016/01/04/introducing-apache-spark-datasets.html Spark Datasets, an extension of the DataFrame API that provides a type-safe, object-oriented programming interface. Datasets extend these benefits with compile-time type safety â€“ meaning production applications can be checked for errors before they are run. è¿™ç‚¹éå¸¸é‡è¦ï¼Œå› ä¸ºåœ¨è¿™ç§å¤§æ•°æ®åº”ç”¨å¼€å‘ä¸­ï¼Œæ„é€ æµ‹è¯•æ•°æ®å’Œè¿è¡Œæµ‹è¯•ç¨‹åºéƒ½æ¯”è¾ƒéº»çƒ¦ï¼Œæœ‰äº†type-safeå°±å¯ä»¥çœå»å¾ˆå¤šéº»çƒ¦ã€‚ Both APIs make it easy to express the transformation using lambda functions. with Datasets you also have access to all the power of a full"/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "ğŸ“š æ–‡ç« ",
      "item": "https://chesterwang.github.io/chester-blog/en/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "spark dataframeæ“ä½œæ€»ç»“!",
      "item": "https://chesterwang.github.io/chester-blog/en/posts/2016-07-16-spark-dataframe-summary/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "spark dataframeæ“ä½œæ€»ç»“!",
  "name": "spark dataframeæ“ä½œæ€»ç»“!",
  "description": "spark datagrameçš„æ“ä½œæ€»ç»“ èµ„æ–™ https://databricks.com/blog/2016/01/04/introducing-apache-spark-datasets.html Spark Datasets, an extension of the DataFrame API that provides a type-safe, object-oriented programming interface. Datasets extend these benefits with compile-time type safety â€“ meaning production applications can be checked for errors before they are run. è¿™ç‚¹éå¸¸é‡è¦ï¼Œå› ä¸ºåœ¨è¿™ç§å¤§æ•°æ®åº”ç”¨å¼€å‘ä¸­ï¼Œæ„é€ æµ‹è¯•æ•°æ®å’Œè¿è¡Œæµ‹è¯•ç¨‹åºéƒ½æ¯”è¾ƒéº»çƒ¦ï¼Œæœ‰äº†type-safeå°±å¯ä»¥çœå»å¾ˆå¤šéº»çƒ¦ã€‚ Both APIs make it easy to express the transformation using lambda functions. with Datasets you also have access to all the power of a full",
  "keywords": [
    "spark"
  ],
  "articleBody": "spark datagrameçš„æ“ä½œæ€»ç»“\nèµ„æ–™ https://databricks.com/blog/2016/01/04/introducing-apache-spark-datasets.html Spark Datasets, an extension of the DataFrame API that provides a type-safe, object-oriented programming interface. Datasets extend these benefits with compile-time type safety â€“ meaning production applications can be checked for errors before they are run. è¿™ç‚¹éå¸¸é‡è¦ï¼Œå› ä¸ºåœ¨è¿™ç§å¤§æ•°æ®åº”ç”¨å¼€å‘ä¸­ï¼Œæ„é€ æµ‹è¯•æ•°æ®å’Œè¿è¡Œæµ‹è¯•ç¨‹åºéƒ½æ¯”è¾ƒéº»çƒ¦ï¼Œæœ‰äº†type-safeå°±å¯ä»¥çœå»å¾ˆå¤šéº»çƒ¦ã€‚ Both APIs make it easy to express the transformation using lambda functions. with Datasets you also have access to all the power of a full relational execution engine. http://www.agildata.com/apache-spark-rdd-vs-dataframe-vs-dataset/ The DataFrame API introduces the concept of a schema to describe the data, allowing Spark to manage the schema and only pass data between nodes, in a much more efficient way than using Java serialization. Because the code is referring to data attributes by name, it is not possible for the compiler to catch any errors. If attribute names are incorrect then the error will only detected at runtime, when the query plan is created. the familiar object-oriented programming style and compile-time type-safety of the RDD API but with the performance benefits of the Catalyst query optimizer. Additionally, the Dataset API is designed to work equally well with both Java and Scala. When working with Java objects, it is important that they are fully bean-compliant https://databricks.com/blog/2015/08/12/from-pandas-to-apache-sparks-dataframe.html a few operations that you can do in Pandas donâ€™t translate to Spark well ä¸å¯åƒpandasé‚£æ ·è¿ç”¨è¡Œåˆ—åæ ‡è·å–å•ä¸ªå…ƒç´  ä¸èƒ½ col1 = col2*col3è¿™ç§å½¢å¼ï¼Œå› ä¸ºimmutable. The only difference is that in Pandas, it is a mutable data structure that you can change â€“ not in Spark. å˜æ€çš„åˆ—å‘½å: In Spark SQL DataFrame columns are allowed to have the same name, theyâ€™ll be given unique names inside of Spark SQL, but this means that you canâ€™t reference them with the column name only as this becomes ambiguous. import //val sqlContext = new SQLContext(sc) //import sqlContext.implicits._ DataFrame creation //createDataFrame val df = sqlContext.createDataFrame(Array((3,8,\"asdf\"),(4,8,\"ewe\"),(4,8,\"-pl[\"))).toDF(\"a\",\"b\",\"c\") df.show(10) //rdd(parallelize) then tranform to DF using toDF val rdd = sc.parallelize(Seq((1,2),(3,4),(3,5))) val df2 = rdd.toDF(\"name\",\"age\")// this creates a DataFrame with column name \"name\" and \"age\" df2.show(10) val df3 = rdd.toDF() // this implicit conversion creates a DataFrame with column name _1 and _2 df3.show(10) // load method(depreacated) val df4 = sqlContext.load(\"com.databricks.spark.csv\", Map(\"path\" -\u003e \"/home/chester/data/2016-06/partsorthead\", \"header\" -\u003e \"true\", \"delimiter\" -\u003e \"\\t\")) df4.show(10) // read val options = Map(\"header\" -\u003e \"true\", \"path\" -\u003e \"/home/chester/data/2016-07/dist\") val newStudents = sqlContext.read.options(options).format(\"com.databricks.spark.csv\").load() newStudents.show(10) save to hdfs df.select(\"year\", \"model\").save(\"newcars.csv\", \"com.databricks.spark.csv\") column rename withColumnRenamed(existingName: String, newName: String): DataFrame single column operation //Returns a new DataFrame by adding a column or replacing the existing column that has the same name. //withColumn(colName: String, col: Column): DataFrame //(column =\u003e column(new value)) or (column =\u003e new column(new value)) val clickSeqUdf = udf((score: String) =\u003e score.replace(\"(\",\"\").toInt-1) val newdf2 = newdf.withColumn(\"clickSeq\",clickSeqUdf(newdf.col(\"clickSeq\"))) multiple column operation ((column1,column2) =\u003e new column(new value))) //udf definition udf[ouput type, input2 type, input2 type] udf definition and application val toInt = udf[String, String]( _+ \"haha\") val newdf = df.withColumn(\"name\",(udf[String, String]( _+ \"haha\")).apply(df.col(\"name\"))) DataFrame join df1.join(department, df1(\"deptId\") === department(\"id\") udf of different style //æ˜¾ç¤ºå®šä¹‰udfï¼Œæ— ç±»å‹æ¨æ–­ val checksum = udf[Int,String,Int](_.toInt+_) df.withColumn(\"name\",checksum.apply($\"name\",$\"age\")).show(10) //æ˜¾ç¤ºå®šä¹‰udfå‡½æ•°,ç±»å‹æ¨æ–­ val a:(Int,Int) =\u003e Int =(x:Int,y:Int) =\u003e x+y //ç®€ç•¥å®šä¹‰ val b = (x: String, y: Int) =\u003e x.toInt + y df.withColumn(\"name\", udf(b).apply($\"name\", $\"age\")).show(10) //éšå¼å®šä¹‰udfå‡½æ•°,è‡ªåŠ¨ç±»å‹æ¨æ–­ df.withColumn(\"name\", udf((x: String, y: Int) =\u003e x.toInt + y).apply($\"name\", $\"age\")).show(10) df.filter(udf((x: String, y: Int) =\u003e x.toInt-100 \u003e y).apply($\"name\", $\"age\")).show(10) //éšå¼å®šä¹‰ï¼Œæ— ç±»å‹æ¨æ–­ df.withColumn(\"name\", udf[String, String]( x =\u003e x+ \"haha\").apply($\"name\")).show(10) //org.apache.spark.sql.functionsé‡Œå®šä¹‰äº†å¤§é‡çš„udf other operation å¦‚æœDataFrameçš„methodæ— æ³•æ»¡è¶³éœ€æ±‚çš„æ—¶å€™ï¼Œå¯ä»¥è°ƒç”¨rdd()è½¬åŒ–ä¸ºrdd, åœ¨rddä¸Šåšæ›´çµæ´»çš„æ“ä½œï¼Œä¹‹åå†è½¬åŒ–ä¸ºDataFrame.\n",
  "wordCount" : "850",
  "inLanguage": "en",
  "datePublished": "2016-07-16T00:00:00Z",
  "dateModified": "2016-07-16T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "lvbibir"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://chesterwang.github.io/chester-blog/en/posts/2016-07-16-spark-dataframe-summary/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Chester's Blog",
    "logo": {
      "@type": "ImageObject",
      "url": "https://image.lvbibir.cn/blog/avatar.webp"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://chesterwang.github.io/chester-blog/en/" accesskey="h" title="Chester&#39;s Blog (Alt + H)">
                <img src="https://image.lvbibir.cn/blog/avatar.webp" alt="" aria-label="logo"
                    height="35">Chester&#39;s Blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
                <ul class="lang-switch"><li>|</li>
                </ul>
            </div>
        </div>
        <ul id="menu">
            <li class="menu-item">
                <a href="https://chesterwang.github.io/chester-blog/en/categories" title="ğŸ¤™ğŸ¿ åˆ†ç±»">
                    <span>ğŸ¤™ğŸ¿ åˆ†ç±»</span>
                    
                </a>
            
            </li>
            <li class="menu-item">
                <a href="https://chesterwang.github.io/chester-blog/en/archives" title="ğŸ“ˆ å½’æ¡£">
                    <span>ğŸ“ˆ å½’æ¡£</span>
                    
                </a>
            
            </li>
            <li class="menu-item">
                <a href="https://chesterwang.github.io/chester-blog/en/talk" title="ğŸ’¬ è¯´è¯´">
                    <span>ğŸ’¬ è¯´è¯´</span>
                    
                </a>
            
            </li>
            <li class="menu-item">
                <a href="https://chesterwang.github.io/chester-blog/en/search" title="ğŸ” æœç´¢ (Alt &#43; /)" accesskey=/>
                    <span>ğŸ” æœç´¢</span>
                    
                </a>
            
            </li>
            <li class="menu-item">
                <a href="https://chesterwang.github.io/chester-blog/en/about" title="ğŸ™‹ğŸ»â€â™‚ï¸ å…³äº">
                    <span>ğŸ™‹ğŸ»â€â™‚ï¸ å…³äº</span>
                    
                </a>
            
            </li>
        </ul>
    </nav>
</header>
<main class="main page">
<article class="post-single">
    <div id="single-content">
        <header class="post-header">
            <div class="breadcrumbs"><a href="https://chesterwang.github.io/chester-blog/en/">ä¸»é¡µ</a>&nbsp;Â»&nbsp;<a href="https://chesterwang.github.io/chester-blog/en/posts/">ğŸ“š æ–‡ç« </a></div>
            <h1 class="post-title">
                spark dataframeæ“ä½œæ€»ç»“!
            </h1>
            <div class="post-meta">åˆ›å»º: 2016-07-16 | æ›´æ–°: 2016-07-16 | å­—æ•°: 850å­— | ä½œè€…:lvbibir


                |&nbsp;æ ‡ç­¾:&nbsp;
                <ul class="post-tags-meta">
                    <a href="https://chesterwang.github.io/chester-blog/en/tags/spark/">Spark</a>
                </ul>

                
                <span id="busuanzi_container_page_pv">
                    &nbsp;|&nbsp;è®¿é—®:&nbsp;<span id="busuanzi_value_page_pv"></span>
                </span>

</div>
        </header> <aside id="toc-container" class="toc-container wide">
    <div class="toc">
        <details  open>
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">æ–‡ç« ç›®å½•</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#%e8%b5%84%e6%96%99" aria-label="èµ„æ–™">èµ„æ–™</a></li>
                <li>
                    <a href="#import" aria-label="import">import</a></li>
                <li>
                    <a href="#dataframe-creation" aria-label="DataFrame creation">DataFrame creation</a></li>
                <li>
                    <a href="#save-to-hdfs" aria-label="save to hdfs">save to hdfs</a></li>
                <li>
                    <a href="#column-rename" aria-label="column rename">column rename</a></li>
                <li>
                    <a href="#single-column-operation" aria-label="single column operation">single column operation</a></li>
                <li>
                    <a href="#multiple-column-operation-column1column2--new-columnnew-value" aria-label="multiple column operation ((column1,column2) =&amp;gt; new column(new value)))">multiple column operation ((column1,column2) =&gt; new column(new value)))</a></li>
                <li>
                    <a href="#udf-definition-and-application" aria-label="udf definition and application">udf definition and application</a></li>
                <li>
                    <a href="#dataframe-join" aria-label="DataFrame join">DataFrame join</a></li>
                <li>
                    <a href="#udf-of-different-style" aria-label="udf of different style">udf of different style</a></li>
                <li>
                    <a href="#other-operation" aria-label="other operation">other operation</a>
                </li>
            </ul>
        </div>
        </details>
    </div>
</aside>
<script>
    let activeElement;
    let elements;
    window.addEventListener('DOMContentLoaded', function (event) {
        checkTocPosition();

        elements = document.querySelectorAll('h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]');
        
        activeElement = elements[0];
        const id = encodeURI(activeElement.getAttribute('id')).toLowerCase();
        document.querySelector(`.inner ul li a[href="#${id}"]`).classList.add('active');
    }, false);

    window.addEventListener('resize', function(event) {
        checkTocPosition();
    }, false);

    window.addEventListener('scroll', () => {
        
        activeElement = Array.from(elements).find((element) => {
            if ((getOffsetTop(element) - window.pageYOffset) > 0 &&
                (getOffsetTop(element) - window.pageYOffset) < window.innerHeight/2) {
                return element;
            }
        }) || activeElement

        elements.forEach(element => {
            const id = encodeURI(element.getAttribute('id')).toLowerCase();
            if (element === activeElement){
                document.querySelector(`.inner ul li a[href="#${id}"]`).classList.add('active');
            } else {
                document.querySelector(`.inner ul li a[href="#${id}"]`).classList.remove('active');
            }
        })
    }, false);

    const main = parseInt(getComputedStyle(document.body).getPropertyValue('--article-width'), 10);
    const toc = parseInt(getComputedStyle(document.body).getPropertyValue('--toc-width'), 10);
    const gap = parseInt(getComputedStyle(document.body).getPropertyValue('--gap'), 10);

    function checkTocPosition() {
        const width = document.body.scrollWidth;
        if (width - main - (toc * 2) - (gap * 4) > 0) {
            document.getElementById("toc-container").classList.add("wide");
        } else {
            document.getElementById("toc-container").classList.remove("wide");
        }
    }

    function getOffsetTop(element) {
        if (!element.getClientRects().length) {
            return 0;
        }
        let rect = element.getBoundingClientRect();
        let win = element.ownerDocument.defaultView;
        return rect.top + win.pageYOffset;
    }
</script>
        <div class="post-content"><p>spark datagrameçš„æ“ä½œæ€»ç»“</p>
<h3 id="èµ„æ–™">èµ„æ–™<a hidden class="anchor" aria-hidden="true" href="#èµ„æ–™">#</a></h3>
<ul>
<li><a href="https://databricks.com/blog/2016/01/04/introducing-apache-spark-datasets.html" target="_blank" rel="noopener" style="color:#42b983";>https://databricks.com/blog/2016/01/04/introducing-apache-spark-datasets.html</a>
<ul>
<li>Spark Datasets, an extension of the DataFrame API that provides a type-safe, object-oriented programming interface.</li>
<li>Datasets extend these benefits with compile-time type safety â€“ meaning production applications can be checked for errors before they are run. è¿™ç‚¹éå¸¸é‡è¦ï¼Œå› ä¸ºåœ¨è¿™ç§å¤§æ•°æ®åº”ç”¨å¼€å‘ä¸­ï¼Œæ„é€ æµ‹è¯•æ•°æ®å’Œè¿è¡Œæµ‹è¯•ç¨‹åºéƒ½æ¯”è¾ƒéº»çƒ¦ï¼Œæœ‰äº†type-safeå°±å¯ä»¥çœå»å¾ˆå¤šéº»çƒ¦ã€‚</li>
<li>Both APIs make it easy to express the transformation using lambda functions.</li>
<li>with Datasets you also have access to all the power of a full relational execution engine.</li>
</ul>
</li>
<li><a href="http://www.agildata.com/apache-spark-rdd-vs-dataframe-vs-dataset/" target="_blank" rel="noopener" style="color:#42b983";>http://www.agildata.com/apache-spark-rdd-vs-dataframe-vs-dataset/</a>
<ul>
<li>The DataFrame API introduces the concept of a schema to describe the data, allowing Spark to manage the schema and only pass data between nodes, in a much more efficient way than using Java serialization.</li>
<li>Because the code is referring to data attributes by name, it is not possible for the compiler to catch any errors. If attribute names are incorrect then the error will only detected at runtime, when the query plan is created.</li>
<li>the familiar object-oriented programming style and compile-time type-safety of the RDD API but with the performance benefits of the Catalyst query optimizer.</li>
<li>Additionally, the Dataset API is designed to work equally well with both Java and Scala. When working with Java objects, it is important that they are fully bean-compliant</li>
</ul>
</li>
<li><a href="https://databricks.com/blog/2015/08/12/from-pandas-to-apache-sparks-dataframe.html" target="_blank" rel="noopener" style="color:#42b983";>https://databricks.com/blog/2015/08/12/from-pandas-to-apache-sparks-dataframe.html</a>
<ul>
<li>a few operations that you can do in Pandas donâ€™t translate to Spark well</li>
<li>ä¸å¯åƒpandasé‚£æ ·è¿ç”¨è¡Œåˆ—åæ ‡è·å–å•ä¸ªå…ƒç´ </li>
<li>ä¸èƒ½ col1 = col2*col3è¿™ç§å½¢å¼ï¼Œå› ä¸ºimmutable.</li>
<li>The only difference is that in Pandas, it is a mutable data structure that you can change â€“ not in Spark.</li>
<li>å˜æ€çš„åˆ—å‘½å: In Spark SQL DataFrame columns are allowed to have the same name, theyâ€™ll be given unique names inside of Spark SQL, but this means that you canâ€™t reference them with the column name only as this becomes ambiguous.</li>
</ul>
</li>
</ul>
<h3 id="import">import<a hidden class="anchor" aria-hidden="true" href="#import">#</a></h3>
<pre><code>//val sqlContext = new SQLContext(sc)
//import sqlContext.implicits._
</code></pre>
<h3 id="dataframe-creation">DataFrame creation<a hidden class="anchor" aria-hidden="true" href="#dataframe-creation">#</a></h3>
<pre><code>//createDataFrame
val df = sqlContext.createDataFrame(Array((3,8,&quot;asdf&quot;),(4,8,&quot;ewe&quot;),(4,8,&quot;-pl[&quot;))).toDF(&quot;a&quot;,&quot;b&quot;,&quot;c&quot;)
df.show(10)

//rdd(parallelize) then tranform to DF using toDF
val rdd = sc.parallelize(Seq((1,2),(3,4),(3,5)))
val df2 = rdd.toDF(&quot;name&quot;,&quot;age&quot;)// this creates a DataFrame with column name &quot;name&quot; and &quot;age&quot;
df2.show(10)
val df3 = rdd.toDF()  // this implicit conversion creates a DataFrame with column name _1 and _2
df3.show(10)

// load method(depreacated)
val df4 = sqlContext.load(&quot;com.databricks.spark.csv&quot;,
  Map(&quot;path&quot; -&gt; &quot;/home/chester/data/2016-06/partsorthead&quot;, &quot;header&quot; -&gt; &quot;true&quot;, &quot;delimiter&quot; -&gt; &quot;\t&quot;))
df4.show(10)

// read
val options = Map(&quot;header&quot; -&gt; &quot;true&quot;, &quot;path&quot; -&gt; &quot;/home/chester/data/2016-07/dist&quot;)
val newStudents = sqlContext.read.options(options).format(&quot;com.databricks.spark.csv&quot;).load()
newStudents.show(10)
</code></pre>
<h3 id="save-to-hdfs">save to hdfs<a hidden class="anchor" aria-hidden="true" href="#save-to-hdfs">#</a></h3>
<pre><code>df.select(&quot;year&quot;, &quot;model&quot;).save(&quot;newcars.csv&quot;, &quot;com.databricks.spark.csv&quot;)
</code></pre>
<h3 id="column-rename">column rename<a hidden class="anchor" aria-hidden="true" href="#column-rename">#</a></h3>
<pre><code>withColumnRenamed(existingName: String, newName: String): DataFrame
</code></pre>
<h3 id="single-column-operation">single column operation<a hidden class="anchor" aria-hidden="true" href="#single-column-operation">#</a></h3>
<pre><code>//Returns a new DataFrame by adding a column or replacing the existing column that has the same name.
//withColumn(colName: String, col: Column): DataFrame 
//(column =&gt; column(new value)) or (column =&gt; new column(new value))
val clickSeqUdf = udf((score: String) =&gt; score.replace(&quot;(&quot;,&quot;&quot;).toInt-1)
val newdf2 = newdf.withColumn(&quot;clickSeq&quot;,clickSeqUdf(newdf.col(&quot;clickSeq&quot;)))
</code></pre>
<h3 id="multiple-column-operation-column1column2--new-columnnew-value">multiple column operation ((column1,column2) =&gt; new column(new value)))<a hidden class="anchor" aria-hidden="true" href="#multiple-column-operation-column1column2--new-columnnew-value">#</a></h3>
<pre><code>//udf definition
udf[ouput type, input2 type, input2 type]
</code></pre>
<h3 id="udf-definition-and-application">udf definition and application<a hidden class="anchor" aria-hidden="true" href="#udf-definition-and-application">#</a></h3>
<pre><code>val toInt    = udf[String, String]( _+ &quot;haha&quot;)
val newdf = df.withColumn(&quot;name&quot;,(udf[String, String]( _+ &quot;haha&quot;)).apply(df.col(&quot;name&quot;)))
</code></pre>
<h3 id="dataframe-join">DataFrame join<a hidden class="anchor" aria-hidden="true" href="#dataframe-join">#</a></h3>
<pre><code>df1.join(department, df1(&quot;deptId&quot;) === department(&quot;id&quot;)
</code></pre>
<h3 id="udf-of-different-style">udf of different style<a hidden class="anchor" aria-hidden="true" href="#udf-of-different-style">#</a></h3>
<pre><code>//æ˜¾ç¤ºå®šä¹‰udfï¼Œæ— ç±»å‹æ¨æ–­
val checksum = udf[Int,String,Int](_.toInt+_)
df.withColumn(&quot;name&quot;,checksum.apply($&quot;name&quot;,$&quot;age&quot;)).show(10)

//æ˜¾ç¤ºå®šä¹‰udfå‡½æ•°,ç±»å‹æ¨æ–­
val a:(Int,Int) =&gt; Int =(x:Int,y:Int) =&gt; x+y
//ç®€ç•¥å®šä¹‰
val b = (x: String, y: Int) =&gt; x.toInt + y
df.withColumn(&quot;name&quot;, udf(b).apply($&quot;name&quot;, $&quot;age&quot;)).show(10)

//éšå¼å®šä¹‰udfå‡½æ•°,è‡ªåŠ¨ç±»å‹æ¨æ–­
df.withColumn(&quot;name&quot;, udf((x: String, y: Int) =&gt; x.toInt + y).apply($&quot;name&quot;, $&quot;age&quot;)).show(10)
df.filter(udf((x: String, y: Int) =&gt; x.toInt-100 &gt; y).apply($&quot;name&quot;, $&quot;age&quot;)).show(10)

//éšå¼å®šä¹‰ï¼Œæ— ç±»å‹æ¨æ–­
df.withColumn(&quot;name&quot;, udf[String, String]( x =&gt;  x+ &quot;haha&quot;).apply($&quot;name&quot;)).show(10)

//org.apache.spark.sql.functionsé‡Œå®šä¹‰äº†å¤§é‡çš„udf
</code></pre>
<h3 id="other-operation">other operation<a hidden class="anchor" aria-hidden="true" href="#other-operation">#</a></h3>
<p>å¦‚æœDataFrameçš„methodæ— æ³•æ»¡è¶³éœ€æ±‚çš„æ—¶å€™ï¼Œå¯ä»¥è°ƒç”¨rdd()è½¬åŒ–ä¸ºrdd, åœ¨rddä¸Šåšæ›´çµæ´»çš„æ“ä½œï¼Œä¹‹åå†è½¬åŒ–ä¸ºDataFrame.</p>


        </div>

        <footer class="post-footer">
            
<nav class="paginav">
  <a class="prev" href="https://chesterwang.github.io/chester-blog/en/posts/2016-07-17-enders-game-notes/">
    <span class="title">Â« ä¸Šä¸€é¡µ</span>
    <br>
    <span>Ender&#39;s Game ç¬”è®°</span>
  </a>
</nav>

        </footer>
    </div>



<div>
    <div class="pagination__title">
        <span class="pagination__title-h" style="font-size: 20px;">ğŸ’¬è¯„è®º</span>
        <hr />
    </div>

    <div id="tcomment"></div>

    <script src="https://image.lvbibir.cn/js/1.6.40/twikoo.all.min.js">
    </script>
    

    

    <script>
        twikoo.init({
            envId: "https://twikoo.lvbibir.cn/", 
            el: "#tcomment",
            lang: 'zh-CN',
            
            path: window.TWIKOO_MAGIC_PATH||window.location.pathname,
            
            
            
            
            
            
            
        });
    </script>

</div>
</article>
</main>


<footer class="footer">

    <a href="https://gohugo.io/" target="_blank">
        
        <img style="display: unset;" src="https://image.lvbibir.cn/blog/frame-hugo-blue.svg">
    </a>
    <a href="https://github.com/adityatelange/hugo-PaperMod" target="_blank">
        
        <img style="display: unset;" src="https://image.lvbibir.cn/blog/theme-papermod-lightgrey.svg">
    </a>
    <a href="https://cn.aliyun.com/" target="_blank">
        
        <img style="display: unset;" src="https://image.lvbibir.cn/blog/å›¾åºŠ-é˜¿é‡Œäº‘-orange.svg">
    </a>

    <br>

    <span id="runtime_span"></span>
    <script
        type="text/javascript">function show_runtime() { window.setTimeout("show_runtime()", 1000); X = new Date("11/11/2025 1:00:00"); Y = new Date(); T = (Y.getTime() - X.getTime()); M = 24 * 60 * 60 * 1000; a = T / M; A = Math.floor(a); b = (a - A) * 24; B = Math.floor(b); c = (b - B) * 60; C = Math.floor((b - B) * 60); D = Math.floor((c - C) * 60); runtime_span.innerHTML = "ç½‘ç«™å·²è¿è¡Œ" + A + "å¤©" + B + "å°æ—¶" + C + "åˆ†" + D + "ç§’" } show_runtime();</script>
    |
    <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span id="busuanzi_container">
        
        æ€»è®¿å®¢æ•°:  <span id="busuanzi_value_site_uv"></span>
        |
        æ€»è®¿é—®é‡:  <span id="busuanzi_value_site_pv"></span>
    </span>

    <br>

    
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <span class="topInner">
        <svg class="topSvg" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
            <path d="M12 6H0l6-6z" />
        </svg>
        <span id="read_progress"></span>
    </span>
</a>

<script>
    document.addEventListener('scroll', function (e) {
        const readProgress = document.getElementById("read_progress");
        const scrollHeight = document.documentElement.scrollHeight;
        const clientHeight = document.documentElement.clientHeight;
        const scrollTop = document.documentElement.scrollTop || document.body.scrollTop;
        
        readProgress.innerText = ((scrollTop / (scrollHeight - clientHeight)).toFixed(2) * 100).toFixed(0);
    })
</script>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    let mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 400 || document.documentElement.scrollTop > 400) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };
</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>


<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerText = 'ğŸ“„å¤åˆ¶';

        function copyingDone() {
            copybutton.innerText = 'ğŸ‘ŒğŸ»å·²å¤åˆ¶!';
            setTimeout(() => {
                copybutton.innerText = 'ğŸ“„å¤åˆ¶';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            
            
            
            
            
            
            
            
            
            
            
            
            
            

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) {
            }
            ;
            selection.removeRange(range);
        });

        let language = codeblock.className.replaceAll("language-", "")
        let macTool = document.createElement("div")
        let macTool1 = document.createElement("div")
        let macTool2 = document.createElement("div")
        let macTool3 = document.createElement("div")
        let languageType = document.createElement("div")
        languageType.innerText = language
        macTool.setAttribute('class', 'mac-tool')
        macTool1.setAttribute('class', 'mac bb1')
        macTool2.setAttribute('class', 'mac bb2')
        macTool3.setAttribute('class', 'mac bb3')
        languageType.setAttribute('class', 'language-type')
        macTool.appendChild(macTool1)
        macTool.appendChild(macTool2)
        macTool.appendChild(macTool3)
        macTool.appendChild(languageType)

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
            container.appendChild(macTool)
        } else if (container.parentNode.firstChild === container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName === "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
            container.appendChild(macTool)
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
            container.appendChild(macTool)
        }
    });
</script>

</body>

</html>
